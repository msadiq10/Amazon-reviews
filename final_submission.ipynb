{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R7vdbnYzWg6n"
      },
      "source": [
        "# Installations"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m-A4zwc9YNgW",
        "outputId": "a38a8e3d-b571-4fb3-cc8a-7deb46a3b219"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! pip install pyLDAvis"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qPbrPLdpjN-1",
        "outputId": "8c187370-c2e4-45e2-de77-31c7c3161717"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting pyLDAvis\n",
            "  Downloading pyLDAvis-3.4.0-py3-none-any.whl (2.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.6/2.6 MB\u001b[0m \u001b[31m27.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pandas>=1.3.4 in /usr/local/lib/python3.9/dist-packages (from pyLDAvis) (1.4.4)\n",
            "Collecting funcy\n",
            "  Downloading funcy-2.0-py2.py3-none-any.whl (30 kB)\n",
            "Requirement already satisfied: numpy>=1.22.0 in /usr/local/lib/python3.9/dist-packages (from pyLDAvis) (1.22.4)\n",
            "Requirement already satisfied: numexpr in /usr/local/lib/python3.9/dist-packages (from pyLDAvis) (2.8.4)\n",
            "Requirement already satisfied: gensim in /usr/local/lib/python3.9/dist-packages (from pyLDAvis) (4.3.1)\n",
            "Collecting joblib>=1.2.0\n",
            "  Downloading joblib-1.2.0-py3-none-any.whl (297 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m298.0/298.0 KB\u001b[0m \u001b[31m26.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: scikit-learn>=1.0.0 in /usr/local/lib/python3.9/dist-packages (from pyLDAvis) (1.2.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.9/dist-packages (from pyLDAvis) (1.10.1)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.9/dist-packages (from pyLDAvis) (67.6.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.9/dist-packages (from pyLDAvis) (3.1.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.9/dist-packages (from pandas>=1.3.4->pyLDAvis) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.9/dist-packages (from pandas>=1.3.4->pyLDAvis) (2022.7.1)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.9/dist-packages (from scikit-learn>=1.0.0->pyLDAvis) (3.1.0)\n",
            "Requirement already satisfied: smart-open>=1.8.1 in /usr/local/lib/python3.9/dist-packages (from gensim->pyLDAvis) (6.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.9/dist-packages (from jinja2->pyLDAvis) (2.1.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.9/dist-packages (from python-dateutil>=2.8.1->pandas>=1.3.4->pyLDAvis) (1.16.0)\n",
            "Installing collected packages: funcy, joblib, pyLDAvis\n",
            "  Attempting uninstall: joblib\n",
            "    Found existing installation: joblib 1.1.1\n",
            "    Uninstalling joblib-1.1.1:\n",
            "      Successfully uninstalled joblib-1.1.1\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "pandas-profiling 3.2.0 requires joblib~=1.1.0, but you have joblib 1.2.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed funcy-2.0 joblib-1.2.0 pyLDAvis-3.4.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_xw9EZvQWg6u",
        "outputId": "42c24b58-9f87-4beb-dd6b-745c543b3a0e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: pandas in c:\\users\\sayed\\anaconda3\\lib\\site-packages (1.4.4)\n",
            "Requirement already satisfied: pytz>=2020.1 in c:\\users\\sayed\\anaconda3\\lib\\site-packages (from pandas) (2022.1)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in c:\\users\\sayed\\anaconda3\\lib\\site-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: numpy>=1.18.5 in c:\\users\\sayed\\anaconda3\\lib\\site-packages (from pandas) (1.23.5)\n",
            "Requirement already satisfied: six>=1.5 in c:\\users\\sayed\\anaconda3\\lib\\site-packages (from python-dateutil>=2.8.1->pandas) (1.16.0)\n",
            "Requirement already satisfied: numpy in c:\\users\\sayed\\anaconda3\\lib\\site-packages (1.23.5)\n",
            "Requirement already satisfied: matplotlib in c:\\users\\sayed\\anaconda3\\lib\\site-packages (3.5.2)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\sayed\\anaconda3\\lib\\site-packages (from matplotlib) (2.8.2)\n",
            "Requirement already satisfied: cycler>=0.10 in c:\\users\\sayed\\anaconda3\\lib\\site-packages (from matplotlib) (0.11.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\users\\sayed\\anaconda3\\lib\\site-packages (from matplotlib) (1.4.2)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\sayed\\anaconda3\\lib\\site-packages (from matplotlib) (4.25.0)\n",
            "Requirement already satisfied: numpy>=1.17 in c:\\users\\sayed\\anaconda3\\lib\\site-packages (from matplotlib) (1.23.5)\n",
            "Requirement already satisfied: pillow>=6.2.0 in c:\\users\\sayed\\anaconda3\\lib\\site-packages (from matplotlib) (9.2.0)\n",
            "Requirement already satisfied: pyparsing>=2.2.1 in c:\\users\\sayed\\anaconda3\\lib\\site-packages (from matplotlib) (3.0.9)\n",
            "Requirement already satisfied: packaging>=20.0 in c:\\users\\sayed\\anaconda3\\lib\\site-packages (from matplotlib) (21.3)\n",
            "Requirement already satisfied: six>=1.5 in c:\\users\\sayed\\anaconda3\\lib\\site-packages (from python-dateutil>=2.7->matplotlib) (1.16.0)\n",
            "Requirement already satisfied: nltk in c:\\users\\sayed\\anaconda3\\lib\\site-packages (3.7)\n",
            "Requirement already satisfied: regex>=2021.8.3 in c:\\users\\sayed\\anaconda3\\lib\\site-packages (from nltk) (2022.7.9)\n",
            "Requirement already satisfied: joblib in c:\\users\\sayed\\anaconda3\\lib\\site-packages (from nltk) (1.1.0)\n",
            "Requirement already satisfied: tqdm in c:\\users\\sayed\\anaconda3\\lib\\site-packages (from nltk) (4.64.1)\n",
            "Requirement already satisfied: click in c:\\users\\sayed\\anaconda3\\lib\\site-packages (from nltk) (8.0.4)\n",
            "Requirement already satisfied: colorama in c:\\users\\sayed\\anaconda3\\lib\\site-packages (from click->nltk) (0.4.5)\n",
            "Requirement already satisfied: scikit-learn in c:\\users\\sayed\\anaconda3\\lib\\site-packages (1.0.2)\n",
            "Requirement already satisfied: numpy>=1.14.6 in c:\\users\\sayed\\anaconda3\\lib\\site-packages (from scikit-learn) (1.23.5)\n",
            "Requirement already satisfied: joblib>=0.11 in c:\\users\\sayed\\anaconda3\\lib\\site-packages (from scikit-learn) (1.1.0)\n",
            "Requirement already satisfied: scipy>=1.1.0 in c:\\users\\sayed\\anaconda3\\lib\\site-packages (from scikit-learn) (1.9.1)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\sayed\\anaconda3\\lib\\site-packages (from scikit-learn) (2.2.0)\n",
            "Requirement already satisfied: tensorflow in c:\\users\\sayed\\anaconda3\\lib\\site-packages (2.12.0)\n",
            "Requirement already satisfied: tensorflow-intel==2.12.0 in c:\\users\\sayed\\anaconda3\\lib\\site-packages (from tensorflow) (2.12.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in c:\\users\\sayed\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow) (16.0.0)\n",
            "Requirement already satisfied: packaging in c:\\users\\sayed\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow) (21.3)\n",
            "Requirement already satisfied: setuptools in c:\\users\\sayed\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow) (63.4.1)\n",
            "Requirement already satisfied: flatbuffers>=2.0 in c:\\users\\sayed\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow) (23.3.3)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in c:\\users\\sayed\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow) (4.22.1)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in c:\\users\\sayed\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow) (1.53.0)\n",
            "Requirement already satisfied: tensorflow-estimator<2.13,>=2.12.0 in c:\\users\\sayed\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow) (2.12.0)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in c:\\users\\sayed\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow) (0.31.0)\n",
            "Requirement already satisfied: numpy<1.24,>=1.22 in c:\\users\\sayed\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow) (1.23.5)\n",
            "Requirement already satisfied: wrapt<1.15,>=1.11.0 in c:\\users\\sayed\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow) (1.14.1)\n",
            "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in c:\\users\\sayed\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow) (0.4.0)\n",
            "Requirement already satisfied: tensorboard<2.13,>=2.12 in c:\\users\\sayed\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow) (2.12.1)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in c:\\users\\sayed\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow) (3.3.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in c:\\users\\sayed\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow) (1.6.3)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in c:\\users\\sayed\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow) (1.4.0)\n",
            "Requirement already satisfied: six>=1.12.0 in c:\\users\\sayed\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow) (1.16.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in c:\\users\\sayed\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow) (4.3.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in c:\\users\\sayed\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow) (2.2.0)\n",
            "Requirement already satisfied: keras<2.13,>=2.12.0 in c:\\users\\sayed\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow) (2.12.0)\n",
            "Requirement already satisfied: jax>=0.3.15 in c:\\users\\sayed\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow) (0.4.8)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in c:\\users\\sayed\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow) (0.2.0)\n",
            "Requirement already satisfied: h5py>=2.9.0 in c:\\users\\sayed\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow) (3.7.0)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in c:\\users\\sayed\\anaconda3\\lib\\site-packages (from astunparse>=1.6.0->tensorflow-intel==2.12.0->tensorflow) (0.37.1)\n",
            "Requirement already satisfied: ml-dtypes>=0.0.3 in c:\\users\\sayed\\anaconda3\\lib\\site-packages (from jax>=0.3.15->tensorflow-intel==2.12.0->tensorflow) (0.0.4)\n",
            "Requirement already satisfied: scipy>=1.7 in c:\\users\\sayed\\anaconda3\\lib\\site-packages (from jax>=0.3.15->tensorflow-intel==2.12.0->tensorflow) (1.9.1)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in c:\\users\\sayed\\anaconda3\\lib\\site-packages (from tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->tensorflow) (1.8.1)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in c:\\users\\sayed\\anaconda3\\lib\\site-packages (from tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->tensorflow) (2.17.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\sayed\\anaconda3\\lib\\site-packages (from tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->tensorflow) (3.3.4)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in c:\\users\\sayed\\anaconda3\\lib\\site-packages (from tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->tensorflow) (2.28.1)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in c:\\users\\sayed\\anaconda3\\lib\\site-packages (from tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->tensorflow) (2.0.3)\n",
            "Requirement already satisfied: google-auth-oauthlib<1.1,>=0.5 in c:\\users\\sayed\\anaconda3\\lib\\site-packages (from tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->tensorflow) (1.0.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in c:\\users\\sayed\\anaconda3\\lib\\site-packages (from tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->tensorflow) (0.7.0)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in c:\\users\\sayed\\anaconda3\\lib\\site-packages (from packaging->tensorflow-intel==2.12.0->tensorflow) (3.0.9)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in c:\\users\\sayed\\anaconda3\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->tensorflow) (0.2.8)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in c:\\users\\sayed\\anaconda3\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->tensorflow) (5.3.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in c:\\users\\sayed\\anaconda3\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->tensorflow) (4.9)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in c:\\users\\sayed\\anaconda3\\lib\\site-packages (from google-auth-oauthlib<1.1,>=0.5->tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->tensorflow) (1.3.1)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\sayed\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->tensorflow) (1.26.11)\n",
            "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\sayed\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->tensorflow) (3.3)\n",
            "Requirement already satisfied: charset-normalizer<3,>=2 in c:\\users\\sayed\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->tensorflow) (2.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\sayed\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->tensorflow) (2022.9.14)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in c:\\users\\sayed\\anaconda3\\lib\\site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->tensorflow) (0.4.8)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in c:\\users\\sayed\\anaconda3\\lib\\site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<1.1,>=0.5->tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->tensorflow) (3.2.2)\n"
          ]
        }
      ],
      "source": [
        "! pip install pandas\n",
        "! pip install numpy\n",
        "! pip install matplotlib\n",
        "! pip install nltk\n",
        "! pip install scikit-learn\n",
        "! pip install tensorflow"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hr6igTp3Wg6z"
      },
      "source": [
        "# Import libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "k_kvbmJeWg60"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import SnowballStemmer\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "import re\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import precision_score, recall_score, f1_score, accuracy_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "from scipy.stats import uniform\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.pipeline import Pipeline\n",
        "from scipy.stats import randint\n",
        "import tensorflow as tf"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wlf4fReVWg63"
      },
      "outputs": [],
      "source": [
        "np.set_printoptions(threshold=np.inf, linewidth=np.inf)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zsyIDlCvWg64",
        "outputId": "1772b9cc-1198-4a0b-c73a-cdc81e21065c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package omw-1.4 to /root/nltk_data...\n",
            "[nltk_data]   Package omw-1.4 is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "source": [
        "# Download necessary tools from NLTK\n",
        "nltk.download('omw-1.4')\n",
        "nltk.download('stopwords')\n",
        "nltk.download('punkt')\n",
        "nltk.download('wordnet')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TsViFZBtWg66"
      },
      "source": [
        "# Data Exploration and Visualization"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hI9nM8A3Wg67"
      },
      "source": [
        "### Load data "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZI5epw5iWg68"
      },
      "outputs": [],
      "source": [
        "train = pd.read_csv('train.csv')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mIJ87HHcWg69"
      },
      "source": [
        "### Exploration"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "I7lGfB1AWg6-",
        "outputId": "80f9b131-d179-4f61-baf0-8be5cd3255e0"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   overall                                             Review\n",
              "0        5  This a really cool (but time-tested) design. T...\n",
              "1        5  I liked the first pair so well I bought severa...\n",
              "2        4  I took them to the range to put them to the te...\n",
              "3        5  What can you say about a yoga block?  These ar...\n",
              "4        5  After reading many reviews I decided on this l..."
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-9deed17c-39ae-4c7c-83bc-6c9bcdacf828\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>overall</th>\n",
              "      <th>Review</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>5</td>\n",
              "      <td>This a really cool (but time-tested) design. T...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>5</td>\n",
              "      <td>I liked the first pair so well I bought severa...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>4</td>\n",
              "      <td>I took them to the range to put them to the te...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>5</td>\n",
              "      <td>What can you say about a yoga block?  These ar...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>After reading many reviews I decided on this l...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-9deed17c-39ae-4c7c-83bc-6c9bcdacf828')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-9deed17c-39ae-4c7c-83bc-6c9bcdacf828 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-9deed17c-39ae-4c7c-83bc-6c9bcdacf828');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ],
      "source": [
        "train.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VLd_B70TWg6_",
        "outputId": "b2e6133c-13ed-43fc-87f1-f1747907809f"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>overall</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>222243.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>4.394771</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>0.985039</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>4.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>5.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>5.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>5.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "             overall\n",
              "count  222243.000000\n",
              "mean        4.394771\n",
              "std         0.985039\n",
              "min         1.000000\n",
              "25%         4.000000\n",
              "50%         5.000000\n",
              "75%         5.000000\n",
              "max         5.000000"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train.describe()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "beyohqVAWg7A",
        "outputId": "cdc4ceff-48a9-46f3-c40f-374a7e7fff07"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 222243 entries, 0 to 222242\n",
            "Data columns (total 2 columns):\n",
            " #   Column   Non-Null Count   Dtype \n",
            "---  ------   --------------   ----- \n",
            " 0   overall  222243 non-null  int64 \n",
            " 1   Review   222243 non-null  object\n",
            "dtypes: int64(1), object(1)\n",
            "memory usage: 3.4+ MB\n"
          ]
        }
      ],
      "source": [
        "train.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6C11uTs_Wg7B",
        "outputId": "e756208b-04e4-4753-fa68-271b0ad249a7"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "overall                                                    4\n",
              "Review     I took them to the range to put them to the te...\n",
              "Name: 2, dtype: object"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train.loc[2]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JgA0_PU3Wg7C",
        "outputId": "a40188e3-71b1-4546-beb1-073affdc6b24"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "4"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train.loc[2, 'overall']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CD66iWUVWg7E",
        "outputId": "7b2f8bc0-8dfc-4d33-ab17-d2b300fbd3ae"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Total number of reviews/ratings:  222243\n"
          ]
        }
      ],
      "source": [
        "totalCount = train['overall'].count()\n",
        "print('Total number of reviews/ratings: ', totalCount)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kym6I9OWWg7F",
        "outputId": "6652a48f-ae8f-424d-8c09-d165c2ac912f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Total number of reviews with 5 star rating:  141169\n",
            "Total number of reviews with 4 star rating:  48748\n",
            "Total number of reviews with 3 star rating:  17947\n",
            "Total number of reviews with 2 star rating:  7650\n",
            "Total number of reviews with 1 star rating:  6729\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "count5 = train[train['overall']==5]['overall'].count()\n",
        "count4 = train[train['overall']==4]['overall'].count()\n",
        "count3 = train[train['overall']==3]['overall'].count()\n",
        "count2 = train[train['overall']==2]['overall'].count()\n",
        "count1 = train[train['overall']==1]['overall'].count()\n",
        "\n",
        "print('Total number of reviews with 5 star rating: ', count5)\n",
        "print('Total number of reviews with 4 star rating: ', count4)\n",
        "print('Total number of reviews with 3 star rating: ', count3)\n",
        "print('Total number of reviews with 2 star rating: ', count2)\n",
        "print('Total number of reviews with 1 star rating: ', count1)\n",
        "\n",
        "count5+count4+count3+count2+count1==totalCount"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6zmHgLEXWg7H",
        "outputId": "6bc907d5-69c8-4145-9ddc-e494adce1be4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Percentage of reviews with 5 star rating:  63.52\n",
            "Percentage of reviews with 4 star rating:  21.93\n",
            "Percentage of reviews with 3 star rating:  8.08\n",
            "Percentage of reviews with 2 star rating:  3.44\n",
            "Percentage of reviews with 1 star rating:  3.03\n"
          ]
        }
      ],
      "source": [
        "percent5 = format((count5/totalCount)*100, '.2f')\n",
        "percent4 = format((count4/totalCount)*100, '.2f')\n",
        "percent3 = format((count3/totalCount)*100, '.2f')\n",
        "percent2 = format((count2/totalCount)*100, '.2f')\n",
        "percent1 = format((count1/totalCount)*100, '.2f')\n",
        "\n",
        "print('Percentage of reviews with 5 star rating: ', percent5)\n",
        "print('Percentage of reviews with 4 star rating: ', percent4)\n",
        "print('Percentage of reviews with 3 star rating: ', percent3)\n",
        "print('Percentage of reviews with 2 star rating: ', percent2)\n",
        "print('Percentage of reviews with 1 star rating: ', percent1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SphYQh2sWg7J"
      },
      "source": [
        "### Visualization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "B217g3qyWg7K",
        "outputId": "082203c5-fe59-46df-81cb-c6802cb95686"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "## Print the Pie Chart ##\n",
        "    \n",
        "labels = ['5 star ['+str(percent5)+'%]', \n",
        "          '4 star ['+str(percent4)+'%]', \n",
        "          '3 star ['+str(percent3)+'%]',\n",
        "          '2 star ['+str(percent2)+'%]',\n",
        "          '1 star ['+str(percent1)+'%]', ]\n",
        "\n",
        "sizes = [percent5, percent4, percent3, percent2, percent1]\n",
        "colors = ['green', 'yellowgreen', 'gold', 'orange', 'red']\n",
        "patches, texts = plt.pie(sizes, colors = colors, startangle = 90)\n",
        "plt.legend(patches, labels, loc = \"best\")\n",
        "plt.title(\"Overall Review Distribution by analyzing \" + str(totalCount) + \" Amazon Reviews \")\n",
        "plt.axis('equal')\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7MBwKug8Wg7L",
        "outputId": "b587c763-762c-4fca-f1fb-3e168d4af647"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# data to plot\n",
        "labels = ['5', '4', '3', '2', '1']\n",
        "values = [count5, count4, count3, count2, count1]\n",
        "\n",
        "# create a bar chart\n",
        "plt.bar(labels, values)\n",
        "\n",
        "# set title and axis labels\n",
        "plt.title('No. of Reviews vs Ratings')\n",
        "plt.xlabel('Ratings')\n",
        "plt.ylabel('No. of Reviews')\n",
        "\n",
        "# display the plot\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V-XXaXjuWg7N"
      },
      "source": [
        "# Text processing and Normalization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XxmJaxLxWg7N"
      },
      "outputs": [],
      "source": [
        "X = train['Review']\n",
        "y = train['overall']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OzbAx_S7Wg7O",
        "outputId": "dda53621-f50f-478b-df6d-b6a75f36138e"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0    This a really cool (but time-tested) design. T...\n",
              "1    I liked the first pair so well I bought severa...\n",
              "2    I took them to the range to put them to the te...\n",
              "3    What can you say about a yoga block?  These ar...\n",
              "4    After reading many reviews I decided on this l...\n",
              "Name: Review, dtype: object"
            ]
          },
          "execution_count": 19,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "X.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HINcA9GfWg7P",
        "outputId": "f3ac9037-7332-4cc8-e4b4-c30af6e19957"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0    5\n",
              "1    5\n",
              "2    4\n",
              "3    5\n",
              "4    5\n",
              "Name: overall, dtype: int64"
            ]
          },
          "execution_count": 20,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "y.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ywms105zWg7Q"
      },
      "outputs": [],
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X, y ,test_size=0.2, random_state=42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xVvfmNaOWg7R",
        "outputId": "a7e62a81-a916-49db-d832-bf11416328b4"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(177794,)"
            ]
          },
          "execution_count": 22,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "X_train.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BB41RB0wWg7S"
      },
      "source": [
        "### Removing stop words, punctuations, Urls, mentions, tags"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VJIsJDpyWg7T"
      },
      "outputs": [],
      "source": [
        "# Define function to perform text processing\n",
        "def process_text(text):\n",
        "\n",
        "# Define stop words\n",
        "    stop_words = set(stopwords.words('english'))\n",
        "\n",
        "    # Define regular expression for removing punctuation\n",
        "    punct_pattern = re.compile(r'[^\\w\\s]')\n",
        "\n",
        "    # Define regular expression for removing URLs and mentions\n",
        "    url_pattern = re.compile(r'https?://\\S+|www\\.\\S+')\n",
        "    mention_pattern = re.compile(r'@[A-Za-z0-9_]+')\n",
        "    hash_pattern = re.compile(r'#[A-Za-z0-9_]+')\n",
        "\n",
        "    # Convert text to lowercase\n",
        "    text = text.lower()\n",
        "\n",
        "    # Remove URLs\n",
        "    text = url_pattern.sub('', text)\n",
        "\n",
        "    # Remove user mentions\n",
        "    text = mention_pattern.sub('', text)\n",
        "\n",
        "    # Remove hashtags\n",
        "    text = hash_pattern.sub('', text)\n",
        "\n",
        "    # remove numbers\n",
        "    text = ''.join((z for z in text if not z.isdigit()))\n",
        "    \n",
        "    # Tokenize text\n",
        "    tokens = nltk.word_tokenize(text)\n",
        "    \n",
        "    # Remove stop words\n",
        "    tokens = [token for token in tokens if token not in stop_words]\n",
        "    \n",
        "    # Remove punctuation\n",
        "    tokens = [punct_pattern.sub('', token) for token in tokens]\n",
        "    \n",
        "    # Remove any remaining empty tokens\n",
        "    tokens = [token for token in tokens if token]\n",
        "\n",
        "    # Join tokens back into a single string\n",
        "    text_processed = ' '.join(tokens)\n",
        "    \n",
        "    return text_processed"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rOvraSeEWg7U",
        "outputId": "031d21db-15d2-4e2e-c13f-50f3a8d21594"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "177794"
            ]
          },
          "execution_count": 24,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "process_train = []\n",
        "for review in X_train:\n",
        "    process_train.append(process_text(review))\n",
        "\n",
        "len(process_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ScAg9LazWg7V",
        "outputId": "3c42dac9-3991-4751-d170-4af55b08765e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Raw text: \n",
            "Not very clear in the pictures but the top area just over the head is a camo portion that is pretty corny looking.  its the &#34;old school&#34; type of camo.  Other than that its a net and not much more to say. Pretty good for the price.\n",
            "\n",
            "Processed text: \n",
            "clear pictures top area head camo portion pretty corny looking old school type camo net much say pretty good price\n"
          ]
        }
      ],
      "source": [
        "print(\"Raw text: \")\n",
        "print(X_train.iloc[0])\n",
        "print(\"\")\n",
        "print(\"Processed text: \")\n",
        "print(process_train[0])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Nhl-pGYWWg7W"
      },
      "source": [
        "### Stemming"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ICU58YsNWg7X"
      },
      "outputs": [],
      "source": [
        "stemmer = SnowballStemmer('english')\n",
        "\n",
        "\n",
        "\n",
        "def stem(text):\n",
        "\n",
        "    # Tokenize text\n",
        "    tokens = nltk.word_tokenize(text)\n",
        "        \n",
        "    # Stem words\n",
        "    tokens = [stemmer.stem(token) for token in tokens]\n",
        "    \n",
        "    # Remove any remaining empty tokens\n",
        "    tokens = [token for token in tokens if token]\n",
        "\n",
        "    # Join tokens back into a single string\n",
        "    text_processed = ' '.join(tokens)\n",
        "\n",
        "    return text_processed\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iecYDDk1Wg7Y"
      },
      "outputs": [],
      "source": [
        "normalized_process_train_stem = []\n",
        "\n",
        "for review in process_train:\n",
        "    normalized_process_train_stem.append(stem(review))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D3s3Wt-NWg7Z"
      },
      "source": [
        "### Lemmatization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NGcHZGYdWg7Z"
      },
      "outputs": [],
      "source": [
        "lemmatizer = WordNetLemmatizer()\n",
        "\n",
        "def lemmatize(text):\n",
        "            \n",
        "    # Tokenize text\n",
        "    tokens = nltk.word_tokenize(text)\n",
        "        \n",
        "    # Stem words\n",
        "    tokens = [lemmatizer.lemmatize(token) for token in tokens]\n",
        "    \n",
        "    # Remove any remaining empty tokens\n",
        "    tokens = [token for token in tokens if token]\n",
        "\n",
        "    # Join tokens back into a single string\n",
        "    text_processed = ' '.join(tokens)\n",
        "\n",
        "    return text_processed"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ttvG2De7Wg7a"
      },
      "outputs": [],
      "source": [
        "lemma_process_train = []\n",
        "for review in process_train:\n",
        "    lemma_process_train.append(lemmatize(review))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TJ31UR_bWg7b",
        "outputId": "cda639da-b146-40e5-e486-1154885080ca"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Raw text: \n",
            "Not very clear in the pictures but the top area just over the head is a camo portion that is pretty corny looking.  its the &#34;old school&#34; type of camo.  Other than that its a net and not much more to say. Pretty good for the price.\n",
            "\n",
            "Processed text: \n",
            "clear pictures top area head camo portion pretty corny looking old school type camo net much say pretty good price\n",
            "\n",
            "Processed Stemming text: \n",
            "clear pictur top area head camo portion pretti corni look old school type camo net much say pretti good price\n",
            "\n",
            "Processed Lemmatized text: \n",
            "clear picture top area head camo portion pretty corny looking old school type camo net much say pretty good price\n"
          ]
        }
      ],
      "source": [
        "print(\"Raw text: \")\n",
        "print(X_train.iloc[0])\n",
        "print(\"\")\n",
        "print(\"Processed text: \")\n",
        "print(process_train[0])\n",
        "print(\"\")\n",
        "print(\"Processed Stemming text: \")\n",
        "print(normalized_process_train_stem[0])\n",
        "print(\"\")\n",
        "print(\"Processed Lemmatized text: \")\n",
        "print(lemma_process_train[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ptQe64u8Wg7c"
      },
      "outputs": [],
      "source": [
        "test=pd.read_csv('test.csv') # submission of majority class "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "z_DahhqzWg7d"
      },
      "outputs": [],
      "source": [
        "final_submission=pd.read_csv('sample_submission.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xOYwnGVBWg7d"
      },
      "outputs": [],
      "source": [
        "test_final = test['Review']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9U9HOlfoWg7e"
      },
      "outputs": [],
      "source": [
        "process_test_final = []\n",
        "for review in test_final:\n",
        "    process_test_final.append(process_text(review))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SBGhL8S2Wg7e"
      },
      "outputs": [],
      "source": [
        "lemma_process_test_final = []\n",
        "for review in process_test_final:\n",
        "    lemma_process_test_final.append(lemmatize(review))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "19GcyCHkWg7f"
      },
      "source": [
        "# Save best output"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EE-MaMEmWg7f"
      },
      "outputs": [],
      "source": [
        "def save_output(model, test_set, vector):\n",
        "    y_final = model.predict(vector.transform(test_set))\n",
        "    final_submission=pd.read_csv('sample_submission.csv')\n",
        "    final_submission['overall'] = y_final # save the labels for your model to csv file, you willl use this for you Kaggle competition submission\n",
        "    final_submission.to_csv('final_submission.csv', index=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VtrpFp_0Wg7g"
      },
      "source": [
        "# Vector space Model and feature representation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xbA6MTcTWg7h"
      },
      "source": [
        "### Bag of words representation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LjdbAnyuWg7h",
        "outputId": "2e756c80-f915-4e58-d9f9-b28a64464411"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Vocabulary size: 13754\n"
          ]
        }
      ],
      "source": [
        "# CountVectorizer object\n",
        "vect =  CountVectorizer(min_df=15) \n",
        "vect.fit(lemma_process_train)\n",
        "print(\"Vocabulary size: {}\".format(len(vect.vocabulary_)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "j2ebLC0IWg7i",
        "outputId": "741d495f-9113-4bf5-f87a-48b15f98aa20"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Vocabulary content:\n",
            " 0\n"
          ]
        }
      ],
      "source": [
        "print(\"Vocabulary content:\\n {}\".format(vect.vocabulary_[\"aa\"]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zU9WrBT7Wg7j",
        "outputId": "8597c83e-f54a-4c7d-db25-8f02880060cb"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<177794x13754 sparse matrix of type '<class 'numpy.int64'>'\n",
              "\twith 6366581 stored elements in Compressed Sparse Row format>"
            ]
          },
          "execution_count": 38,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "bag_of_words = vect.transform(lemma_process_train)\n",
        "bag_of_words"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CEP1K1cMWg7k"
      },
      "outputs": [],
      "source": [
        "# print(\"Dense representation of bag_of_words:\\n{}\".format(\n",
        "#     bag_of_words.toarray()))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YS-VH_5_Wg7k",
        "outputId": "b8abf884-dc56-4b72-edec-63b5933d6563"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "        aa  aaa  ab  ability  able  absolute  absolutely  absorb  absorbent  \\\n",
            "0        0    0   0        0     0         0           0       0          0   \n",
            "1        0    0   0        0     0         0           0       0          0   \n",
            "2        0    0   0        0     0         0           0       0          0   \n",
            "3        0    0   0        0     0         0           0       0          0   \n",
            "4        0    0   0        0     1         0           0       0          0   \n",
            "...     ..  ...  ..      ...   ...       ...         ...     ...        ...   \n",
            "177789   0    0   0        0     0         0           0       0          0   \n",
            "177790   0    0   0        0     0         0           0       0          0   \n",
            "177791   0    0   0        0     0         0           0       0          0   \n",
            "177792   0    0   0        0     0         0           0       0          0   \n",
            "177793   0    0   0        1     0         0           0       0          0   \n",
            "\n",
            "        absorbing  ...  zip  ziplock  zipped  zipper  zippered  zippo  zombie  \\\n",
            "0               0  ...    0        0       0       0         0      0       0   \n",
            "1               0  ...    0        0       0       0         0      0       0   \n",
            "2               0  ...    0        0       0       0         0      0       0   \n",
            "3               0  ...    0        0       0       0         0      0       0   \n",
            "4               0  ...    0        0       0       0         0      0       0   \n",
            "...           ...  ...  ...      ...     ...     ...       ...    ...     ...   \n",
            "177789          0  ...    0        0       0       0         0      0       0   \n",
            "177790          0  ...    0        0       0       0         0      0       0   \n",
            "177791          0  ...    0        0       0       0         0      0       0   \n",
            "177792          0  ...    0        0       0       0         0      0       0   \n",
            "177793          0  ...    0        0       0       0         0      0       0   \n",
            "\n",
            "        zone  zoom  zt  \n",
            "0          0     0   0  \n",
            "1          0     0   0  \n",
            "2          0     0   0  \n",
            "3          0     0   0  \n",
            "4          0     0   0  \n",
            "...      ...   ...  ..  \n",
            "177789     0     0   0  \n",
            "177790     0     0   0  \n",
            "177791     0     0   0  \n",
            "177792     0     0   0  \n",
            "177793     0     0   0  \n",
            "\n",
            "[177794 rows x 5089 columns]\n"
          ]
        }
      ],
      "source": [
        "# Convert the sparse matrix to a dense matrix and print the output\n",
        "df = pd.DataFrame(bag_of_words.todense(), columns=vect.get_feature_names_out())\n",
        "print(df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "txej2WSOWg7l"
      },
      "outputs": [],
      "source": [
        "process_test = []\n",
        "for review in X_test:\n",
        "    process_test.append(process_text(review))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2ttuum0aWg7m"
      },
      "outputs": [],
      "source": [
        "lemma_process_test = []\n",
        "for review in process_test:\n",
        "    lemma_process_test.append(lemmatize(review))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aR4qdgWeWg7m"
      },
      "source": [
        "##### Logistic regression"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ADrVqvHDWg7n",
        "outputId": "50a3a6d9-d514-487d-a9e8-d21c3bf379a0"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\sadiq\\anaconda3\\envs\\tensorProject\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        }
      ],
      "source": [
        "# Train and evaluate a logistic regression classifier\n",
        "lr = LogisticRegression(max_iter=1000)\n",
        "lr.fit(bag_of_words, y_train)\n",
        "lr_pred = lr.predict(vect.transform(lemma_process_test))\n",
        "precision_lr = precision_score(y_test, lr_pred, average='macro')\n",
        "recall_lr = recall_score(y_test, lr_pred, average='macro')\n",
        "f1_lr = f1_score(y_test, lr_pred, average='macro')\n",
        "acc_lr = accuracy_score(y_test, lr_pred)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WANoeov1Wg7o",
        "outputId": "979c687e-351d-4a2c-902c-a29250546c16"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Logistic Regression: \n",
            "Precision: 0.48\n",
            "Recall: 0.42\n",
            "F1-score: 0.44\n",
            "Accuracy: 0.68\n"
          ]
        }
      ],
      "source": [
        "print('Logistic Regression: ')\n",
        "print('Precision: {:.2f}'.format(precision_lr))\n",
        "print('Recall: {:.2f}'.format(recall_lr))\n",
        "print('F1-score: {:.2f}'.format(f1_lr))\n",
        "print('Accuracy: {:.2f}'.format(acc_lr))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eTvre3o2Wg7q"
      },
      "source": [
        "Hyper-parameter tuning"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qxXitRFmWg7r",
        "outputId": "e1816739-e589-43cb-a73a-7b5f5c660e45"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\sadiq\\anaconda3\\envs\\tensorProject\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:378: FitFailedWarning: \n",
            "215 fits failed out of a total of 500.\n",
            "The score on these train-test partitions for these parameters will be set to nan.\n",
            "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
            "\n",
            "Below are more details about the failures:\n",
            "--------------------------------------------------------------------------------\n",
            "215 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"c:\\Users\\sadiq\\anaconda3\\envs\\tensorProject\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"c:\\Users\\sadiq\\anaconda3\\envs\\tensorProject\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1162, in fit\n",
            "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
            "  File \"c:\\Users\\sadiq\\anaconda3\\envs\\tensorProject\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 54, in _check_solver\n",
            "    raise ValueError(\n",
            "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
            "\n",
            "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
            "c:\\Users\\sadiq\\anaconda3\\envs\\tensorProject\\lib\\site-packages\\sklearn\\model_selection\\_search.py:952: UserWarning: One or more of the test scores are non-finite: [       nan 0.68419632        nan        nan 0.68827407 0.68348764\n",
            " 0.68309392 0.68835282 0.68228399 0.68248086 0.68458441        nan\n",
            "        nan        nan 0.68452818        nan        nan 0.68263834\n",
            " 0.68252585        nan        nan 0.68321204 0.68158657 0.68301518\n",
            "        nan 0.68369012        nan 0.68306581 0.69073197 0.68397135\n",
            " 0.68227838 0.68313329 0.68279583 0.69074323 0.68248085 0.68408383\n",
            " 0.6831558  0.68448319        nan        nan 0.68399947 0.68239649\n",
            " 0.68335265        nan        nan        nan 0.68294769 0.6839376\n",
            "        nan 0.68475315        nan 0.68308269        nan        nan\n",
            " 0.68302082        nan 0.6842132  0.6820534         nan        nan\n",
            " 0.68577681        nan        nan        nan        nan 0.68604116\n",
            "        nan        nan 0.68452255        nan        nan        nan\n",
            " 0.68496125        nan 0.68503438 0.68353826 0.68235149 0.68421883\n",
            " 0.68502312 0.68199714 0.68300394 0.68305455        nan        nan\n",
            "        nan 0.68365637        nan        nan 0.68591742        nan\n",
            " 0.6841907  0.68312205        nan 0.68391511 0.68360013        nan\n",
            "        nan 0.68405008 0.68219962 0.69108632]\n",
            "  warnings.warn(\n",
            "c:\\Users\\sadiq\\anaconda3\\envs\\tensorProject\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        },
        {
          "ename": "TypeError",
          "evalue": "sklearn.linear_model._logistic.LogisticRegression() argument after ** must be a mapping, not numpy.float64",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[1;32md:\\Github\\Amazon-reviews\\final_submission.ipynb Cell 46\u001b[0m in \u001b[0;36m2\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Github/Amazon-reviews/final_submission.ipynb#Y132sZmlsZQ%3D%3D?line=24'>25</a>\u001b[0m best_score \u001b[39m=\u001b[39m clf\u001b[39m.\u001b[39mbest_score_\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Github/Amazon-reviews/final_submission.ipynb#Y132sZmlsZQ%3D%3D?line=26'>27</a>\u001b[0m \u001b[39m# create a new logistic regression model with the best hyperparameters\u001b[39;00m\n\u001b[1;32m---> <a href='vscode-notebook-cell:/d%3A/Github/Amazon-reviews/final_submission.ipynb#Y132sZmlsZQ%3D%3D?line=27'>28</a>\u001b[0m best_lr \u001b[39m=\u001b[39m LogisticRegression(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mbest_score)\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Github/Amazon-reviews/final_submission.ipynb#Y132sZmlsZQ%3D%3D?line=29'>30</a>\u001b[0m \u001b[39m# train the model with the entire training set\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Github/Amazon-reviews/final_submission.ipynb#Y132sZmlsZQ%3D%3D?line=30'>31</a>\u001b[0m best_lr\u001b[39m.\u001b[39mfit(bag_of_words, y_train)\n",
            "\u001b[1;31mTypeError\u001b[0m: sklearn.linear_model._logistic.LogisticRegression() argument after ** must be a mapping, not numpy.float64"
          ]
        }
      ],
      "source": [
        "# define your logistic regression model\n",
        "lr_cv = LogisticRegression()\n",
        "\n",
        "# define the hyperparameters you want to tune and their range of values\n",
        "hyperparameters = {\n",
        "    'C': uniform(loc=0, scale=4),\n",
        "    'penalty': ['l1', 'l2']\n",
        "}\n",
        "\n",
        "# define your hyperparameter tuning process\n",
        "clf = RandomizedSearchCV(\n",
        "    lr_cv, \n",
        "    hyperparameters, \n",
        "    n_iter=100, \n",
        "    cv=5, \n",
        "    random_state=42, \n",
        "    n_jobs=-1\n",
        ")\n",
        "\n",
        "# fit the hyperparameter tuning process to your data\n",
        "clf.fit(bag_of_words, y_train)\n",
        "\n",
        "# get the best hyperparameters and the best score achieved\n",
        "best_params = clf.best_params_\n",
        "best_score = clf.best_score_\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nGLCQIgQWg7s",
        "outputId": "d0d73dee-f2fc-4e25-a31a-01523df65b27"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\sadiq\\anaconda3\\envs\\tensorProject\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        }
      ],
      "source": [
        "# create a new logistic regression model with the best hyperparameters\n",
        "best_lr = LogisticRegression(**best_params)\n",
        "\n",
        "# train the model with the entire training set\n",
        "best_lr.fit(bag_of_words, y_train)\n",
        "\n",
        "lr_pred_best = best_lr.predict(vect.transform(lemma_process_test))\n",
        "precision_lr_best = precision_score(y_test, lr_pred_best, average='macro')\n",
        "recall_lr_best = recall_score(y_test, lr_pred_best, average='macro')\n",
        "f1_lr_best = f1_score(y_test, lr_pred_best, average='macro')\n",
        "acc_lr_best = accuracy_score(y_test, lr_pred_best)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eJcqK83xWg7u",
        "outputId": "280803d2-be1e-4c0e-8c66-ef85147c2b30"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Logistic Regression CV: \n",
            "Precision: 0.51\n",
            "Recall: 0.42\n",
            "F1-score: 0.45\n",
            "Accuracy: 0.70\n"
          ]
        }
      ],
      "source": [
        "print('Logistic Regression CV: ')\n",
        "print('Precision: {:.2f}'.format(precision_lr_best))\n",
        "print('Recall: {:.2f}'.format(recall_lr_best))\n",
        "print('F1-score: {:.2f}'.format(f1_lr_best))\n",
        "print('Accuracy: {:.2f}'.format(acc_lr_best))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-PfLozLLWg7v"
      },
      "outputs": [],
      "source": [
        "y_final = best_lr.predict(vect.transform(lemma_process_test_final))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dQp-lgApWg7w"
      },
      "outputs": [],
      "source": [
        "final_submission['overall'] = y_final # save the labels for your model to csv file, you willl use this for you Kaggle competition submission\n",
        "\n",
        "final_submission.to_csv('final_submission.csv', index=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EOLG2SrcWg7x"
      },
      "source": [
        "##### Naive Bayes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mixx10IlWg7y"
      },
      "outputs": [],
      "source": [
        "# Train and evaluate a Naive Bayes classifier\n",
        "nb = MultinomialNB()\n",
        "nb.fit(bag_of_words, y_train)\n",
        "y_pred_nb = nb.predict(vect.transform(lemma_process_test))\n",
        "precision_nb = precision_score(y_test, y_pred_nb, average='macro')\n",
        "recall_nb = recall_score(y_test, y_pred_nb, average='macro')\n",
        "f1_nb = f1_score(y_test, y_pred_nb, average='macro')\n",
        "acc_nb = accuracy_score(y_test, y_pred_nb)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uuSLoQfdWg7z",
        "outputId": "5f4abae1-41a7-4995-ddc5-ca0fcac3cc8e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Naive Bayes: \n",
            "Precision: 0.43\n",
            "Recall: 0.44\n",
            "F1-score: 0.42\n",
            "Accuracy: 0.66\n"
          ]
        }
      ],
      "source": [
        "print('Naive Bayes: ')\n",
        "print('Precision: {:.2f}'.format(precision_nb))\n",
        "print('Recall: {:.2f}'.format(recall_nb))\n",
        "print('F1-score: {:.2f}'.format(f1_nb))\n",
        "print('Accuracy: {:.2f}'.format(acc_nb))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8lgkBjOfWg70"
      },
      "source": [
        "Hyper-param tuning"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s4JCaZOPWg71",
        "outputId": "0db17421-7980-42dd-c2f9-fbfdfb1b1ebe"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Best hyperparameters:  {'alpha': 10, 'fit_prior': True}\n",
            "Best accuracy score:  0.6640325393599831\n"
          ]
        }
      ],
      "source": [
        "# create a Multinomial Naive Bayes classifier\n",
        "nb = MultinomialNB()\n",
        "\n",
        "# define the parameter grid to search over\n",
        "param_grid = {\n",
        "    'alpha': [0.001, 0.01, 0.1, 1, 10],\n",
        "    'fit_prior': [True, False]\n",
        "}\n",
        "\n",
        "# perform grid search to find the best hyperparameters\n",
        "grid_search = GridSearchCV(nb, param_grid, cv=5)\n",
        "grid_search.fit(bag_of_words, y_train)\n",
        "\n",
        "# print the best hyperparameters and accuracy score\n",
        "print(\"Best hyperparameters: \", grid_search.best_params_)\n",
        "print(\"Best accuracy score: \", grid_search.best_score_)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dxrFBMfAWg73"
      },
      "outputs": [],
      "source": [
        "# create a new logistic regression model with the best hyperparameters\n",
        "best_nb = MultinomialNB(**grid_search.best_params_)\n",
        "\n",
        "# train the model with the entire training set\n",
        "best_nb.fit(bag_of_words, y_train)\n",
        "\n",
        "nb_pred_best = best_nb.predict(vect.transform(lemma_process_test))\n",
        "precision_nb_best = precision_score(y_test, nb_pred_best, average='macro')\n",
        "recall_nb_best = recall_score(y_test, nb_pred_best, average='macro')\n",
        "f1_nb_best = f1_score(y_test, nb_pred_best, average='macro')\n",
        "acc_nb_best = accuracy_score(y_test, nb_pred_best)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rDMywQEfWg74",
        "outputId": "b35dbe98-55c3-4d0d-946a-0039f65d4b44"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Naive Bayes hyper-param tuning: \n",
            "Precision: 0.46\n",
            "Recall: 0.35\n",
            "F1-score: 0.37\n",
            "Accuracy: 0.67\n"
          ]
        }
      ],
      "source": [
        "print('Naive Bayes hyper-param tuning: ')\n",
        "print('Precision: {:.2f}'.format(precision_nb_best))\n",
        "print('Recall: {:.2f}'.format(recall_nb_best))\n",
        "print('F1-score: {:.2f}'.format(f1_nb_best))\n",
        "print('Accuracy: {:.2f}'.format(acc_nb_best))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yHGSVmE6Wg75"
      },
      "outputs": [],
      "source": [
        "save_output(best_nb, lemma_process_test_final, vect)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1h2V54vuWg75"
      },
      "source": [
        "##### Random forest classifier"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uIHIE_wiWg76"
      },
      "outputs": [],
      "source": [
        "rfc = RandomForestClassifier(random_state=42)\n",
        "\n",
        "# train the model with the entire training set\n",
        "rfc.fit(bag_of_words, y_train)\n",
        "\n",
        "rfc_pred_best = rfc.predict(vect.transform(lemma_process_test))\n",
        "precision_rfc_best = precision_score(y_test, rfc_pred_best, average='macro')\n",
        "recall_rfc_best = recall_score(y_test, rfc_pred_best, average='macro')\n",
        "f1_rfc_best = f1_score(y_test, rfc_pred_best, average='macro')\n",
        "acc_rfc_best = accuracy_score(y_test, rfc_pred_best)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v1uipFqBWg77",
        "outputId": "55d12b2d-8e05-4fe6-8725-11207bd581b9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "RFC: \n",
            "Precision: 0.63\n",
            "Recall: 0.27\n",
            "F1-score: 0.29\n",
            "Accuracy: 0.67\n"
          ]
        }
      ],
      "source": [
        "print('RFC: ')\n",
        "print('Precision: {:.2f}'.format(precision_rfc_best))\n",
        "print('Recall: {:.2f}'.format(recall_rfc_best))\n",
        "print('F1-score: {:.2f}'.format(f1_rfc_best))\n",
        "print('Accuracy: {:.2f}'.format(acc_rfc_best))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lLeeLd83Wg77"
      },
      "source": [
        "Hyper param tuning"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UmDpCSpNWg78",
        "outputId": "3349494b-9e9a-4b15-d2eb-59cc339f661c"
      },
      "outputs": [
        {
          "ename": "AttributeError",
          "evalue": "lower not found",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_24212\\1504230101.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[0mbest_model\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msearch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbest_estimator_\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 21\u001b[1;33m \u001b[0mrfc_pred_best\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbest_model\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvect\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlemma_process_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     22\u001b[0m \u001b[0mprecision_rfc_best\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mprecision_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrfc_pred_best\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maverage\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'macro'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[0mrecall_rfc_best\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrecall_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrfc_pred_best\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maverage\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'macro'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32mc:\\Users\\sayed\\anaconda3\\lib\\site-packages\\sklearn\\utils\\metaestimators.py\u001b[0m in \u001b[0;36m<lambda>\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    111\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    112\u001b[0m             \u001b[1;31m# lambda, but not partial, allows help() to work with update_wrapper\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 113\u001b[1;33m             \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mlambda\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# noqa\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    114\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    115\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32mc:\\Users\\sayed\\anaconda3\\lib\\site-packages\\sklearn\\pipeline.py\u001b[0m in \u001b[0;36mpredict\u001b[1;34m(self, X, **predict_params)\u001b[0m\n\u001b[0;32m    467\u001b[0m         \u001b[0mXt\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    468\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtransform\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_iter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mwith_final\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 469\u001b[1;33m             \u001b[0mXt\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtransform\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mXt\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    470\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msteps\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mXt\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mpredict_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    471\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32mc:\\Users\\sayed\\anaconda3\\lib\\site-packages\\sklearn\\feature_extraction\\text.py\u001b[0m in \u001b[0;36mtransform\u001b[1;34m(self, raw_documents)\u001b[0m\n\u001b[0;32m   1377\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1378\u001b[0m         \u001b[1;31m# use the same matrix-building strategy as fit_transform\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1379\u001b[1;33m         \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_count_vocab\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mraw_documents\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfixed_vocab\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1380\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbinary\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1381\u001b[0m             \u001b[0mX\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfill\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32mc:\\Users\\sayed\\anaconda3\\lib\\site-packages\\sklearn\\feature_extraction\\text.py\u001b[0m in \u001b[0;36m_count_vocab\u001b[1;34m(self, raw_documents, fixed_vocab)\u001b[0m\n\u001b[0;32m   1199\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mdoc\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mraw_documents\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1200\u001b[0m             \u001b[0mfeature_counter\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1201\u001b[1;33m             \u001b[1;32mfor\u001b[0m \u001b[0mfeature\u001b[0m \u001b[1;32min\u001b[0m \u001b[0manalyze\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdoc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1202\u001b[0m                 \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1203\u001b[0m                     \u001b[0mfeature_idx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mvocabulary\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mfeature\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32mc:\\Users\\sayed\\anaconda3\\lib\\site-packages\\sklearn\\feature_extraction\\text.py\u001b[0m in \u001b[0;36m_analyze\u001b[1;34m(doc, analyzer, tokenizer, ngrams, preprocessor, decoder, stop_words)\u001b[0m\n\u001b[0;32m    111\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    112\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mpreprocessor\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 113\u001b[1;33m             \u001b[0mdoc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpreprocessor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdoc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    114\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mtokenizer\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    115\u001b[0m             \u001b[0mdoc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdoc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32mc:\\Users\\sayed\\anaconda3\\lib\\site-packages\\sklearn\\feature_extraction\\text.py\u001b[0m in \u001b[0;36m_preprocess\u001b[1;34m(doc, accent_function, lower)\u001b[0m\n\u001b[0;32m     69\u001b[0m     \"\"\"\n\u001b[0;32m     70\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mlower\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 71\u001b[1;33m         \u001b[0mdoc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdoc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     72\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0maccent_function\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     73\u001b[0m         \u001b[0mdoc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0maccent_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdoc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32mc:\\Users\\sayed\\anaconda3\\lib\\site-packages\\scipy\\sparse\\_base.py\u001b[0m in \u001b[0;36m__getattr__\u001b[1;34m(self, attr)\u001b[0m\n\u001b[0;32m    769\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgetnnz\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    770\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 771\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mattr\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m\" not found\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    772\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    773\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mtranspose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxes\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;31mAttributeError\u001b[0m: lower not found"
          ]
        }
      ],
      "source": [
        "pipeline = Pipeline([\n",
        "    ('cv', CountVectorizer(min_df=15)),\n",
        "    ('rfc', RandomForestClassifier())\n",
        "])\n",
        "\n",
        "param_grid = {\n",
        "    'rfc__n_estimators': randint(100, 1000),\n",
        "    'rfc__max_depth': [10, 20, 30, 40, None],\n",
        "    'rfc__max_features': ['auto', 'sqrt'],\n",
        "    'rfc__min_samples_leaf': [1, 2, 4],\n",
        "    'rfc__min_samples_split': [2, 5, 10],\n",
        "    'rfc__bootstrap': [True, False]\n",
        "}\n",
        "\n",
        "\n",
        "search = RandomizedSearchCV(pipeline, param_distributions=param_grid, n_iter=20, cv=5, n_jobs=-1, random_state=42)\n",
        "search.fit(X_train, y_train)\n",
        "\n",
        "best_model = search.best_estimator_\n",
        "\n",
        "# rfc_pred_best = best_model.predict(vect.transform(lemma_process_test))\n",
        "# precision_rfc_best = precision_score(y_test, rfc_pred_best, average='macro')\n",
        "# recall_rfc_best = recall_score(y_test, rfc_pred_best, average='macro')\n",
        "# f1_rfc_best = f1_score(y_test, rfc_pred_best, average='macro')\n",
        "# acc_rfc_best = accuracy_score(y_test, rfc_pred_best)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9xkFBG_9Wg79",
        "outputId": "d2fc2429-8ad5-4053-f253-8fe6922944c1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy: 0.6507008031676753\n"
          ]
        }
      ],
      "source": [
        "accuracy = best_model.score(lemma_process_test, y_test)\n",
        "print(\"Accuracy:\", accuracy)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_ilrBoFLWg7-"
      },
      "outputs": [],
      "source": [
        "# save_output(best_nb, lemma_process_test_final, vect)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mjo_1IolWg7_"
      },
      "source": [
        "### Tf-idf vectorization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JLaAxsNHWg7_"
      },
      "outputs": [],
      "source": [
        "vectorizer = TfidfVectorizer(min_df=15)\n",
        "\n",
        "tfidf_representation_train = vectorizer.fit_transform(lemma_process_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4wbR269NWg8A",
        "outputId": "2b90259d-414c-4590-b85a-a75a5f07e556"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\sayed\\anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n",
            "  warnings.warn(msg, category=FutureWarning)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "         aa  aaa  aac   ab  abandoned  abc  abdomen  abdominal  abec  abf  \\\n",
            "0       0.0  0.0  0.0  0.0        0.0  0.0      0.0        0.0   0.0  0.0   \n",
            "1       0.0  0.0  0.0  0.0        0.0  0.0      0.0        0.0   0.0  0.0   \n",
            "2       0.0  0.0  0.0  0.0        0.0  0.0      0.0        0.0   0.0  0.0   \n",
            "3       0.0  0.0  0.0  0.0        0.0  0.0      0.0        0.0   0.0  0.0   \n",
            "4       0.0  0.0  0.0  0.0        0.0  0.0      0.0        0.0   0.0  0.0   \n",
            "...     ...  ...  ...  ...        ...  ...      ...        ...   ...  ...   \n",
            "177789  0.0  0.0  0.0  0.0        0.0  0.0      0.0        0.0   0.0  0.0   \n",
            "177790  0.0  0.0  0.0  0.0        0.0  0.0      0.0        0.0   0.0  0.0   \n",
            "177791  0.0  0.0  0.0  0.0        0.0  0.0      0.0        0.0   0.0  0.0   \n",
            "177792  0.0  0.0  0.0  0.0        0.0  0.0      0.0        0.0   0.0  0.0   \n",
            "177793  0.0  0.0  0.0  0.0        0.0  0.0      0.0        0.0   0.0  0.0   \n",
            "\n",
            "        ...  zipties   zk  zombie  zone  zoom  zoomed  zooming   zt  zumba  \\\n",
            "0       ...      0.0  0.0     0.0   0.0   0.0     0.0      0.0  0.0    0.0   \n",
            "1       ...      0.0  0.0     0.0   0.0   0.0     0.0      0.0  0.0    0.0   \n",
            "2       ...      0.0  0.0     0.0   0.0   0.0     0.0      0.0  0.0    0.0   \n",
            "3       ...      0.0  0.0     0.0   0.0   0.0     0.0      0.0  0.0    0.0   \n",
            "4       ...      0.0  0.0     0.0   0.0   0.0     0.0      0.0  0.0    0.0   \n",
            "...     ...      ...  ...     ...   ...   ...     ...      ...  ...    ...   \n",
            "177789  ...      0.0  0.0     0.0   0.0   0.0     0.0      0.0  0.0    0.0   \n",
            "177790  ...      0.0  0.0     0.0   0.0   0.0     0.0      0.0  0.0    0.0   \n",
            "177791  ...      0.0  0.0     0.0   0.0   0.0     0.0      0.0  0.0    0.0   \n",
            "177792  ...      0.0  0.0     0.0   0.0   0.0     0.0      0.0  0.0    0.0   \n",
            "177793  ...      0.0  0.0     0.0   0.0   0.0     0.0      0.0  0.0    0.0   \n",
            "\n",
            "        zytel  \n",
            "0         0.0  \n",
            "1         0.0  \n",
            "2         0.0  \n",
            "3         0.0  \n",
            "4         0.0  \n",
            "...       ...  \n",
            "177789    0.0  \n",
            "177790    0.0  \n",
            "177791    0.0  \n",
            "177792    0.0  \n",
            "177793    0.0  \n",
            "\n",
            "[177794 rows x 13754 columns]\n"
          ]
        }
      ],
      "source": [
        "# Convert the sparse matrix to a dense matrix and print the output\n",
        "temp_df = pd.DataFrame(tfidf_representation_train.todense(), columns=vectorizer.get_feature_names())\n",
        "print(temp_df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ALkRItBoWg8B"
      },
      "outputs": [],
      "source": [
        "process_test = []\n",
        "for review in X_test:\n",
        "    process_test.append(process_text(review))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9e4x6OKBWg8B"
      },
      "outputs": [],
      "source": [
        "lemma_process_test = []\n",
        "for review in process_test:\n",
        "    lemma_process_test.append(lemmatize(review))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HpHtEQnbWg8C"
      },
      "source": [
        "##### Logistic Regression"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SH8KYLUmWg8D"
      },
      "outputs": [],
      "source": [
        "# Train and evaluate a logistic regression classifier\n",
        "lr = LogisticRegression(max_iter=1000)\n",
        "lr.fit(tfidf_representation_train, y_train)\n",
        "lr_pred = lr.predict(vectorizer.transform(lemma_process_test))\n",
        "precision_lr = precision_score(y_test, lr_pred, average='macro')\n",
        "recall_lr = recall_score(y_test, lr_pred, average='macro')\n",
        "f1_lr = f1_score(y_test, lr_pred, average='macro')\n",
        "acc_lr = accuracy_score(y_test, lr_pred)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4pfO6e6_Wg8E",
        "outputId": "7cf7c186-a68f-4661-e149-2e53981d37cb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Logistic Regression: \n",
            "Precision: 0.54\n",
            "Recall: 0.41\n",
            "F1-score: 0.45\n",
            "Accuracy: 0.70\n"
          ]
        }
      ],
      "source": [
        "print('Logistic Regression: ')\n",
        "print('Precision: {:.2f}'.format(precision_lr))\n",
        "print('Recall: {:.2f}'.format(recall_lr))\n",
        "print('F1-score: {:.2f}'.format(f1_lr))\n",
        "print('Accuracy: {:.2f}'.format(acc_lr))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NIlly9YhWg8F"
      },
      "source": [
        "Hyper param tuning"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qJI1fkBUWg8F",
        "outputId": "675ccce8-fbc7-4ab7-84ff-bb703d495745"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\sayed\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:372: FitFailedWarning: \n",
            "215 fits failed out of a total of 500.\n",
            "The score on these train-test partitions for these parameters will be set to nan.\n",
            "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
            "\n",
            "Below are more details about the failures:\n",
            "--------------------------------------------------------------------------------\n",
            "215 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"c:\\Users\\sayed\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"c:\\Users\\sayed\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1461, in fit\n",
            "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
            "  File \"c:\\Users\\sayed\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 447, in _check_solver\n",
            "    raise ValueError(\n",
            "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
            "\n",
            "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
            "c:\\Users\\sayed\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:969: UserWarning: One or more of the test scores are non-finite: [       nan 0.69667707        nan        nan 0.69154191 0.6963171  0.69400544 0.69119881 0.69412355 0.63438024 0.69657019        nan        nan        nan 0.69602463        nan        nan 0.69401669 0.6943879         nan        nan 0.69502347 0.69329113 0.69495597        nan 0.69656457        nan 0.6946635  0.68572618 0.69586151 0.69490536 0.6952597  0.69513033 0.68450004 0.69365672 0.69613149 0.69423604 0.69647458        nan        nan 0.6957659  0.69506284 0.69635084        nan        nan        nan 0.69320114 0.69602462        nan 0.69696391        nan 0.69500096        nan        nan 0.69463539        nan 0.6963621  0.69446102        nan        nan 0.69528781        nan        nan        nan        nan 0.69500659        nan        nan 0.69642397        nan        nan        nan 0.69649146        nan 0.69617086 0.6944104  0.69439353 0.69567591 0.69613149 0.6929199  0.693353   0.69626085        nan        nan        nan 0.69637334        nan        nan 0.69560278        nan 0.69590651 0.69469725        nan 0.69681768 0.69670518        nan        nan 0.69649145 0.69586152 0.68528747]\n",
            "  warnings.warn(\n",
            "c:\\Users\\sayed\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        }
      ],
      "source": [
        "# define your logistic regression model\n",
        "lr_cv = LogisticRegression()\n",
        "\n",
        "# define the hyperparameters you want to tune and their range of values\n",
        "hyperparameters = {\n",
        "    'C': uniform(loc=0, scale=4),\n",
        "    'penalty': ['l1', 'l2']\n",
        "}\n",
        "\n",
        "# define your hyperparameter tuning process\n",
        "clf = RandomizedSearchCV(\n",
        "    lr_cv, \n",
        "    hyperparameters, \n",
        "    n_iter=100, \n",
        "    cv=5, \n",
        "    random_state=42, \n",
        "    n_jobs=-1\n",
        ")\n",
        "\n",
        "# fit the hyperparameter tuning process to your data\n",
        "clf.fit(tfidf_representation_train, y_train)\n",
        "\n",
        "# get the best hyperparameters and the best score achieved\n",
        "best_params = clf.best_params_\n",
        "best_score = clf.best_score_\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dDSQCBceWg8G",
        "outputId": "247c1507-260f-45b9-d28e-900e8236477b"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\sayed\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        }
      ],
      "source": [
        "# create a new logistic regression model with the best hyperparameters\n",
        "best_lr = LogisticRegression(**best_params)\n",
        "\n",
        "# train the model with the entire training set\n",
        "best_lr.fit(tfidf_representation_train, y_train)\n",
        "\n",
        "lr_pred_best = best_lr.predict(vectorizer.transform(lemma_process_test))\n",
        "precision_lr_best = precision_score(y_test, lr_pred_best, average='macro')\n",
        "recall_lr_best = recall_score(y_test, lr_pred_best, average='macro')\n",
        "f1_lr_best = f1_score(y_test, lr_pred_best, average='macro')\n",
        "acc_lr_best = accuracy_score(y_test, lr_pred_best)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JRmq0G0sWg8I",
        "outputId": "d4d611de-4cbe-4436-dccc-42e3f2724eda"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Logistic Regression: \n",
            "Precision: 0.53\n",
            "Recall: 0.40\n",
            "F1-score: 0.44\n",
            "Accuracy: 0.70\n"
          ]
        }
      ],
      "source": [
        "print('Logistic Regression: ')\n",
        "print('Precision: {:.2f}'.format(precision_lr_best))\n",
        "print('Recall: {:.2f}'.format(recall_lr_best))\n",
        "print('F1-score: {:.2f}'.format(f1_lr_best))\n",
        "print('Accuracy: {:.2f}'.format(acc_lr_best))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m0GiVYYPWg8I"
      },
      "source": [
        "bi-gram"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_7JD6rDKWg8J"
      },
      "outputs": [],
      "source": [
        "vectorizer = TfidfVectorizer(min_df=15, ngram_range=(2, 2))\n",
        "\n",
        "tfidf_representation_train = vectorizer.fit_transform(lemma_process_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lUkLLoDTWg8J",
        "outputId": "0ecb0c19-c17d-43ea-96b5-b74f3c9a24d3"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\sayed\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:372: FitFailedWarning: \n",
            "215 fits failed out of a total of 500.\n",
            "The score on these train-test partitions for these parameters will be set to nan.\n",
            "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
            "\n",
            "Below are more details about the failures:\n",
            "--------------------------------------------------------------------------------\n",
            "215 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"c:\\Users\\sayed\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"c:\\Users\\sayed\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1461, in fit\n",
            "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
            "  File \"c:\\Users\\sayed\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 447, in _check_solver\n",
            "    raise ValueError(\n",
            "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
            "\n",
            "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
            "c:\\Users\\sayed\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:969: UserWarning: One or more of the test scores are non-finite: [       nan 0.67802065        nan        nan 0.663037   0.67902743 0.67559649 0.66267141 0.67341418 0.63420588 0.67839186        nan        nan        nan 0.67582709        nan        nan 0.67532652 0.67744694        nan        nan 0.67829624 0.67169311 0.67684513        nan 0.67916805        nan 0.67566961 0.65410532 0.67822875 0.67494405 0.67768318 0.67728945 0.65250797 0.67302611 0.67813875 0.67539963 0.6790668         nan        nan 0.67880807 0.67702512 0.67889244        nan        nan        nan 0.67171563 0.67836936        nan 0.67898806        nan 0.67625456        nan        nan 0.67536588        nan 0.6793649  0.67560774        nan        nan 0.67395414        nan        nan        nan        nan 0.67343106        nan        nan 0.6794099         nan        nan        nan 0.6785831         nan 0.67750882 0.6753659  0.67539401 0.67724446 0.67799815 0.67327358 0.67332981 0.67919615        nan        nan        nan 0.6787237         nan        nan 0.67424098        nan 0.67807127 0.67671576        nan 0.6793874  0.67946052        nan        nan 0.67876308 0.67681139 0.65343038]\n",
            "  warnings.warn(\n",
            "c:\\Users\\sayed\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        }
      ],
      "source": [
        "# define your logistic regression model\n",
        "lr_cv = LogisticRegression()\n",
        "\n",
        "# define the hyperparameters you want to tune and their range of values\n",
        "hyperparameters = {\n",
        "    'C': uniform(loc=0, scale=4),\n",
        "    'penalty': ['l1', 'l2']\n",
        "}\n",
        "\n",
        "# define your hyperparameter tuning process\n",
        "clf = RandomizedSearchCV(\n",
        "    lr_cv, \n",
        "    hyperparameters, \n",
        "    n_iter=100, \n",
        "    cv=5, \n",
        "    random_state=42, \n",
        "    n_jobs=-1\n",
        ")\n",
        "\n",
        "# fit the hyperparameter tuning process to your data\n",
        "clf.fit(tfidf_representation_train, y_train)\n",
        "\n",
        "# get the best hyperparameters and the best score achieved\n",
        "best_params = clf.best_params_\n",
        "best_score = clf.best_score_\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YYL82MlWWg8K",
        "outputId": "9213c51b-6d15-4653-8f7a-e42156165e13"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\sayed\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        }
      ],
      "source": [
        "# create a new logistic regression model with the best hyperparameters\n",
        "best_lr = LogisticRegression(**best_params)\n",
        "\n",
        "# train the model with the entire training set\n",
        "best_lr.fit(tfidf_representation_train, y_train)\n",
        "\n",
        "lr_pred_best = best_lr.predict(vectorizer.transform(lemma_process_test))\n",
        "precision_lr_best = precision_score(y_test, lr_pred_best, average='macro')\n",
        "recall_lr_best = recall_score(y_test, lr_pred_best, average='macro')\n",
        "f1_lr_best = f1_score(y_test, lr_pred_best, average='macro')\n",
        "acc_lr_best = accuracy_score(y_test, lr_pred_best)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wLR2K1b5Wg8L",
        "outputId": "4e7a4b18-7808-41e6-dc28-175c046a2801"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Logistic Regression: \n",
            "Precision: 0.56\n",
            "Recall: 0.36\n",
            "F1-score: 0.40\n",
            "Accuracy: 0.69\n"
          ]
        }
      ],
      "source": [
        "print('Logistic Regression: ')\n",
        "print('Precision: {:.2f}'.format(precision_lr_best))\n",
        "print('Recall: {:.2f}'.format(recall_lr_best))\n",
        "print('F1-score: {:.2f}'.format(f1_lr_best))\n",
        "print('Accuracy: {:.2f}'.format(acc_lr_best))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g9R9LgdMWg8M"
      },
      "source": [
        "##### Naive Bayes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8e7-6xhKWg8N"
      },
      "outputs": [],
      "source": [
        "# Train and evaluate a Naive Bayes classifier\n",
        "nb = MultinomialNB()\n",
        "nb.fit(tfidf_representation_train, y_train)\n",
        "y_pred_nb = nb.predict(vectorizer.transform(lemma_process_test))\n",
        "precision_nb = precision_score(y_test, y_pred_nb, average='macro')\n",
        "recall_nb = recall_score(y_test, y_pred_nb, average='macro')\n",
        "f1_nb = f1_score(y_test, y_pred_nb, average='macro')\n",
        "acc_nb = accuracy_score(y_test, y_pred_nb)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cUsShC0nWg8N",
        "outputId": "cc20aae8-d0e4-47fd-9b93-ab0bc70f287b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Naive Bayes: \n",
            "Precision: 0.69\n",
            "Recall: 0.24\n",
            "F1-score: 0.24\n",
            "Accuracy: 0.66\n"
          ]
        }
      ],
      "source": [
        "print('Naive Bayes: ')\n",
        "print('Precision: {:.2f}'.format(precision_nb))\n",
        "print('Recall: {:.2f}'.format(recall_nb))\n",
        "print('F1-score: {:.2f}'.format(f1_nb))\n",
        "print('Accuracy: {:.2f}'.format(acc_nb))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lokgbWkmWg8O"
      },
      "source": [
        "Hyper-param tuning"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MfHGPCXbWg8O",
        "outputId": "255bb8a4-2db9-40c5-c2e2-31c2e2938065"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Best hyperparameters:  {'alpha': 0.1, 'fit_prior': True}\n",
            "Best accuracy score:  0.6727223734702079\n"
          ]
        }
      ],
      "source": [
        "# create a Multinomial Naive Bayes classifier\n",
        "nb = MultinomialNB()\n",
        "\n",
        "# define the parameter grid to search over\n",
        "param_grid = {\n",
        "    'alpha': [0.001, 0.01, 0.1, 1, 10],\n",
        "    'fit_prior': [True, False]\n",
        "}\n",
        "\n",
        "# perform grid search to find the best hyperparameters\n",
        "grid_search = GridSearchCV(nb, param_grid, cv=5)\n",
        "grid_search.fit(tfidf_representation_train, y_train)\n",
        "\n",
        "# print the best hyperparameters and accuracy score\n",
        "print(\"Best hyperparameters: \", grid_search.best_params_)\n",
        "print(\"Best accuracy score: \", grid_search.best_score_)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kbD_RM6wWg8P"
      },
      "outputs": [],
      "source": [
        "# create a new logistic regression model with the best hyperparameters\n",
        "best_nb = MultinomialNB(**grid_search.best_params_)\n",
        "\n",
        "# train the model with the entire training set\n",
        "best_nb.fit(tfidf_representation_train, y_train)\n",
        "\n",
        "nb_pred_best = best_nb.predict(vectorizer.transform(lemma_process_test))\n",
        "precision_nb_best = precision_score(y_test, nb_pred_best, average='macro')\n",
        "recall_nb_best = recall_score(y_test, nb_pred_best, average='macro')\n",
        "f1_nb_best = f1_score(y_test, nb_pred_best, average='macro')\n",
        "acc_nb_best = accuracy_score(y_test, nb_pred_best)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dWKlK7mnWg8Q",
        "outputId": "071b3c77-78c6-43db-bf38-041133aa0b9b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Naive Bayes hyper-param tuning: \n",
            "Precision: 0.55\n",
            "Recall: 0.30\n",
            "F1-score: 0.32\n",
            "Accuracy: 0.68\n"
          ]
        }
      ],
      "source": [
        "print('Naive Bayes hyper-param tuning: ')\n",
        "print('Precision: {:.2f}'.format(precision_nb_best))\n",
        "print('Recall: {:.2f}'.format(recall_nb_best))\n",
        "print('F1-score: {:.2f}'.format(f1_nb_best))\n",
        "print('Accuracy: {:.2f}'.format(acc_nb_best))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Rnocc6bPWg8Q"
      },
      "outputs": [],
      "source": [
        "test = pd.read_csv('test.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5Ho7-uFQWg8R",
        "outputId": "f635b7c9-78cd-4744-d654-e27f1397fc56"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>Review</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>Bought for a Smith and Wesson M&amp;P15 fits perfe...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>Beware of the charts listed on Butler Creek's ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>I've only used this once to sight in a scope. ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>I need more of these!!! This thing makes shoot...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>Grabber Outdoors Original Space Brand Sportsma...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   id                                             Review\n",
              "0   0  Bought for a Smith and Wesson M&P15 fits perfe...\n",
              "1   1  Beware of the charts listed on Butler Creek's ...\n",
              "2   2  I've only used this once to sight in a scope. ...\n",
              "3   3  I need more of these!!! This thing makes shoot...\n",
              "4   4  Grabber Outdoors Original Space Brand Sportsma..."
            ]
          },
          "execution_count": 24,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "test.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Vector space model bi-gram Tf-idf"
      ],
      "metadata": {
        "id": "nCof5fABmI7J"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bUe0IJSiWg8S",
        "outputId": "42563c9c-07f9-4c9c-b38e-ba8905625755"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[\"This a really cool (but time-tested) design. The carbon steel blade gets really sharp but does require maintenance from time to time. I oiled the locking screw-top and blade; after that it opens easily. I've been using mine for a couple of months now and am not disappointed. It's a solid knife and at an affordable price. Nice knife!\",\n",
              " \"I liked the first pair so well I bought several more. I have found it's usually worthwhile to buy the higher priced products in the long run and these socks are no exception. Better comfort, moisture wicking, arch support, etc. My go to sock in hot weather. I use these road, cx, & single track cycling Excellent\",\n",
              " \"I took them to the range to put them to the test. When you adjust the volume you can hear people talking without a problem and the shots are muffled. I tried them today mowing the lawn while having my music going. The sound of the music was really good. I was a little shocked.  Overall a great buy. I just ordered a second set for my wife. I will say it's a 4 out 5 for hearing protection. Go for it! Great Sound Protection\",\n",
              " \"What can you say about a yoga block?  These are solid and sturdy - not a &#34;name-brand&#34;. so I feared it would be less dense, but it's just the same as the higher priced blocks.  Supportive when you need them, light and easy to store when you don't. Less expensive but good quality blocks\",\n",
              " \"After reading many reviews I decided on this light.  I am very satisfied after a few days of use.  It is very bright and easy to install. I can't comment on the battery life yet but was happy it came with batteries. very good light for the money\"]"
            ]
          },
          "execution_count": 74,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "reviews = train['Review'].tolist()\n",
        "\n",
        "reviews[:5]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sxOWVQDSWg8S",
        "outputId": "5eeab2a3-3289-4706-c9e2-630fa56b15f4"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "from sklearn.decomposition import PCA\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Create TfidfVectorizer object with bigram feature extraction\n",
        "vectorizer = TfidfVectorizer(ngram_range=(2, 2))\n",
        "\n",
        "# Fit the vectorizer to the text data and transform the text data into bigram tf-idf features\n",
        "bigram_tfidf_features = vectorizer.fit_transform(reviews[:5])\n",
        "\n",
        "# Print the bigram tf-idf features                                                                                                              \n",
        "# print(bigram_tfidf_features.toarray())\n",
        "\n",
        "# Convert the sparse matrix to a dense matrix and print the output\n",
        "# df = pd.DataFrame(bigram_tfidf_features.todense(), columns=vectorizer.get_feature_names())\n",
        "# print(df)\n",
        "\n",
        "# Apply PCA to reduce the dimensionality of the feature space to two dimensions\n",
        "pca = PCA(n_components=2)\n",
        "bigram_tfidf_features_pca = pca.fit_transform(bigram_tfidf_features.toarray())\n",
        "\n",
        "# Plot the data points on a scatter plot\n",
        "plt.scatter(bigram_tfidf_features_pca[:, 0], bigram_tfidf_features_pca[:, 1])\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zmxvji7dWg8T"
      },
      "outputs": [],
      "source": [
        "# ! pip install mglearn\n",
        "# ! pip install joblib==1.1.0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0vr8R7xkWg8U"
      },
      "outputs": [],
      "source": [
        "# from sklearn.model_selection import GridSearchCV\n",
        "# from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "# from sklearn.pipeline import make_pipeline\n",
        "# import mglearn as mglearn\n",
        "\n",
        "# pipe = make_pipeline(TfidfVectorizer(min_df=5),\n",
        "#                      LogisticRegression())\n",
        "\n",
        "# param_grid = {'logisticregression__C': [0.001, 0.01, 0.1, 1, 10]}\n",
        "\n",
        "# grid = GridSearchCV(pipe, param_grid, cv=5)\n",
        "\n",
        "# grid.fit(X_train, y_train)\n",
        "\n",
        "# vectorizer = grid.best_estimator_.named_steps[\"tfidfvectorizer\"]\n",
        "\n",
        "# feature_names = np.array(vectorizer.get_feature_names_out())\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# mglearn.tools.visualize_coefficients(\n",
        "#     grid.best_estimator_.named_steps[\"logisticregression\"].coef_,\n",
        "#     feature_names, n_top_features=40)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GAjao_znWg8U"
      },
      "source": [
        "# Save best output"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0TPff_PNWg8V"
      },
      "outputs": [],
      "source": [
        "def save_output(model, test_set, vector):\n",
        "    y_final = model.predict(vector.transform(test_set))\n",
        "    final_submission=pd.read_csv('sample_submission.csv')\n",
        "    final_submission['overall'] = y_final # save the labels for your model to csv file, you willl use this for you Kaggle competition submission\n",
        "    final_submission.to_csv('final_submission.csv', index=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5YnXF9LbWg8V"
      },
      "source": [
        "# Sequencial models"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Load data"
      ],
      "metadata": {
        "id": "i3ijmet6hYkc"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IKLcPa65Wg8W"
      },
      "outputs": [],
      "source": [
        "df = pd.read_csv('train.csv')\n",
        "\n",
        "X = df['Review']\n",
        "y= df['overall']"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### One-hot encoding labels"
      ],
      "metadata": {
        "id": "0rTO8shChfgy"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bUvvn8STWg8X"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "# Define the list of labels\n",
        "labels = y\n",
        "\n",
        "# Create a dictionary to map each label to an integer\n",
        "label_map = {label: i for i, label in enumerate(set(labels))}\n",
        "\n",
        "# Convert the list of labels to integer labels\n",
        "int_labels = [label_map[label] for label in labels]\n",
        "\n",
        "# Convert the integer labels to one-hot encoding\n",
        "one_hot_labels = to_categorical(int_labels, num_classes=len(set(labels)))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Text as a sequence"
      ],
      "metadata": {
        "id": "-j0N5wyThawC"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "avshC5BzWg8Y"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "tokenizer = Tokenizer()\n",
        "tokenizer.fit_on_texts(X)\n",
        "word_index = tokenizer.word_index\n",
        "sequences = tokenizer.texts_to_sequences(X)\n",
        "data = pad_sequences(sequences)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Train-test split"
      ],
      "metadata": {
        "id": "smQTTxB1hjbU"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mJScOXjwWg8Z"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(data, one_hot_labels, test_size=0.2, random_state=42)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Build LSTM model"
      ],
      "metadata": {
        "id": "cxiR6LphhmsG"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fAg12wZTWg8a"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Embedding, LSTM, Dense\n",
        "# Define the model architecture\n",
        "model = Sequential()\n",
        "model.add(Embedding(len(word_index)+1, 64))\n",
        "model.add(LSTM(64))\n",
        "model.add(Dense(5, activation='softmax'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YH3fqNXpWg8b",
        "outputId": "caa71871-d0b7-4a95-b0da-97670a16dc7c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "5557/5557 [==============================] - 14026s 3s/step - loss: 0.7071 - accuracy: 0.7125\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x1a1272ba760>"
            ]
          },
          "execution_count": 46,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Train the model\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "model.fit(X_train, np.array(y_train), batch_size=32, epochs=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Evaluate model"
      ],
      "metadata": {
        "id": "z3G3Vt9ahrrk"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "htFAoN3ZWg8c",
        "outputId": "0ec86193-386a-43a3-8c0a-08c93079e996"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy: 72.759789\n"
          ]
        }
      ],
      "source": [
        "# Evaluate the model\n",
        "loss, accuracy = model.evaluate(X_test, np.array(y_test), verbose=0)\n",
        "print('Accuracy: %f' % (accuracy*100))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Run model on Test set save output to final_submission.csv"
      ],
      "metadata": {
        "id": "6EfoKVU1hxgt"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s6TOogLWWg8c"
      },
      "outputs": [],
      "source": [
        "labels = y\n",
        "\n",
        "# Create a dictionary to map each label to an integer\n",
        "label_map = {label: i for i, label in enumerate(set(labels))}\n",
        "\n",
        "# Create the label_map_inv dictionary\n",
        "label_map_inv = {v: k for k, v in label_map.items()}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h0ay06FOWg8d",
        "outputId": "6b9731f8-a508-4520-9e8a-fa325f57c294"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2316/2316 [==============================] - 643s 278ms/step\n"
          ]
        }
      ],
      "source": [
        "test_sequences = tokenizer.texts_to_sequences(test['Review'])\n",
        "test_data = pad_sequences(test_sequences, maxlen=data.shape[1])\n",
        "\n",
        "\n",
        "# Use the model to predict the categories of the test texts\n",
        "predicted_probs = model.predict(test_data)\n",
        "predicted_labels = np.argmax(predicted_probs, axis=1)\n",
        "predicted_categories = [label_map_inv[label] for label in predicted_labels]\n",
        "\n",
        "\n",
        "y_final = predicted_categories\n",
        "final_submission=pd.read_csv('sample_submission.csv')\n",
        "final_submission['overall'] = y_final # save the labels for your model to csv file, you willl use this for you Kaggle competition submission\n",
        "final_submission.to_csv('final_submission.csv', index=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Topic Modelling for five star ratings"
      ],
      "metadata": {
        "id": "59GHR6hghDHp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import gensim\n",
        "import pyLDAvis.gensim_models as gensimvis\n",
        "import pyLDAvis\n",
        "\n",
        "stopwords = set(gensim.parsing.preprocessing.STOPWORDS)\n",
        "tokenized_text = [[word for word in gensim.utils.simple_preprocess(doc) if word not in stopwords] for doc in df[df['overall']==5]['Review']]\n",
        "dictionary = gensim.corpora.Dictionary(tokenized_text)\n",
        "doc_term_matrix = [dictionary.doc2bow(doc) for doc in tokenized_text]\n",
        "lda_model = gensim.models.ldamodel.LdaModel(doc_term_matrix, num_topics=10, id2word=dictionary, passes=10)\n",
        "\n",
        "# Create visualization\n",
        "lda_display = gensimvis.prepare(lda_model, doc_term_matrix, dictionary)\n",
        "pyLDAvis.display(lda_display)\n"
      ],
      "metadata": {
        "id": "g61IpkS7Q2Fq",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 951
        },
        "outputId": "6711de47-b739-47ad-d04c-6fb04aaea9c5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n",
            "/usr/local/lib/python3.9/dist-packages/pyLDAvis/_prepare.py:243: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.\n",
            "  default_term_info = default_term_info.sort_values(\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "<link rel=\"stylesheet\" type=\"text/css\" href=\"https://cdn.jsdelivr.net/gh/bmabey/pyLDAvis@3.4.0/pyLDAvis/js/ldavis.v1.0.0.css\">\n",
              "\n",
              "\n",
              "<div id=\"ldavis_el34491404573654022246424928385\" style=\"background-color:white;\"></div>\n",
              "<script type=\"text/javascript\">\n",
              "\n",
              "var ldavis_el34491404573654022246424928385_data = {\"mdsDat\": {\"x\": [0.021525781970895993, 0.13991998995661206, 0.06143524116421839, 0.07003635132280525, -0.0062298346890289685, 0.014228672551983958, 0.043456593619004225, 0.008645668534348548, -0.0019557349582920796, -0.3510627294725479], \"y\": [-0.17044583889203122, -0.1218224481107366, -0.0024275512259467422, -0.07222743361573075, 0.03757007518463544, 0.1240772083872666, 0.2360315425128528, 0.005075045074901697, 0.004327808462541293, -0.040158407777753063], \"topics\": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10], \"cluster\": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1], \"Freq\": [14.82350991830797, 12.227670104191635, 11.205175978060128, 11.171298860151724, 10.219162152296072, 10.198531934004073, 9.497606205442235, 8.364212349543013, 7.785368952939789, 4.507463545063375]}, \"tinfo\": {\"Term\": [\"knife\", \"light\", \"bike\", \"price\", \"great\", \"quality\", \"bag\", \"product\", \"water\", \"blade\", \"scope\", \"good\", \"bottle\", \"sharp\", \"gun\", \"case\", \"sight\", \"grip\", \"fit\", \"bright\", \"carry\", \"holster\", \"works\", \"wear\", \"pack\", \"comfortable\", \"knives\", \"rifle\", \"tool\", \"steel\", \"watch\", \"bands\", \"exercises\", \"program\", \"ups\", \"video\", \"customer\", \"lube\", \"compass\", \"step\", \"videos\", \"lee\", \"roller\", \"fitness\", \"muscles\", \"steps\", \"website\", \"die\", \"sent\", \"heart\", \"com\", \"eat\", \"watching\", \"dvd\", \"date\", \"cleats\", \"hitch\", \"cardio\", \"watches\", \"information\", \"review\", \"weights\", \"read\", \"exercise\", \"reviews\", \"workout\", \"reading\", \"update\", \"ago\", \"based\", \"instructions\", \"workouts\", \"door\", \"time\", \"years\", \"weeks\", \"press\", \"ve\", \"ll\", \"amazon\", \"know\", \"set\", \"people\", \"started\", \"decided\", \"use\", \"try\", \"new\", \"day\", \"going\", \"thing\", \"think\", \"minutes\", \"work\", \"like\", \"need\", \"took\", \"want\", \"way\", \"got\", \"lot\", \"best\", \"sure\", \"product\", \"weight\", \"sling\", \"described\", \"cage\", \"hydration\", \"taurus\", \"xd\", \"awsome\", \"swivels\", \"recomend\", \"springfield\", \"bi\", \"sleek\", \"ga\", \"iwb\", \"rush\", \"troy\", \"havent\", \"compliments\", \"promptly\", \"magnetic\", \"voodoo\", \"shifter\", \"bracelets\", \"gi\", \"reccomend\", \"owning\", \"xdm\", \"dumbbell\", \"visor\", \"tweezers\", \"price\", \"prime\", \"quality\", \"cards\", \"seller\", \"product\", \"shipping\", \"beat\", \"money\", \"value\", \"great\", \"buy\", \"good\", \"looks\", \"item\", \"shipped\", \"arrived\", \"priced\", \"exactly\", \"expected\", \"deal\", \"worth\", \"works\", \"advertised\", \"recommend\", \"purchase\", \"cheap\", \"happy\", \"awesome\", \"nice\", \"bought\", \"products\", \"excellent\", \"highly\", \"love\", \"fast\", \"looking\", \"high\", \"like\", \"got\", \"fit\", \"perfect\", \"easy\", \"better\", \"best\", \"work\", \"use\", \"knife\", \"blade\", \"sharp\", \"knives\", \"sheath\", \"edge\", \"edc\", \"cutting\", \"razor\", \"blades\", \"spyderco\", \"sharpening\", \"sharpen\", \"kershaw\", \"ka\", \"machete\", \"gerber\", \"sharpener\", \"folder\", \"swiss\", \"serrated\", \"tasks\", \"mora\", \"axe\", \"scales\", \"tang\", \"bk\", \"assisted\", \"stone\", \"victorinox\", \"steel\", \"handle\", \"opening\", \"pocket\", \"cut\", \"hand\", \"wood\", \"open\", \"clip\", \"survival\", \"carry\", \"buck\", \"tool\", \"like\", \"box\", \"little\", \"good\", \"small\", \"great\", \"use\", \"grip\", \"solid\", \"quality\", \"nice\", \"best\", \"love\", \"better\", \"holster\", \"gloves\", \"socks\", \"shirt\", \"wearing\", \"shorts\", \"hat\", \"sweat\", \"yoga\", \"walking\", \"holsters\", \"xl\", \"clothes\", \"shirts\", \"cotton\", \"sock\", \"paddle\", \"lasts\", \"pairs\", \"compression\", \"iphone\", \"pool\", \"smart\", \"propane\", \"bite\", \"layer\", \"hip\", \"boots\", \"washing\", \"suit\", \"wear\", \"pants\", \"pair\", \"running\", \"comfortable\", \"warm\", \"skin\", \"feet\", \"soft\", \"worn\", \"leg\", \"fit\", \"head\", \"size\", \"glove\", \"material\", \"like\", \"hands\", \"large\", \"feel\", \"long\", \"love\", \"great\", \"fits\", \"perfect\", \"good\", \"ve\", \"nice\", \"bit\", \"little\", \"bought\", \"use\", \"day\", \"water\", \"bottle\", \"tent\", \"stove\", \"bottles\", \"pot\", \"backpacking\", \"sleeping\", \"cup\", \"fuel\", \"filter\", \"drink\", \"ice\", \"coffee\", \"boat\", \"cooking\", \"mouth\", \"nalgene\", \"hammock\", \"coleman\", \"stakes\", \"taste\", \"canteen\", \"cook\", \"drinking\", \"mattress\", \"camelbak\", \"solo\", \"boil\", \"burner\", \"camping\", \"food\", \"oz\", \"trip\", \"lid\", \"emergency\", \"rain\", \"rope\", \"camp\", \"hot\", \"heat\", \"hiking\", \"clean\", \"kit\", \"use\", \"pack\", \"great\", \"bag\", \"small\", \"easy\", \"little\", \"cold\", \"like\", \"plastic\", \"need\", \"stuff\", \"light\", \"works\", \"love\", \"bought\", \"good\", \"day\", \"scope\", \"sight\", \"sights\", \"rail\", \"dot\", \"laser\", \"bolt\", \"bipod\", \"bore\", \"wrench\", \"bolts\", \"mosin\", \"optics\", \"scopes\", \"optic\", \"mossberg\", \"crossbow\", \"nut\", \"rails\", \"grease\", \"receiver\", \"sighting\", \"picatinny\", \"arrows\", \"chamber\", \"sks\", \"weaver\", \"nagant\", \"riser\", \"reticle\", \"ar\", \"rings\", \"ak\", \"cleaning\", \"pin\", \"barrel\", \"screws\", \"rifle\", \"mount\", \"stock\", \"magpul\", \"zero\", \"screw\", \"tool\", \"mounted\", \"install\", \"utg\", \"red\", \"gun\", \"installed\", \"rifles\", \"easy\", \"works\", \"clean\", \"great\", \"use\", \"fit\", \"perfect\", \"perfectly\", \"need\", \"range\", \"nice\", \"like\", \"pouch\", \"mags\", \"magazines\", \"clips\", \"molle\", \"vest\", \"loading\", \"loader\", \"compartment\", \"shells\", \"zipper\", \"pouches\", \"maxpedition\", \"wallet\", \"zippers\", \"pen\", \"camera\", \"loops\", \"reel\", \"stack\", \"rig\", \"compartments\", \"buckle\", \"laptop\", \"flap\", \"storing\", \"zippered\", \"carabiner\", \"organized\", \"poncho\", \"keys\", \"velcro\", \"straps\", \"pockets\", \"bag\", \"case\", \"ammo\", \"belt\", \"load\", \"shell\", \"mag\", \"strap\", \"magazine\", \"pack\", \"carry\", \"room\", \"holder\", \"storage\", \"safe\", \"hold\", \"pocket\", \"carrying\", \"secure\", \"holds\", \"small\", \"fits\", \"fit\", \"extra\", \"gear\", \"use\", \"need\", \"great\", \"size\", \"perfect\", \"nice\", \"range\", \"inside\", \"little\", \"like\", \"easy\", \"bike\", \"ride\", \"rack\", \"seat\", \"road\", \"chain\", \"tire\", \"mat\", \"tires\", \"bikes\", \"helmet\", \"bicycle\", \"wheel\", \"pedals\", \"chair\", \"saddle\", \"brake\", \"tubes\", \"wheels\", \"brakes\", \"pedal\", \"shimano\", \"topeak\", \"levers\", \"flats\", \"psi\", \"basket\", \"trails\", \"stem\", \"fenders\", \"pump\", \"riding\", \"cable\", \"pads\", \"miles\", \"mountain\", \"tape\", \"rides\", \"tube\", \"bars\", \"bar\", \"frame\", \"easy\", \"stand\", \"old\", \"rear\", \"use\", \"great\", \"like\", \"good\", \"little\", \"ve\", \"need\", \"ball\", \"trigger\", \"targets\", \"pellets\", \"pellet\", \"balls\", \"bow\", \"bb\", \"golf\", \"crosman\", \"hogue\", \"hitting\", \"bbs\", \"hearing\", \"hits\", \"fps\", \"basketball\", \"baseball\", \"dumbbells\", \"muffs\", \"club\", \"ab\", \"shooters\", \"games\", \"gamo\", \"bat\", \"routine\", \"traction\", \"practicing\", \"buffer\", \"grips\", \"practice\", \"fun\", \"shoot\", \"shooting\", \"target\", \"grip\", \"game\", \"shot\", \"airsoft\", \"net\", \"shots\", \"hit\", \"ear\", \"gun\", \"accuracy\", \"range\", \"training\", \"accurate\", \"kids\", \"pistol\", \"air\", \"play\", \"great\", \"like\", \"feel\", \"use\", \"good\", \"better\", \"little\", \"easy\", \"makes\", \"love\", \"hand\", \"bright\", \"battery\", \"batteries\", \"lights\", \"dark\", \"lantern\", \"led\", \"eyes\", \"mode\", \"mirror\", \"visible\", \"goggles\", \"charger\", \"mask\", \"tail\", \"settings\", \"beam\", \"brightness\", \"plug\", \"lenses\", \"vision\", \"visibility\", \"sunglasses\", \"flashing\", \"headlight\", \"modes\", \"headlamp\", \"fog\", \"lamp\", \"usb\", \"light\", \"flash\", \"glasses\", \"night\", \"whistle\", \"charge\", \"lens\", \"switch\", \"flashlight\", \"power\", \"red\", \"setting\", \"green\", \"button\", \"unit\", \"use\", \"life\", \"low\", \"easy\", \"turn\", \"great\"], \"Freq\": [36525.0, 22059.0, 18490.0, 26034.0, 89496.0, 24594.0, 19634.0, 25917.0, 14771.0, 13103.0, 10506.0, 49965.0, 8909.0, 8657.0, 13411.0, 11068.0, 7932.0, 9063.0, 22176.0, 5492.0, 11435.0, 7186.0, 25685.0, 7432.0, 9085.0, 11328.0, 6799.0, 8244.0, 10620.0, 7673.0, 4376.596594587866, 1465.0954646876396, 1369.72211834028, 1274.329697753493, 1201.9314966725547, 1195.73308526199, 1128.236874163488, 1122.63236113735, 1047.1201337566447, 977.7987955512367, 970.2222031792235, 799.7292184917686, 756.4674106635794, 733.5588909095246, 789.126090580179, 704.5338983790654, 694.7413808679328, 638.762294041191, 604.7447312786198, 601.5565124560094, 586.96762968265, 569.9665720250763, 564.6750824915143, 562.449754558311, 559.1187028160442, 541.6667587945398, 529.7989550786579, 524.1018916936079, 503.2171666528902, 484.19150832820065, 4470.981304300112, 1398.7163950767317, 3413.702839567259, 1789.0898687494791, 4533.484989941712, 2906.285086595386, 1503.4808044030488, 2278.571747230994, 2380.290457227887, 1358.5344948383477, 2120.8417570314236, 1133.0985664569932, 1376.085571174623, 10067.940215221388, 4991.4569412924275, 1479.3851147330793, 1222.67101570749, 8110.196100555177, 4362.624221679945, 3537.946524870002, 4298.429107708271, 4824.421766966533, 3040.558777122696, 1676.0398068267987, 1803.2440290096902, 8905.61445138592, 2518.4130248002307, 3382.5271146033297, 3590.3872507325304, 3145.4781982257687, 3973.533378670669, 3247.5495577760203, 2173.155321297769, 3928.629932545841, 5527.783719001058, 3969.999002700139, 2426.0946014755386, 3187.4576440417454, 3139.601541473715, 3021.1431714947817, 2790.8105366057616, 3050.7453164811564, 2644.8157707254895, 2904.4342585179834, 2536.6136103316576, 2247.195508827951, 1656.6419214209639, 757.0901390175677, 615.0598886760376, 556.1747381292897, 497.95189409541524, 395.2416793025918, 381.20611454779237, 370.22472390422007, 359.6465084722542, 357.3790357174961, 352.4377017091428, 299.87955065387723, 298.2234334955019, 293.5401227583361, 292.77464017789015, 273.4601061823355, 270.41226630972966, 265.3961218038399, 253.38369070409334, 234.49537894579936, 218.09965472008878, 216.10858006867042, 211.66142747578925, 209.04564546552967, 203.96638017944244, 200.79329597351332, 200.78587217198043, 197.98628643869418, 192.70430704955623, 23792.56029535992, 610.7194024454797, 20680.117393784923, 441.07497419915046, 844.4026876788206, 20020.142767148263, 2495.072474708441, 2537.8220480249847, 6305.140865022659, 4032.413092940681, 46264.04144224008, 11318.156737179872, 27253.731878755825, 5825.214921341804, 4418.034153340376, 1019.8023718955926, 1980.1305644541571, 1199.6421542470728, 3039.5637743357656, 2646.4864101875273, 2963.9130945242628, 4753.802428926996, 12196.524978916723, 1682.7115053948928, 8030.834777788142, 3419.9841847541607, 3359.0135738603863, 3656.896971391647, 4335.211711904754, 9562.897627145547, 7691.989724276673, 2497.457250914286, 4841.91002610465, 3992.5724679262735, 6063.259376033855, 2931.5955505378583, 3823.3431816164098, 3719.8818332326705, 7260.090827312511, 4307.326879185861, 4942.381466121776, 4604.534821580638, 5027.305619012257, 4210.242465515855, 3950.2528102805886, 4014.9653126216213, 4108.077069113138, 36524.60385625007, 13102.876047304426, 8656.9778217805, 6798.5998236755995, 5208.912285858474, 5154.192502055798, 2509.1075451241495, 1839.3028902865665, 1765.5667550393127, 1526.4012371807846, 1461.5432712381344, 1160.2131037952743, 1148.9630182044673, 1103.0203400358669, 1046.597433694353, 855.7196366957196, 850.4982393573547, 789.7061738636431, 770.2839431367571, 754.3607627737451, 734.427527593533, 731.2117668888416, 714.4940893382962, 701.1100913900041, 695.3733573311234, 688.025967561229, 672.9115673291404, 646.4545469867461, 616.6397488058574, 583.8159202952222, 6855.081757157569, 7042.3510463541215, 1936.2005443785683, 4632.2696523454715, 2303.91025123101, 3649.41469348417, 1442.5122983917922, 2599.7672759967954, 2395.1648565421024, 1618.660793096471, 3699.3741279457795, 1132.3524288835101, 3190.442935236404, 5783.003755530311, 2246.7056414285066, 3840.323357886528, 4887.467808005219, 3004.1578829919467, 5606.067465113907, 4401.736989161946, 2335.325686755037, 2204.105510471563, 2774.108538366741, 2778.386922982985, 2281.7098187855636, 2132.3505751633675, 2008.6705745397162, 7186.005420544204, 3440.526047700712, 3271.634652346274, 2467.2082760707067, 2442.968288400639, 2155.1315610438824, 1761.9577192742265, 1522.6441589500957, 1437.4191211714958, 1191.190165957472, 999.3591903120366, 898.1524839546285, 877.7186966982925, 846.8570176472691, 753.8605121362048, 738.7673776563554, 671.4085159895528, 656.3310384982315, 644.3790873417946, 643.179977979019, 629.9720259023538, 627.807852160487, 602.2286520751267, 581.7522805094757, 569.7013258954076, 563.0590509734992, 561.6739811284448, 552.3958994287759, 546.9556020679727, 537.0557287139852, 7289.147182212219, 1871.8766624161644, 3250.2215609497284, 2306.124319030135, 8618.219267900364, 2529.2050915758355, 885.3579573595235, 2442.7652874459322, 2052.063090279062, 1199.4868851628364, 1280.004973278213, 8085.377394941503, 2389.612510874449, 5435.662082354791, 1300.4957870660405, 2022.0130101247487, 7867.472066948511, 2165.878059057709, 2724.8307948416846, 2782.3356743277714, 3394.9509836286607, 3722.8285695090076, 7367.287432681938, 2983.9140026630857, 3417.8547283122944, 4237.460824913751, 3100.1579642481834, 3171.0968098392973, 2342.948476255474, 2557.7251060236626, 2317.9774691899997, 2248.2230207914067, 2168.2194537128266, 14770.177099764416, 8908.370019285345, 4651.216648819417, 4469.803485720451, 2737.6886093580433, 2254.536454944344, 2088.7111473338305, 1914.827685926042, 1890.9406629694954, 1743.815275177852, 1631.7046547497705, 1552.2623755580837, 1366.7120992070136, 1204.1183750013802, 1131.3149605977187, 1025.8381426828144, 1024.967369673877, 1024.1083880612325, 1005.9927905769666, 976.0305439221925, 938.3321535385312, 934.2524538914123, 848.8463210481566, 836.6380279013025, 785.5699844385555, 751.0026727835211, 740.1731704471318, 735.0124899147601, 710.4040310572959, 708.3365239272492, 5933.057734675657, 1633.0781363451506, 1943.5711590435997, 2393.871248684953, 1373.398499990564, 2245.8081053452233, 1928.7858593237524, 1556.3519528146624, 1595.4918568288576, 2197.8463848523947, 1704.7167336532693, 1696.833907423905, 2646.039703866099, 3025.229771775549, 8430.754018033605, 3394.5153137394577, 7493.790160345488, 3932.8951581645883, 3480.496693863626, 3798.655729263798, 3386.5332175350227, 2085.8429364869517, 3795.5884845863047, 2214.169875305364, 2476.68389169443, 2044.056573958249, 2474.2428874566854, 2504.0379555713535, 2318.3144506443823, 2179.5915748098055, 2205.625743122668, 2045.7514482714262, 10505.516722957964, 7931.979575609053, 3988.6794304322543, 3572.238763461494, 3270.517702457755, 2950.056227373458, 1823.5480874682926, 1578.9642925757967, 1565.3740175391538, 1498.404712606203, 1158.6231925182312, 1124.452446306026, 1057.2089749606744, 1039.4374464984123, 994.6831374423717, 948.7201549754362, 853.100644777871, 816.448908169941, 805.7587592826329, 736.934179478529, 722.398492397326, 699.8028672854015, 665.6240501068986, 638.2897820113792, 636.4742458674168, 632.2170267819121, 608.8293379850826, 577.5174389342776, 575.3749978500457, 540.0769039942195, 5499.662898039415, 2420.034761619231, 1345.2217153443635, 4704.00806440499, 1556.1508129842655, 2920.417174711308, 2112.81607874777, 6655.019628793, 6402.397151468048, 3791.5191548544194, 1697.248924450048, 2052.0561193670487, 2346.7326438328255, 6202.1267813962795, 2556.7971007015735, 3471.2624728386218, 1353.6340034228424, 2934.2139679084826, 5258.14754899034, 2069.6461435032584, 1609.6974232495018, 6022.980409711356, 5562.896392953861, 2487.631507168787, 7278.249542186837, 5402.922201241204, 3926.3996649703854, 3300.2481849976593, 2582.8238106464446, 2889.9357842535737, 2512.5361679669954, 2660.211192808914, 2707.086132857054, 3712.029243779175, 2644.3626309620095, 2077.360911658663, 1999.5206444586638, 1746.200626156539, 1568.3248507077997, 1496.1960262175546, 1462.486557058697, 1451.1482439544882, 1255.809605045818, 1255.2823190365896, 1224.9309560309555, 1198.7222594495122, 1047.6696782055933, 959.4017133804349, 839.2719607190722, 785.7724550279978, 752.7823095576817, 607.2418465843374, 603.0886229647494, 564.0026725457432, 536.6199469848841, 528.4114406834398, 485.4505979213165, 485.2497817045265, 448.3221466075169, 431.57550852878296, 356.29418500327625, 355.34659065230636, 349.457540342817, 1256.9696342661207, 2377.469616695237, 3693.37169595753, 2787.406890984593, 15700.750960020667, 8936.076536616476, 3500.6459629096066, 5440.505601137585, 2047.7785026351487, 1086.702383639119, 2630.8840759953155, 3416.218694294649, 2059.0267353221116, 5690.1024867804235, 6594.757281507147, 3560.060481578198, 1709.7996459320766, 2132.694615297835, 2426.7708011820387, 3874.8285409361915, 3607.5970079039735, 1951.1663944981199, 2210.3567872015724, 2983.2754552013407, 4433.854069612888, 4043.3948208309203, 4737.263734244994, 2797.6016991743377, 2273.12505144268, 4756.3180949110165, 3558.5609008233346, 5504.450074648462, 3172.4190859502264, 3390.001276551791, 3406.5501393450177, 2729.8520452356, 2367.4088389861845, 2788.5856248010878, 2934.8447803262925, 2637.5977637550372, 18489.544756852243, 4832.691973117821, 3957.622824300426, 3835.6366654439576, 3804.971964859765, 3700.3156729768257, 3509.468042057481, 3272.1316109867366, 3156.448655128058, 3016.9303107512515, 2843.947548996648, 2126.5655968320893, 1893.2498679108683, 1834.6239761152292, 1415.316362456296, 1383.0380653501757, 1271.866449275764, 1197.0561853757672, 1185.6589409249289, 1087.0582594125644, 902.9953738863865, 864.430548387983, 767.6622039043241, 704.2024955597485, 646.7741436141031, 609.8067453231973, 595.8733944330748, 587.6821713300106, 574.3322295161762, 543.1893719868157, 4336.709571488648, 3409.51338257801, 1599.6169369045992, 1418.2318919645083, 2116.886038864824, 1956.5630418434193, 2007.170772729506, 1652.9869930446712, 2325.7590193946303, 1312.448093574701, 2106.842267090017, 1700.454238835534, 4248.960723239746, 1684.3419212386066, 2180.0391365845153, 1736.761019573747, 3204.4694978217276, 3499.628609993786, 2518.3048325620166, 2325.7828691334153, 2082.16385094078, 1976.47211658501, 1857.536501012247, 3753.521395689567, 2645.1113651670316, 2190.4310167974013, 2017.0120029677448, 1678.9795417124385, 1419.0283325591124, 1321.642786566436, 1286.1047464084893, 906.4611583851661, 895.1670214476339, 864.5108350135853, 848.2132189477156, 671.3652717321124, 664.4635709010782, 659.8548334662675, 607.0989912262653, 583.0831003649855, 545.8345912555105, 534.5484968331211, 518.5517931174462, 516.3162561012771, 475.68396456806033, 466.2829228177246, 446.39909751422795, 435.11681270427454, 433.2968526693995, 427.9653706135446, 413.03027889671193, 396.98080499396, 392.0378328582024, 3638.169341190523, 2758.2662609677805, 3076.496262716064, 2681.0656407578044, 4578.071277539219, 3728.6364428703478, 6727.462515369505, 1435.9780978353288, 2653.864255448466, 997.5241587015906, 1070.6230021242627, 1381.7924280932532, 2059.7255657295973, 999.3017897093986, 5745.087821390715, 1161.6540205091253, 4086.1240774817184, 1619.6462860209883, 1833.194910671314, 1640.1004244158353, 2340.442078658966, 2008.2598652023473, 1342.3957678923766, 5396.099479156395, 3596.14545937635, 2068.591333416544, 3270.296609014012, 3003.2995922086147, 2209.9145976338527, 2231.634656131519, 2071.658965040347, 1771.9602350840107, 1770.2838174831454, 1716.8926165468663, 5491.626003175908, 4249.8697710650185, 3440.95732875223, 2459.9573621239333, 1725.587570618136, 1636.36104864164, 1502.03956569064, 1478.5003659552567, 1264.9833752130062, 1251.66133443992, 1118.4688103035144, 1082.9033944952118, 856.9924183180084, 851.3145669367655, 781.5867375865171, 759.2070488073097, 696.9900359527664, 637.6118126384812, 596.7534152966315, 576.7072892886039, 543.0121982545228, 539.7537388336443, 507.1992610852779, 493.2887239807635, 475.2204815341656, 467.91405396422846, 467.3355238394124, 442.8902162045008, 419.73689382950374, 416.120712943422, 18371.247368014734, 1048.5122483424943, 1825.5428501630217, 3334.0285365063705, 683.3884512532301, 1067.6120748636724, 903.4183307864763, 1166.5255318266388, 1149.379408562323, 1617.842856473567, 1951.447517639079, 994.2043734872716, 1132.031673839656, 1050.715270145098, 1013.0572777091071, 2248.1067429112995, 1085.2274267409425, 1138.820130966486, 1498.5518290575358, 982.1761968491171, 1086.6110411955294], \"Total\": [36525.0, 22059.0, 18490.0, 26034.0, 89496.0, 24594.0, 19634.0, 25917.0, 14771.0, 13103.0, 10506.0, 49965.0, 8909.0, 8657.0, 13411.0, 11068.0, 7932.0, 9063.0, 22176.0, 5492.0, 11435.0, 7186.0, 25685.0, 7432.0, 9085.0, 11328.0, 6799.0, 8244.0, 10620.0, 7673.0, 4377.520829180608, 1466.0197175180292, 1370.6463429705104, 1275.2539262981147, 1202.8557656362789, 1196.6574105640498, 1129.1611785973676, 1123.5566711536005, 1048.0444120477223, 978.7231192674632, 971.1465096414713, 800.6534359181014, 757.3916625738839, 734.4831413280888, 790.1386750738185, 705.4581675063561, 695.6657510454894, 639.6865291524133, 605.6690604257898, 602.4808173365749, 587.8919432215959, 570.8909532726532, 565.5994038644003, 563.3739539024824, 560.0429907856303, 542.5911904560851, 530.7233744135988, 525.0261200724725, 504.1413681417195, 485.11579657273364, 4539.373494070295, 1410.9553718152572, 3541.382268998381, 1878.1043513018176, 5168.415284556083, 3245.2478050277855, 1609.9013286382128, 2632.8652785791787, 2786.8716961829164, 1513.5511722486776, 2610.7992244845645, 1293.17520006622, 1663.3292084256716, 21455.50049885389, 8937.689447518158, 1850.0014904635514, 1442.4677273516097, 18907.68072208957, 8140.432641396357, 6224.1856164540295, 8703.31689756015, 11947.580116787673, 5919.295007850505, 2341.591838094791, 2663.2379193440343, 46976.51869438528, 4976.834503308027, 9206.232253811066, 10480.360753553941, 8119.318099709157, 13006.653931610332, 9588.24579187843, 4164.01144436421, 18251.80512280678, 42944.004232148895, 19665.956097993483, 5808.357012937355, 12748.28880756808, 13409.11593456847, 14382.915709495099, 10855.852856935388, 16422.165923176355, 9111.419886447824, 25917.160437537106, 10163.921700067009, 2248.1227173876255, 1657.5691654159543, 758.0174146741932, 615.98742510327, 557.1020697162129, 498.8791636732946, 396.1689193513349, 382.13337717512184, 371.1520112184686, 360.57384617207305, 358.3062864005075, 353.3651834724949, 300.8068907804502, 299.1507343662971, 294.467539326803, 293.7018012853135, 274.38736668261396, 271.33970980962044, 266.32339798816304, 254.31161133945096, 235.42278230758296, 219.0271662710705, 217.03571628717907, 212.58866228339087, 209.97291703226765, 204.8939722607884, 201.72058591592625, 201.71344567805033, 198.91412313585863, 193.63178690930926, 26034.01883523317, 627.9526296457265, 24594.403751549453, 456.6184529431674, 909.9888230834712, 25917.160437537106, 2947.833196448327, 3062.0477375782634, 8381.08186595237, 5209.580390186511, 89496.32902300962, 18292.12245258078, 49965.26686237141, 8836.532760331162, 6454.464288707491, 1236.5920733983887, 2676.529116022287, 1495.589638843606, 4517.697358436915, 3860.437247431256, 4445.131693511518, 7875.906926711695, 25685.341063083222, 2321.1447267687927, 16462.293984834327, 6009.842434209114, 6046.546310569941, 6904.8527155636475, 8848.246733609874, 26224.016874649344, 19622.64329732126, 4265.372307351703, 11791.653737992681, 9085.552116389477, 18698.664524969743, 5584.345544280736, 9243.127858417207, 9091.983272547086, 42944.004232148895, 14382.915709495099, 22176.600262897777, 19524.197330272247, 28878.68011007833, 16872.32704360449, 16422.165923176355, 18251.80512280678, 46976.51869438528, 36525.532165432545, 13103.804359273758, 8657.90616955734, 6799.528137101546, 5209.840594219371, 5155.120916771176, 2510.035907259871, 1840.231299236298, 1766.4950968951985, 1527.3295880416674, 1462.4715723381162, 1161.141414748056, 1149.891326102887, 1103.9486387331615, 1047.5257457512646, 856.6479488022728, 851.4265621185563, 790.6344882009215, 771.2122626103875, 755.2891324571941, 735.3558338080642, 732.140170348447, 715.4223868255566, 702.038406775861, 696.3017148750591, 688.9543178654221, 673.8398676432462, 647.3828646649617, 617.5681268880296, 584.7442355546278, 7673.092058572177, 9843.243872024468, 2610.9746976576844, 8896.848991733283, 4051.9485245866695, 8863.390933364935, 2186.1987387175373, 5618.285999055866, 4968.457640230365, 2653.248249577186, 11435.961257901983, 1533.2407855446063, 10620.37977704971, 42944.004232148895, 7187.704675215744, 24344.302613427488, 49965.26686237141, 16315.882644862006, 89496.32902300962, 46976.51869438528, 9063.61221630712, 8917.557449718775, 24594.403751549453, 26224.016874649344, 16422.165923176355, 18698.664524969743, 16872.32704360449, 7186.931454627116, 3441.4520870329443, 3272.5606106310684, 2468.1342601168303, 2443.894350921184, 2156.057548015695, 1762.8837184413517, 1523.5701700919124, 1438.3451619930395, 1192.1163026276727, 1000.2852506513334, 899.0785436258326, 878.6448924130235, 847.7829767342774, 754.7865865839904, 739.6933954284365, 672.3345575245352, 657.2573313754713, 645.3051362481893, 644.1060585937616, 630.8981358665013, 628.7339412001597, 603.1549151388583, 582.6785916787029, 570.6275103294614, 563.9851768627531, 562.6001621763697, 553.3219103188009, 547.8816612283421, 537.9819444348246, 7432.564774913039, 1975.1749011618888, 3753.8006963196817, 2636.4543420204595, 11328.894017409923, 3469.3246701799017, 982.8173899444082, 3505.974773695786, 2948.0900413014765, 1460.6168335657476, 1595.381852131436, 22176.600262897777, 4030.081666300315, 14328.991558875998, 1800.7822598045575, 4045.632267497705, 42944.004232148895, 4966.3509590795375, 7871.234963184741, 9224.734626956082, 14055.749349590775, 18698.664524969743, 89496.32902300962, 13719.653698011109, 19524.197330272247, 49965.26686237141, 18907.68072208957, 26224.016874649344, 10846.393496628622, 24344.302613427488, 19622.64329732126, 46976.51869438528, 10480.360753553941, 14771.103712420347, 8909.296613043967, 4652.143205280443, 4470.7300158408925, 2738.615180491482, 2255.463007188842, 2089.6377171658255, 1915.7542648614162, 1891.8672411403643, 1744.7418261287346, 1632.6311996416066, 1553.1889376316985, 1367.6386911207767, 1205.044953668461, 1132.2416125796203, 1026.7646970547341, 1025.8940506647064, 1025.0349256228571, 1006.9193502098534, 976.9571509476251, 939.2587401234911, 935.179098386151, 849.7729040037036, 837.5645748914021, 786.496517107082, 751.9292592834018, 741.0997337732423, 735.9390959488057, 711.3305586530101, 709.2630812683949, 6558.148901365302, 1694.1077660457684, 2034.8866077852717, 2783.475825570754, 1521.8857100651796, 2827.1515119824135, 2502.9421209604566, 1894.1425573442916, 2005.4509155194385, 3181.305448924576, 2332.5790445850134, 2382.6769867929997, 5307.955851774889, 6915.687985047496, 46976.51869438528, 9085.44084614233, 89496.32902300962, 19634.46913520427, 16315.882644862006, 28878.68011007833, 24344.302613427488, 4878.300259774114, 42944.004232148895, 8029.276297202714, 19665.956097993483, 6437.3360631206415, 22059.09063607247, 25685.341063083222, 18698.664524969743, 19622.64329732126, 49965.26686237141, 10480.360753553941, 10506.440750161786, 7932.9036200629525, 3989.6034738007497, 3573.162800588402, 3271.4417345985653, 2950.9802995772543, 1824.4721921189087, 1579.888324674972, 1566.2980400261592, 1499.3288141569265, 1159.5473461358329, 1125.376475793241, 1058.1330563422457, 1040.3614935391413, 995.6071773145545, 949.6442109149671, 854.0247414663495, 817.3730591971942, 806.6828521982508, 737.8583183197095, 723.3225727191194, 700.7269291587711, 666.5480576140798, 639.2139181428242, 637.3983535167043, 633.1411050577133, 609.7533546848118, 578.4414635603005, 576.2990120266574, 541.0009270927671, 5713.563951724276, 2480.373257285009, 1391.983538956835, 5217.724251347437, 1649.8683825605917, 3248.1696877448617, 2297.228515114198, 8244.454445854828, 7907.716060788343, 4722.263408867605, 1895.062468435636, 2519.8705764979786, 2991.7330123540546, 10620.37977704971, 3461.83783459294, 5691.286923431657, 1538.1384087399138, 4886.480236359407, 13411.693804071501, 3037.557808610751, 2041.706076974376, 28878.68011007833, 25685.341063083222, 5307.955851774889, 89496.32902300962, 46976.51869438528, 22176.600262897777, 19524.197330272247, 8501.401574372434, 19665.956097993483, 9329.228414433694, 26224.016874649344, 42944.004232148895, 3712.953558220126, 2645.286921594995, 2078.2852076232916, 2000.4450420187031, 1747.1249170963802, 1569.2491925171526, 1497.1203709555539, 1463.4108530291296, 1452.0726056737103, 1256.7339169484462, 1256.2066535260576, 1225.8552428197897, 1199.6465343704683, 1048.5941013701472, 960.3260258462004, 840.1963711431292, 786.6968792997553, 753.7066704595022, 608.1661937025121, 604.0129207857927, 564.9270949445335, 537.5442257627581, 529.3357873396269, 486.3749783600282, 486.1741601433418, 449.246627506586, 432.49982016036233, 357.21860230324563, 356.270929795636, 350.38198577346776, 1271.4268395094812, 2518.698961482497, 3977.503419985258, 3105.8491640165244, 19634.46913520427, 11068.538751856824, 4095.2617077181035, 6770.386438622712, 2326.4807041248105, 1161.9682516477774, 3126.577564748314, 4391.406204548365, 2579.402703630117, 9085.44084614233, 11435.961257901983, 5393.19090017097, 2091.9225297779494, 2868.9488825883504, 3820.8720029120154, 9038.44504208371, 8896.848991733283, 2926.451744654559, 3750.784596320013, 6798.745714159844, 16315.882644862006, 13719.653698011109, 22176.600262897777, 6990.370551543896, 4319.950453919089, 46976.51869438528, 19665.956097993483, 89496.32902300962, 14328.991558875998, 19524.197330272247, 26224.016874649344, 9329.228414433694, 5617.241789131502, 24344.302613427488, 42944.004232148895, 28878.68011007833, 18490.469387363188, 4833.616624040518, 3958.5474889713105, 3836.561343164776, 3805.8966223037364, 3701.2403456665115, 3510.392660874577, 3273.0563303204353, 3157.3732461306204, 3017.8549320412494, 2844.8722250792302, 2127.490254941661, 1894.1745230093181, 1835.5485836251821, 1416.241058313431, 1383.962721581497, 1272.791082200901, 1197.9808783021037, 1186.5835844278831, 1087.9828823617636, 903.9199818947387, 865.3551661910913, 768.5868322550807, 705.1271331457152, 647.6987591561375, 610.7313439220857, 596.7980918079086, 588.6069436333306, 575.2568635739835, 544.1139998173825, 4527.806650099479, 3558.5532090606353, 1698.7250740696004, 1537.2204859284936, 2423.3775536194426, 2221.0983694182246, 2402.283173943248, 1990.691104124049, 3154.0616195878465, 1545.7818969955192, 4225.614246538587, 2769.297208523576, 28878.68011007833, 3152.6408814390225, 7046.830338918376, 3523.587596956688, 46976.51869438528, 89496.32902300962, 42944.004232148895, 49965.26686237141, 24344.302613427488, 18907.68072208957, 19665.956097993483, 3754.4449108971535, 2646.034904264704, 2191.354494573015, 2017.9354502748506, 1679.9030025677794, 1419.9518405917065, 1322.566339726461, 1287.028233214707, 907.3846602985157, 896.0904848477903, 865.4343127703127, 849.1367999770631, 672.2887324759947, 665.387102885976, 660.7784720366159, 608.0224620851867, 584.0066614743685, 546.7581426468682, 535.472067904047, 519.4752804966258, 517.2399386857232, 476.607507548375, 467.20649001467257, 447.32264910440085, 436.04027731559006, 434.22037685690384, 428.88901467310404, 413.9541344133402, 397.9043710847644, 392.9614232755634, 3790.090369172213, 2951.3080925781474, 3616.4356988368086, 3132.8823466664076, 5826.112017958396, 4673.534519683891, 9063.61221630712, 1630.0287203836808, 3456.169466189699, 1128.8514585984533, 1229.4005366523522, 1671.5116960739147, 2749.2577736071134, 1143.1280429468286, 13411.693804071501, 1488.6682495333275, 9329.228414433694, 2447.631257689551, 3136.1810172260525, 2777.8416180403615, 5384.404336896812, 4871.5738570904105, 2147.9466114383486, 89496.32902300962, 42944.004232148895, 9224.734626956082, 46976.51869438528, 49965.26686237141, 16872.32704360449, 24344.302613427488, 28878.68011007833, 10538.346613112148, 18698.664524969743, 8863.390933364935, 5492.548494464782, 4250.792276911175, 3441.8798270605685, 2460.879840091296, 1726.5101187857874, 1637.2835063747068, 1502.9620580987141, 1479.4229851947125, 1265.9058998763808, 1252.5838529043367, 1119.391416428683, 1083.825873108858, 857.9149057431893, 852.2370634114811, 782.5092749078777, 760.1296232416131, 697.9125385651367, 638.5342996546806, 597.6760145033809, 577.6298025619343, 543.9347343755935, 540.6762495438543, 508.12186136900345, 494.2111771488677, 476.142942004567, 468.83651317079114, 468.2579866764287, 443.8126955655455, 420.65936151759786, 417.0431926297683, 22059.09063607247, 1102.5831972732603, 1996.2398229167306, 4458.370807653381, 735.7624211522386, 1341.6457382685046, 1153.2027091878208, 1769.4759398391805, 1764.046232766236, 3152.0928936643645, 4886.480236359407, 1563.5846552667401, 2433.432599135673, 2051.481349499454, 2588.3462829571968, 46976.51869438528, 3672.6969473552967, 4656.713129357684, 28878.68011007833, 2378.693871660281, 89496.32902300962], \"Category\": [\"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\"], \"logprob\": [30.0, 29.0, 28.0, 27.0, 26.0, 25.0, 24.0, 23.0, 22.0, 21.0, 20.0, 19.0, 18.0, 17.0, 16.0, 15.0, 14.0, 13.0, 12.0, 11.0, 10.0, 9.0, 8.0, 7.0, 6.0, 5.0, 4.0, 3.0, 2.0, 1.0, -5.1691, -6.2635, -6.3308, -6.403, -6.4615, -6.4666, -6.5247, -6.5297, -6.5993, -6.6678, -6.6756, -6.8689, -6.9245, -6.9552, -6.8822, -6.9956, -7.0096, -7.0936, -7.1483, -7.1536, -7.1782, -7.2076, -7.2169, -7.2208, -7.2268, -7.2585, -7.2807, -7.2915, -7.3321, -7.3707, -5.1478, -6.3098, -5.4176, -6.0637, -5.1339, -5.5785, -6.2376, -5.8218, -5.7782, -6.339, -5.8936, -6.5204, -6.3262, -4.336, -5.0377, -6.2538, -6.4444, -4.5523, -5.1723, -5.3818, -5.1871, -5.0717, -5.5334, -6.129, -6.0558, -4.4587, -5.7218, -5.4268, -5.3671, -5.4994, -5.2657, -5.4675, -5.8692, -5.2771, -4.9356, -5.2666, -5.7591, -5.4862, -5.5013, -5.5398, -5.6191, -5.53, -5.6728, -5.5792, -5.7146, -5.6432, -5.9481, -6.7312, -6.9389, -7.0396, -7.1501, -7.3811, -7.4173, -7.4465, -7.4755, -7.4818, -7.4958, -7.6573, -7.6628, -7.6786, -7.6812, -7.7495, -7.7607, -7.7794, -7.8257, -7.9032, -7.9757, -7.9849, -8.0056, -8.0181, -8.0427, -8.0584, -8.0584, -8.0724, -8.0995, -3.2835, -6.946, -3.4237, -7.2714, -6.622, -3.4561, -5.5386, -5.5216, -4.6115, -5.0585, -2.6185, -4.0265, -3.1477, -4.6907, -4.9672, -6.4333, -5.7697, -6.2709, -5.3412, -5.4796, -5.3664, -4.8939, -3.9517, -5.9325, -4.3696, -5.2232, -5.2412, -5.1563, -4.9861, -4.195, -4.4127, -5.5376, -4.8756, -5.0684, -4.6506, -5.3773, -5.1118, -5.1392, -4.4705, -4.9926, -4.855, -4.9258, -4.838, -5.0154, -5.0791, -5.0629, -5.0399, -2.7676, -3.7927, -4.2072, -4.4488, -4.7152, -4.7257, -5.4456, -5.7562, -5.7971, -5.9426, -5.9861, -6.217, -6.2267, -6.2675, -6.32, -6.5214, -6.5275, -6.6016, -6.6266, -6.6474, -6.6742, -6.6786, -6.7017, -6.7206, -6.7289, -6.7395, -6.7617, -6.8018, -6.849, -6.9037, -4.4406, -4.4136, -5.7048, -4.8325, -5.5309, -5.071, -5.9992, -5.4101, -5.4921, -5.884, -5.0574, -6.2413, -5.2054, -4.6106, -5.5561, -5.02, -4.7789, -5.2656, -4.6417, -4.8836, -5.5174, -5.5752, -5.3452, -5.3437, -5.5406, -5.6083, -5.6681, -4.3904, -5.1269, -5.1772, -5.4594, -5.4693, -5.5947, -5.7961, -5.9421, -5.9997, -6.1876, -6.3632, -6.4699, -6.493, -6.5287, -6.6451, -6.6653, -6.7609, -6.7836, -6.802, -6.8039, -6.8246, -6.828, -6.8696, -6.9042, -6.9252, -6.9369, -6.9394, -6.956, -6.9659, -6.9842, -4.3761, -5.7356, -5.1838, -5.527, -4.2086, -5.4346, -6.4843, -5.4694, -5.6437, -6.1806, -6.1157, -4.2725, -5.4914, -4.6695, -6.0998, -5.6584, -4.2998, -5.5897, -5.3601, -5.3392, -5.1402, -5.048, -4.3655, -5.2693, -5.1335, -4.9186, -5.2311, -5.2084, -5.5111, -5.4234, -5.5218, -5.5524, -5.5886, -3.5808, -4.0865, -4.7363, -4.7761, -5.2663, -5.4605, -5.5369, -5.6238, -5.6364, -5.7174, -5.7838, -5.8337, -5.961, -6.0877, -6.1501, -6.2479, -6.2488, -6.2496, -6.2675, -6.2977, -6.3371, -6.3415, -6.4373, -6.4518, -6.5148, -6.5598, -6.5743, -6.5813, -6.6154, -6.6183, -4.4929, -5.783, -5.6089, -5.4005, -5.9562, -5.4644, -5.6166, -5.8311, -5.8063, -5.486, -5.74, -5.7447, -5.3004, -5.1665, -4.1416, -5.0513, -4.2594, -4.9041, -5.0263, -4.9388, -5.0536, -5.5383, -4.9396, -5.4786, -5.3665, -5.5585, -5.3675, -5.3555, -5.4326, -5.4943, -5.4824, -5.5577, -3.9195, -4.2005, -4.888, -4.9982, -5.0865, -5.1896, -5.6706, -5.8147, -5.8233, -5.867, -6.1242, -6.1541, -6.2158, -6.2327, -6.2768, -6.3241, -6.4303, -6.4742, -6.4874, -6.5767, -6.5966, -6.6284, -6.6785, -6.7204, -6.7232, -6.7299, -6.7676, -6.8204, -6.8242, -6.8875, -4.5667, -5.3876, -5.9749, -4.723, -5.8292, -5.1997, -5.5234, -4.3761, -4.4147, -4.9387, -5.7424, -5.5526, -5.4184, -4.4465, -5.3327, -5.0269, -5.9686, -5.195, -4.6116, -5.544, -5.7954, -4.4758, -4.5553, -5.3601, -4.2865, -4.5845, -4.9037, -5.0774, -5.3225, -5.2102, -5.3501, -5.293, -5.2755, -4.8886, -5.2278, -5.4691, -5.5073, -5.6428, -5.7502, -5.7973, -5.8201, -5.8279, -5.9724, -5.9729, -5.9973, -6.019, -6.1536, -6.2417, -6.3754, -6.4413, -6.4842, -6.699, -6.7059, -6.7729, -6.8227, -6.8381, -6.9229, -6.9233, -7.0025, -7.0405, -7.2322, -7.2349, -7.2516, -5.9715, -5.3342, -4.8937, -5.1751, -3.4465, -4.0101, -4.9473, -4.5063, -5.4835, -6.1171, -5.2329, -4.9717, -5.478, -4.4615, -4.3139, -4.9304, -5.6638, -5.4428, -5.3137, -4.8457, -4.9172, -5.5318, -5.4071, -5.1072, -4.7109, -4.8031, -4.6448, -5.1715, -5.3791, -4.6407, -4.9309, -4.4947, -5.0457, -4.9794, -4.9745, -5.196, -5.3384, -5.1747, -5.1236, -5.2303, -3.1559, -4.4977, -4.6975, -4.7288, -4.7368, -4.7647, -4.8177, -4.8877, -4.9237, -4.9689, -5.0279, -5.3186, -5.4348, -5.4663, -5.7258, -5.7489, -5.8327, -5.8933, -5.9028, -5.9897, -6.1752, -6.2188, -6.3375, -6.4238, -6.5089, -6.5678, -6.5909, -6.6047, -6.6277, -6.6834, -4.606, -4.8466, -5.6034, -5.7237, -5.3232, -5.402, -5.3764, -5.5706, -5.2291, -5.8012, -5.328, -5.5422, -4.6265, -5.5518, -5.2938, -5.5211, -4.9086, -4.8205, -5.1496, -5.2291, -5.3397, -5.3918, -5.4539, -4.6787, -5.0287, -5.2173, -5.2998, -5.4832, -5.6515, -5.7225, -5.7498, -6.0996, -6.1122, -6.147, -6.166, -6.3999, -6.4102, -6.4172, -6.5005, -6.5409, -6.6069, -6.6278, -6.6581, -6.6625, -6.7444, -6.7644, -6.808, -6.8336, -6.8378, -6.8501, -6.8857, -6.9253, -6.9378, -4.7099, -4.9868, -4.8776, -5.0152, -4.4801, -4.6854, -4.0952, -5.6396, -5.0254, -6.0039, -5.9332, -5.678, -5.2789, -6.0021, -4.2531, -5.8516, -4.5938, -5.5192, -5.3954, -5.5067, -5.1511, -5.3042, -5.707, -4.3157, -4.7216, -5.2746, -4.8165, -4.9017, -5.2085, -5.1987, -5.2731, -5.4293, -5.4303, -5.4609, -3.7517, -4.008, -4.2192, -4.5548, -4.9093, -4.9624, -5.0481, -5.0639, -5.2199, -5.2304, -5.343, -5.3753, -5.6092, -5.6159, -5.7013, -5.7304, -5.8159, -5.9049, -5.9712, -6.0053, -6.0655, -6.0716, -6.1338, -6.1616, -6.1989, -6.2144, -6.2156, -6.2693, -6.323, -6.3317, -2.5441, -5.4075, -4.853, -4.2507, -5.8356, -5.3895, -5.5565, -5.3009, -5.3157, -4.9738, -4.7863, -5.4607, -5.3309, -5.4054, -5.4419, -4.6448, -5.3731, -5.3249, -5.0504, -5.4729, -5.3718], \"loglift\": [30.0, 29.0, 28.0, 27.0, 26.0, 25.0, 24.0, 23.0, 22.0, 21.0, 20.0, 19.0, 18.0, 17.0, 16.0, 15.0, 14.0, 13.0, 12.0, 11.0, 10.0, 9.0, 8.0, 7.0, 6.0, 5.0, 4.0, 3.0, 2.0, 1.0, 1.9087, 1.9083, 1.9083, 1.9082, 1.9082, 1.9082, 1.9081, 1.9081, 1.9081, 1.908, 1.908, 1.9078, 1.9077, 1.9077, 1.9077, 1.9076, 1.9076, 1.9075, 1.9074, 1.9074, 1.9074, 1.9073, 1.9073, 1.9073, 1.9073, 1.9073, 1.9072, 1.9072, 1.9071, 1.907, 1.8938, 1.9002, 1.8722, 1.8604, 1.7779, 1.7986, 1.8406, 1.7644, 1.7513, 1.8009, 1.7011, 1.7768, 1.7194, 1.1523, 1.3264, 1.6854, 1.7436, 1.0625, 1.2852, 1.3441, 1.2035, 1.0021, 1.2428, 1.5746, 1.519, 0.246, 1.2278, 0.9077, 0.8377, 0.9607, 0.7232, 0.8263, 1.2587, 0.373, -0.1412, 0.3088, 1.0359, 0.5228, 0.4571, 0.3485, 0.5506, 0.2257, 0.672, -0.2797, 0.5209, 2.1011, 2.1009, 2.1002, 2.1, 2.0998, 2.0996, 2.0991, 2.099, 2.099, 2.0989, 2.0989, 2.0988, 2.0984, 2.0984, 2.0983, 2.0983, 2.0981, 2.098, 2.098, 2.0978, 2.0975, 2.0972, 2.0972, 2.0971, 2.097, 2.0969, 2.0969, 2.0969, 2.0968, 2.0967, 2.0114, 2.0736, 1.9281, 2.0668, 2.0267, 1.8433, 1.9347, 1.9137, 1.8169, 1.8453, 1.4416, 1.6214, 1.4953, 1.6848, 1.7224, 1.9087, 1.8001, 1.881, 1.7052, 1.7239, 1.6962, 1.5966, 1.3567, 1.7798, 1.3837, 1.5377, 1.5136, 1.4659, 1.388, 1.0927, 1.165, 1.5662, 1.2114, 1.2792, 0.9753, 1.457, 1.2187, 1.2078, 0.324, 0.8957, 0.6003, 0.6569, 0.3532, 0.7133, 0.6766, 0.5872, -0.3352, 2.1888, 2.1887, 2.1887, 2.1887, 2.1886, 2.1886, 2.1884, 2.1883, 2.1883, 2.1882, 2.1882, 2.188, 2.188, 2.188, 2.1879, 2.1877, 2.1877, 2.1876, 2.1876, 2.1876, 2.1875, 2.1875, 2.1875, 2.1875, 2.1875, 2.1874, 2.1874, 2.1874, 2.1873, 2.1872, 2.0761, 1.854, 1.8898, 1.5361, 1.6242, 1.3014, 1.773, 1.4182, 1.4591, 1.6946, 1.0602, 1.8857, 0.9862, 0.1838, 1.0259, 0.3421, -0.1359, 0.4967, -0.5816, -0.1789, 0.8327, 0.7911, 0.0066, -0.056, 0.2151, 0.0176, 0.0606, 2.1917, 2.1916, 2.1915, 2.1914, 2.1914, 2.1914, 2.1913, 2.1912, 2.1912, 2.191, 2.1909, 2.1908, 2.1908, 2.1907, 2.1906, 2.1906, 2.1904, 2.1904, 2.1904, 2.1904, 2.1904, 2.1903, 2.1903, 2.1902, 2.1902, 2.1902, 2.1902, 2.1901, 2.1901, 2.1901, 2.1723, 2.1381, 2.0478, 2.058, 1.9183, 1.8758, 2.0874, 1.8305, 1.8295, 1.9949, 1.9716, 1.1828, 1.6692, 1.2225, 1.8663, 1.4983, 0.4947, 1.362, 1.131, 0.9932, 0.7711, 0.5779, -0.3053, 0.6662, 0.4492, -0.2755, 0.3837, 0.0792, 0.6594, -0.0614, 0.0558, -0.8477, 0.6162, 2.2808, 2.2808, 2.2807, 2.2807, 2.2806, 2.2805, 2.2805, 2.2804, 2.2804, 2.2804, 2.2803, 2.2803, 2.2802, 2.2801, 2.2801, 2.28, 2.28, 2.28, 2.28, 2.28, 2.2799, 2.2799, 2.2798, 2.2798, 2.2797, 2.2797, 2.2797, 2.2796, 2.2796, 2.2796, 2.1807, 2.2442, 2.235, 2.1301, 2.1782, 2.0507, 2.0203, 2.0845, 2.0522, 1.9111, 1.9673, 1.9414, 1.5848, 1.4541, 0.5631, 1.2964, -0.1992, 0.673, 0.7359, 0.2524, 0.3084, 1.4313, -0.1452, 0.9927, 0.2089, 1.1337, 0.0931, -0.0471, 0.1933, 0.0834, -0.8394, 0.6472, 2.2828, 2.2828, 2.2827, 2.2827, 2.2826, 2.2826, 2.2824, 2.2823, 2.2823, 2.2823, 2.2821, 2.2821, 2.2821, 2.282, 2.282, 2.282, 2.2818, 2.2818, 2.2818, 2.2817, 2.2816, 2.2816, 2.2815, 2.2815, 2.2815, 2.2815, 2.2814, 2.2813, 2.2813, 2.2812, 2.2448, 2.2583, 2.2488, 2.1793, 2.2244, 2.1766, 2.1992, 2.0688, 2.0718, 2.0634, 2.1727, 2.0776, 2.0401, 1.745, 1.9799, 1.7885, 2.1551, 1.7729, 1.3466, 1.8993, 2.0452, 0.7154, 0.7531, 1.5251, -0.2264, 0.1202, 0.5516, 0.5053, 1.0916, 0.3653, 0.9711, -0.0053, -0.4811, 2.3539, 2.3538, 2.3537, 2.3537, 2.3536, 2.3535, 2.3535, 2.3535, 2.3535, 2.3534, 2.3534, 2.3534, 2.3534, 2.3532, 2.3532, 2.353, 2.353, 2.3529, 2.3526, 2.3526, 2.3525, 2.3524, 2.3524, 2.3522, 2.3522, 2.3521, 2.352, 2.3515, 2.3515, 2.3515, 2.3427, 2.2964, 2.28, 2.246, 2.1306, 2.1401, 2.1972, 2.1354, 2.2265, 2.2872, 2.1815, 2.103, 2.1288, 1.8862, 1.8036, 1.9388, 2.1524, 2.0576, 1.9002, 1.5071, 1.4515, 1.9488, 1.8253, 1.5304, 1.0513, 1.1324, 0.8106, 1.4384, 1.712, 0.064, 0.6446, -0.4345, 0.8463, 0.6033, 0.3132, 1.1252, 1.4901, 0.1874, -0.3291, -0.0391, 2.4812, 2.481, 2.481, 2.481, 2.481, 2.481, 2.4809, 2.4809, 2.4809, 2.4809, 2.4809, 2.4808, 2.4807, 2.4807, 2.4806, 2.4805, 2.4805, 2.4804, 2.4804, 2.4804, 2.4802, 2.4801, 2.48, 2.4799, 2.4798, 2.4797, 2.4797, 2.4796, 2.4796, 2.4795, 2.4381, 2.4384, 2.4211, 2.4006, 2.346, 2.3544, 2.3015, 2.2953, 2.1766, 2.3176, 1.7852, 1.9935, 0.5648, 1.8543, 1.308, 1.7738, -0.2039, -0.7603, -0.3551, -0.5861, 0.0223, 0.223, 0.1216, 2.5527, 2.5526, 2.5525, 2.5525, 2.5524, 2.5523, 2.5522, 2.5522, 2.5519, 2.5519, 2.5519, 2.5518, 2.5515, 2.5515, 2.5515, 2.5514, 2.5513, 2.5512, 2.5512, 2.5511, 2.5511, 2.551, 2.5509, 2.5509, 2.5508, 2.5508, 2.5508, 2.5507, 2.5506, 2.5506, 2.512, 2.4853, 2.3912, 2.3972, 2.3119, 2.3271, 2.2549, 2.4262, 2.2888, 2.4292, 2.4146, 2.3626, 2.2642, 2.4185, 1.7051, 2.3049, 1.7274, 2.14, 2.016, 2.026, 1.7198, 1.6668, 2.0829, -0.2556, 0.0729, 1.0579, -0.1118, -0.2587, 0.5202, 0.1634, -0.0818, 0.77, 0.1956, 0.9115, 3.0993, 3.0992, 3.0992, 3.0991, 3.0989, 3.0989, 3.0988, 3.0988, 3.0987, 3.0987, 3.0986, 3.0986, 3.0984, 3.0984, 3.0983, 3.0982, 3.0981, 3.098, 3.0979, 3.0978, 3.0977, 3.0977, 3.0976, 3.0976, 3.0975, 3.0975, 3.0975, 3.0974, 3.0972, 3.0972, 2.9165, 3.0492, 3.01, 2.8088, 3.0256, 2.871, 2.8553, 2.6828, 2.671, 2.4325, 2.1815, 2.6466, 2.3341, 2.4303, 2.1614, 0.0599, 1.8803, 1.6911, 0.1408, 2.2149, -1.3117]}, \"token.table\": {\"Topic\": [9, 1, 6, 9, 1, 6, 9, 1, 2, 5, 6, 10, 1, 3, 5, 8, 5, 8, 9, 2, 9, 6, 7, 1, 2, 3, 6, 7, 9, 6, 7, 1, 2, 3, 6, 3, 2, 3, 4, 5, 6, 7, 8, 9, 10, 2, 3, 5, 5, 7, 9, 9, 1, 1, 3, 8, 6, 9, 1, 3, 8, 9, 1, 3, 4, 5, 6, 8, 9, 9, 10, 10, 9, 9, 10, 1, 2, 3, 5, 3, 4, 7, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 2, 8, 8, 8, 6, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 4, 3, 3, 3, 5, 5, 6, 6, 4, 6, 5, 5, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 9, 1, 2, 3, 6, 7, 8, 9, 2, 8, 8, 10, 10, 2, 3, 6, 9, 7, 9, 5, 1, 3, 4, 6, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 7, 8, 2, 5, 7, 3, 5, 3, 5, 5, 7, 1, 2, 3, 3, 5, 7, 3, 5, 7, 1, 2, 3, 5, 6, 7, 10, 8, 8, 6, 1, 10, 10, 1, 2, 3, 5, 6, 8, 9, 10, 3, 5, 6, 5, 6, 1, 3, 4, 7, 8, 10, 7, 4, 9, 5, 3, 4, 5, 5, 1, 2, 3, 4, 8, 9, 7, 7, 1, 2, 4, 5, 5, 4, 9, 6, 5, 1, 3, 4, 5, 6, 7, 8, 9, 3, 10, 1, 1, 3, 4, 5, 7, 8, 9, 10, 1, 2, 3, 5, 8, 9, 1, 3, 4, 5, 6, 8, 2, 1, 1, 5, 7, 9, 6, 5, 5, 2, 9, 1, 7, 9, 1, 2, 3, 5, 6, 7, 8, 9, 10, 1, 3, 3, 3, 5, 7, 10, 1, 2, 4, 5, 6, 7, 8, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 4, 1, 1, 2, 3, 4, 5, 6, 7, 8, 9, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 10, 1, 2, 3, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 8, 9, 4, 8, 9, 8, 5, 2, 4, 6, 7, 8, 1, 2, 3, 4, 5, 6, 7, 7, 3, 10, 10, 6, 7, 10, 8, 10, 3, 3, 5, 9, 3, 7, 8, 9, 5, 1, 3, 9, 2, 3, 9, 9, 9, 2, 3, 5, 7, 8, 3, 2, 7, 10, 2, 4, 7, 4, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 9, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 6, 2, 3, 4, 5, 6, 7, 8, 9, 10, 3, 5, 6, 7, 9, 10, 3, 9, 3, 9, 6, 7, 9, 5, 1, 3, 4, 5, 6, 7, 8, 9, 3, 5, 6, 7, 8, 9, 10, 1, 3, 4, 5, 9, 1, 2, 3, 4, 5, 6, 7, 8, 9, 4, 2, 3, 4, 6, 8, 9, 10, 10, 10, 9, 1, 3, 4, 5, 8, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 3, 4, 5, 4, 3, 5, 8, 9, 10, 1, 9, 9, 9, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 5, 7, 8, 2, 3, 5, 6, 7, 8, 4, 4, 4, 5, 2, 5, 1, 3, 4, 5, 6, 7, 8, 9, 2, 6, 8, 6, 8, 10, 1, 6, 8, 4, 1, 2, 5, 6, 7, 9, 2, 3, 3, 3, 7, 5, 8, 9, 10, 2, 3, 5, 6, 7, 3, 3, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 10, 10, 7, 3, 4, 5, 6, 7, 8, 9, 6, 4, 4, 10, 1, 2, 3, 4, 8, 9, 6, 10, 10, 8, 5, 7, 1, 3, 4, 5, 9, 10, 3, 5, 10, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 7, 9, 7, 7, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 6, 8, 9, 7, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 8, 9, 10, 1, 3, 6, 7, 9, 6, 7, 9, 7, 2, 2, 6, 7, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 10, 8, 2, 3, 4, 5, 7, 5, 7, 4, 8, 1, 5, 6, 8, 9, 10, 10, 10, 7, 1, 2, 3, 6, 9, 3, 6, 6, 6, 8, 10, 5, 8, 6, 8, 10, 5, 9, 1, 6, 5, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 7, 9, 1, 2, 3, 4, 5, 6, 8, 9, 2, 3, 4, 5, 6, 7, 8, 9, 10, 5, 10, 6, 1, 3, 4, 5, 6, 8, 9, 3, 4, 5, 6, 7, 10, 3, 5, 7, 6, 6, 7, 2, 3, 5, 5, 7, 4, 8, 9, 4, 8, 10, 4, 3, 4, 8, 8, 9, 9, 7, 1, 3, 4, 5, 8, 9, 10, 2, 3, 4, 5, 6, 7, 8, 9, 2, 3, 4, 5, 6, 7, 8, 6, 1, 6, 6, 7, 9, 1, 2, 3, 5, 6, 7, 8, 9, 10, 1, 3, 9, 10, 3, 4, 7, 4, 7, 7, 4, 5, 7, 7, 1, 5, 8, 9, 10, 3, 9, 9, 1, 6, 10, 1, 2, 3, 6, 8, 10, 1, 2, 3, 4, 6, 8, 9, 10, 2, 5, 1, 2, 5, 6, 9, 1, 2, 3, 4, 5, 6, 7, 1, 2, 4, 8, 8, 9, 1, 2, 3, 4, 5, 6, 7, 8, 9, 1, 2, 3, 4, 7, 8, 6, 6, 5, 8, 10, 6, 7, 9, 3, 1, 10, 1, 10, 6, 8, 10, 2, 6, 2, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 6, 10, 7, 6, 1, 3, 4, 1, 2, 3, 8, 3, 4, 8, 8, 10, 6, 7, 9, 6, 7, 9, 7, 6, 7, 6, 8, 1, 1, 4, 5, 7, 8, 9, 10, 3, 5, 9, 4, 8, 10, 2, 8, 3, 5, 7, 9, 10, 3, 6, 6, 1, 3, 5, 6, 10, 3, 6, 8, 3, 4, 6, 7, 8, 1, 2, 1, 3, 1, 2, 5, 6, 7, 8, 9, 10, 1, 5, 6, 10, 10, 3, 3, 3, 3, 3, 6, 7, 7, 2, 8, 1, 2, 1, 2, 4, 4, 6, 9, 9, 6, 9, 4, 6, 9, 6, 9, 6, 6, 6, 2, 3, 4, 5, 6, 7, 8, 9, 3, 4, 6, 2, 5, 2, 3, 4, 5, 6, 7, 8, 9, 10, 4, 4, 4, 4, 7, 9, 1, 2, 3, 5, 6, 7, 8, 9, 10, 5, 2, 3, 7, 5, 1, 2, 3, 5, 7, 8, 9, 1, 4, 5, 8, 9, 3, 5, 6, 8, 1, 1, 6, 8, 9, 3, 5, 7, 7, 5, 4, 7, 10, 7, 8, 1, 2, 3, 4, 5, 6, 7, 8, 4, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 3, 5, 4, 3, 1, 6, 10, 2, 10, 3, 3, 7, 8, 6, 9, 9, 3, 5, 2, 5, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 8, 8, 1, 2, 3, 4, 5, 6, 8, 9, 1, 3, 6, 7, 8, 9, 8, 1, 4, 9, 9, 5, 7, 8, 2, 1, 2, 3, 4, 5, 6, 8, 9, 5, 6, 7, 8, 8, 1, 5, 6, 8, 9, 10, 2, 1, 5, 6, 10, 1, 3, 4, 5, 6, 8, 10, 1, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 2, 6, 1, 2, 3, 6, 8, 9, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 4, 7, 7, 3, 1, 1, 10, 10, 10, 2, 2, 4, 7, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 4, 5, 4, 1, 1, 1, 5, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 4, 8, 4, 6, 1, 1, 4, 5, 8, 10, 1, 2, 3, 4, 5, 7, 8, 9, 10, 1, 9, 8, 8, 3, 10, 3, 5, 6, 9, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 4, 1, 4, 1, 2, 4, 5, 6, 7, 8, 9, 10, 3, 4, 8, 1, 2, 3, 4, 5, 6, 7, 8, 9, 6, 2, 2, 4, 1, 2, 3, 4, 5, 8, 9, 4, 1, 3, 4, 5, 6, 7, 7, 7], \"Freq\": [0.9987253504429673, 0.10613513121511817, 0.11285254458316363, 0.7805634333668817, 0.3150328359789272, 0.10044063090421261, 0.5844688141187991, 0.057299313767972565, 0.7250732712142693, 0.062469176664330994, 0.1456178049140957, 0.009478081976657116, 0.8540041521322296, 0.03408840103048816, 0.062076772402888954, 0.04951788781270911, 0.27999164951892175, 0.3077034330123634, 0.41218712040615463, 0.11604715483350264, 0.8840844314796613, 0.9662470585018234, 0.03304636780006236, 0.5684277780288353, 0.42945377350793573, 0.0020886266575395303, 0.04419741958343706, 0.8548904196774206, 0.1008482557345829, 0.9626215872389378, 0.0372797087421625, 0.21146790319290779, 0.7397640429716562, 0.048570366457735, 0.9981009203517484, 0.9978639152494754, 0.4899275676314039, 0.12228411261295939, 0.0628373074055503, 0.09685534612690037, 0.06916624484208055, 0.047354014034038806, 0.022603347987608022, 0.06860116114239034, 0.020456029928785258, 0.9970494420580776, 0.9985208689925814, 0.9996948192691073, 0.20031099251612552, 0.7996651140339911, 0.9998814975561734, 0.9993296669897552, 0.9993044312393318, 0.17180934123239078, 0.3294195633546666, 0.498625732750203, 0.8989678128630333, 0.10067208041308626, 0.1261497500902388, 0.024583028222713202, 0.84876139547894, 0.9986133857226194, 0.8978883733286259, 0.03303489232261317, 0.05351652556263333, 0.014535352621949793, 0.0013213956929045267, 0.9986627105232678, 0.9982762842604791, 0.9971894988767281, 0.9997443760082351, 0.9998136166484827, 0.9992010795193369, 0.9980830669714656, 0.9986924743220507, 0.028412359132195388, 0.8288570974426654, 0.1090773327603823, 0.03363762058179454, 0.1754700430721164, 0.02082598996057947, 0.8036468891880347, 0.18578548129843028, 0.24052856477509002, 0.13895852780171022, 0.09864715821155591, 0.09767286529094794, 0.05133305825453187, 0.006576477214103728, 0.05255092440529182, 0.0866511766265704, 0.04122476920322429, 0.14769746897151334, 0.24952100496391302, 0.11907071234501217, 0.10389793864649395, 0.06572892981115903, 0.07378946583849684, 0.014283743989620673, 0.07930145003366167, 0.13098371044423937, 0.015765460171116595, 0.9963542744012944, 0.9997695618391096, 0.9999746146323625, 0.9997167087018755, 0.9994377294514442, 0.1509257432444091, 0.023417922287159384, 0.15369163957753817, 0.21601650361737967, 0.07467920099448465, 0.10353671940346452, 0.06850203251716308, 0.1084231362586592, 0.09330290297088699, 0.0075601166438861, 0.9989003153228643, 0.9987536094499965, 0.9999386163550902, 0.9991294688113964, 0.9989034031554523, 0.9981294791334008, 0.9997411897419164, 0.9995279656862164, 0.9976109561285234, 0.9991712688179463, 0.9998544651614731, 0.9997753680415327, 0.08092691570338957, 0.3919961181300205, 0.0562105718015357, 0.118128835390716, 0.11109614372379675, 0.0670653785048241, 0.04856634172879739, 0.08000960809466097, 0.03766057349169074, 0.008357691546193884, 0.9995717872824602, 0.24013229229513286, 0.07262401887488955, 0.312617184697082, 0.017390809117550178, 0.3224951642758505, 0.006538944228198867, 0.02838180047984189, 0.9952278993296725, 0.9993784665747869, 0.9990966012630365, 0.9999001384393174, 0.9991632404790635, 0.19696841021140052, 0.7383054316533292, 0.01826197180767952, 0.045002716240353104, 0.9974764839794029, 0.9975533901838268, 0.9982191639438837, 0.16817116084636957, 0.02486008464685463, 0.1272251390750796, 0.16719625556610077, 0.5123127247812591, 0.09020276374583347, 0.6187362909547535, 0.0697021356217804, 0.06133787934716676, 0.04275064318135865, 0.04608541202287128, 0.013284407024386383, 0.01787654772417427, 0.03985322107315915, 0.000109336683328283, 0.05769032405298136, 0.9418828416813282, 0.9986577951185587, 0.9985160785746837, 0.9991141705044316, 0.20394415880982236, 0.7953323552607987, 0.09514880027656786, 0.904676012886021, 0.9990904581682211, 0.9965886370547659, 0.998045582813421, 0.9657953969172784, 0.03285018356861491, 0.32345335180670337, 0.09977298578303556, 0.5766896066951092, 0.20844355322592373, 0.12472442119256093, 0.6666776595799626, 0.07787839201948799, 0.06134504429377302, 0.009215308568431294, 0.04029438844627801, 0.002800731035503628, 0.8073333075245297, 0.001084153949227211, 0.99966488378201, 0.9991236955699413, 0.9978061544888072, 0.2034814349370104, 0.7960372619513814, 0.9989335705242274, 0.04862279802373462, 0.5555237366045055, 0.09410330637926871, 0.053915075359651315, 0.06284579336401074, 0.0846764373746671, 0.07243804603535975, 0.027784456013562643, 0.03278098101396555, 0.49849698714340723, 0.4687303492111856, 0.09831872580608715, 0.9015424682102027, 0.9989104311561193, 0.4820409417617486, 0.0006038091128539649, 0.3842238654794063, 0.0736647117681837, 0.059173293059688555, 0.9997775284952323, 0.9992660374872806, 0.9976027785308422, 0.9991328508822183, 0.2853452895218991, 0.28698520497892144, 0.427607955418593, 0.9990202733592802, 0.9984828109453107, 0.07811883478122023, 0.054021160323284495, 0.7607097380164474, 0.08694582176214907, 0.020125530316517752, 0.9992613277948229, 0.9989875702562225, 0.9990034658496183, 0.9950626105903908, 0.9982828005124242, 0.9993259327002036, 0.9992552363195505, 0.998957868889072, 0.9987830639134891, 0.998800103303108, 0.9995415951386517, 0.9989716449525745, 0.568615318289372, 0.1707820313612176, 0.04170832846827424, 0.0550352499906814, 0.03578525223609329, 0.10316024437715168, 0.02492627914376153, 0.9993308997424352, 0.9997045376217394, 0.9981376594247395, 0.3425454604492134, 0.09570281248762146, 0.20686310814871717, 0.19522228748721188, 0.07022659022022872, 0.001812914693185252, 0.022232059132219144, 0.06545576208026752, 0.16872391004630122, 0.6667968925029825, 0.07131397264623665, 0.03419471243605038, 0.03306988636907504, 0.025421069113642718, 0.676995467398604, 0.0506901764275161, 0.058199832194555524, 0.060828211713019324, 0.05106565921586807, 0.10175583564338418, 0.9996566264456231, 0.9989267725344741, 0.8272565605352253, 0.05651316619935406, 0.10160345837968973, 0.013827689601969608, 0.9998649725000774, 0.9992345183493829, 0.9993686976403807, 0.9964630732688536, 0.9991184079761718, 0.9975612044309733, 0.1250953477017023, 0.8739178486293748, 0.07777363755679996, 0.17407305253696945, 0.04595085353422687, 0.13155033351659975, 0.20856216340365366, 0.09134766512682026, 0.14713276312504142, 0.07174843144153585, 0.05190680440678679, 0.9984393634764297, 0.9995872938483172, 0.999782562467637, 0.07251114739735082, 0.7944392051436582, 0.06791287951361637, 0.0647294632864156, 0.10359259659702481, 0.6729091744764005, 0.055337925532598725, 0.007968661276694216, 0.08057201957546375, 0.06884037936255281, 0.01084623340438935, 0.01696114933867168, 0.41062942548924136, 0.16342067387810164, 0.08395768922642481, 0.042148456106599126, 0.08285521451941115, 0.05486931811060288, 0.046049520454493606, 0.06496120196711253, 0.03400710442403672, 0.9525562297749566, 0.046855756411512677, 0.9995284392842653, 0.02668091550213294, 0.6854145865887743, 0.08392831672515604, 0.07253064408346818, 0.03186167579380923, 0.021241117195872825, 0.03574724601256646, 0.041187044318826575, 0.0010361520583352596, 0.06637702487710337, 0.09856415978518152, 0.04191480234696398, 0.10929320475454089, 0.08826427661459652, 0.061656245090585246, 0.4002649043235673, 0.09269894853526506, 0.039625939420167317, 0.0014305393292479175, 0.9997140877227504, 0.14092967452668004, 0.5250391432175678, 0.08846157460759839, 0.08273127017957582, 0.0136094730165536, 0.0376051228088981, 0.04799129958468901, 0.05031923575857317, 0.013251328989802188, 0.11252356213769073, 0.1263993000506237, 0.15013982038603244, 0.3015804912014023, 0.08509729891915917, 0.22428829485826793, 0.6968104900038221, 0.08100457599716966, 0.2221921292316731, 0.9979526352607058, 0.9996133850426568, 0.22284750328787492, 0.3645734650106169, 0.17703344757349188, 0.21360352551085865, 0.02186989864318481, 0.9993422022904227, 0.26764523951011365, 0.029665471808446697, 0.21749820117052812, 0.04358710599865141, 0.14686959629980367, 0.29468673838218673, 0.9975848980887927, 0.04806893496207041, 0.9514021278341861, 0.9975492720422572, 0.15815912010565308, 0.1899043198401211, 0.651343473123281, 0.998921166443104, 0.9981688320914077, 0.998428107708915, 0.0354168732370825, 0.9639292332692622, 0.998318381064936, 0.052359854895208356, 0.2293000541962573, 0.6138741608403738, 0.10399750489531039, 0.9995748218345974, 0.13189782419010587, 0.017420467345863038, 0.8505612310456302, 0.9973175788016135, 0.11840282173345455, 0.8809660725867395, 0.9970431877146195, 0.9976142632465185, 0.06828782023006165, 0.005324135136581078, 0.31991107646761086, 0.5261634419760344, 0.08009351118508926, 0.9983245036248263, 0.9972309798788509, 0.08516010854427847, 0.914719754128544, 0.2376744871123129, 0.7219084888925392, 0.03998262400020217, 0.9998686348025452, 0.9992380020357983, 0.3873477995784717, 0.09015535430570469, 0.08042547317161908, 0.06663121131063694, 0.10887613825989474, 0.034239328547794955, 0.0636752980547122, 0.07488313581676019, 0.059980406484806265, 0.03374667633847416, 0.998474009580391, 0.02481723961198009, 0.545458909987827, 0.09780794353527959, 0.08479890664190294, 0.044150669825829096, 0.04751300551519414, 0.03592495572863247, 0.04655233817537556, 0.06010175044740017, 0.012848925670073563, 0.21004086104778055, 0.2994524953766272, 0.07175179364492205, 0.11534517990012179, 0.09163649614729387, 0.04206379375501729, 0.015991194320089216, 0.0848923837601258, 0.06813639318994535, 0.0005562154546117988, 0.9988367437238302, 0.5169374040817414, 0.06263944075917002, 0.0823162254856949, 0.08373527810367823, 0.08132177128884042, 0.06149972920771884, 0.03910774931450144, 0.06029297580029994, 0.01214574957281802, 0.061641321010196974, 0.1364327905025693, 0.1919099794117466, 0.041505156146865965, 0.10314647715706293, 0.46518650255695315, 0.2576235549661869, 0.7421985671338497, 0.039840738687447086, 0.9598715718207451, 0.39204593221504835, 0.17954480881967222, 0.4283575276864688, 0.9990869673825795, 0.08800243674955195, 0.4116934508963014, 0.11869046597503674, 0.04659616202251918, 0.05686311297663357, 0.06814547666247357, 0.016133780070751193, 0.1937181844858727, 0.7154145616582865, 0.06176825525251892, 0.06278418050338272, 0.06491762353019669, 0.06461284595493755, 0.028445907024186343, 0.002031850501727596, 0.10168431594161775, 0.19934153026178528, 0.4361351056030575, 0.007047427837537864, 0.2557209529620882, 0.17813558821139813, 0.5296275171455959, 0.01839286154703054, 0.09167465637220733, 0.05286137373752871, 0.04547526398242196, 0.017089430413776405, 0.06604051075154271, 0.000724128407363407, 0.9994987086033484, 0.9949437661821409, 0.052852526980064325, 0.5930400914664494, 0.025557794736838616, 0.1409400719468382, 0.0488823841083224, 0.13870686658148337, 0.997313475237534, 0.9975995821764044, 0.9979153444965198, 0.9992019375177777, 0.006430650243052592, 0.26237052991654575, 0.730950577626978, 0.9996934044799829, 0.06093280018153827, 0.4091516546485963, 0.11515639312287106, 0.07325134462257128, 0.029806478067142365, 0.08425004501635075, 0.01616808957885582, 0.04883422974838085, 0.08282021396515941, 0.07974057785490117, 0.005173048307677025, 0.4394889764373268, 0.042485035037517695, 0.10830381988838708, 0.06592884970847954, 0.07638501118144374, 0.07341326002596969, 0.04435613761689024, 0.1150177762026062, 0.029717511554740356, 0.0835195039457896, 0.20397225586760676, 0.7122241115377133, 0.9989332349744656, 0.040374533470669965, 0.023642744825167098, 0.08074906694133993, 0.7492931436899111, 0.10584674990959424, 0.9986370029124908, 0.9988218865027239, 0.9986612287006125, 0.9994981562853426, 0.01725960596912984, 0.06693629238027919, 0.09824698782427756, 0.053659672404025464, 0.10211933531735155, 0.10610232131022768, 0.4287241867331931, 0.0739065178678124, 0.052442648906202205, 0.0006638309988126861, 0.1759147362111263, 0.8174298883723532, 0.006692408442814588, 0.17297308201286718, 0.15664654110859144, 0.0756021804035831, 0.12825895196872464, 0.43875740105814864, 0.027652159369403937, 0.9998703960608228, 0.9987151158627037, 0.30899264964711204, 0.6909113366473574, 0.9983970044467962, 0.9995329971834496, 0.997699937663097, 0.015666051650165113, 0.1507857471328392, 0.32649475825457747, 0.03471454627025224, 0.4213811847266003, 0.03863105918279352, 0.012105585366036679, 0.11491249849087906, 0.6098796364859957, 0.27498174333062037, 0.6814685120171357, 0.3012288350220672, 0.017448227602371108, 0.8123949096157469, 0.1256320275124776, 0.06166694033386858, 0.9985764169912029, 0.07126850183442802, 0.6844874806619631, 0.10488864291719081, 0.06522617233107435, 0.06971918657715785, 0.004338082720356489, 0.9961533292948962, 0.9994981070838621, 0.999140685807403, 0.01101125095440114, 0.9886530321201595, 0.2638739355187203, 0.12455713736627179, 0.5903864314470686, 0.02087952013654267, 0.045114817307342306, 0.014170679795254954, 0.437411289598431, 0.2685199222427393, 0.23468380926223256, 0.999985430316795, 0.9999223273893575, 0.49383471274094165, 0.1401764424253022, 0.1040982433092818, 0.04009965443150038, 0.06526247483407512, 0.03883576847520667, 0.023094643383185034, 0.03148225018404328, 0.0483723625090592, 0.01459213785902736, 0.9984325523739229, 0.9992160756706401, 0.9971730076151031, 0.15740859036670077, 0.3461972629130425, 0.11243470740478627, 0.02782282590016745, 0.2910597905812038, 0.04027322287832458, 0.024900793956314247, 0.9996678054484489, 0.998087002889964, 0.998253186602823, 0.9993598919589952, 0.9991838717117948, 0.06456134615195204, 0.04324983382994845, 0.8023157580048408, 0.04262302464400717, 0.047010688945596145, 0.2159204084556531, 0.7830366619897781, 0.9989096778609051, 0.9984015178359584, 0.9021702424298319, 0.09724777558602704, 0.41549848023776376, 0.09366413971283796, 0.014430812223198872, 0.13695657638243458, 0.04410927509732485, 0.2954232313617128, 0.054988667484616206, 0.11215330862072588, 0.8328085823247191, 0.9996424693002226, 0.12872576972832936, 0.1690573603885078, 0.13466373486594224, 0.1831920460298059, 0.08839417906815092, 0.06303557500987474, 0.0683448144270345, 0.058634494966702845, 0.08373695150923885, 0.02221497545601053, 0.07258371817253796, 0.09472442224441004, 0.15773711249719624, 0.10507592025203853, 0.13912906250729262, 0.09842138581856306, 0.114564793425698, 0.08552309068207359, 0.09168469663899531, 0.040584444569591115, 0.5359665993442333, 0.06363298154029631, 0.09237838246776608, 0.08918444903138055, 0.07567165372359562, 0.03464189342541228, 0.04827753232690435, 0.0357474857687765, 0.022111846867284436, 0.002456871874142715, 0.8802995857085473, 0.11949379141942194, 0.9990359146057929, 0.9992516493815131, 0.13282820812782611, 0.07719261157937404, 0.0694377777893724, 0.24153817171610587, 0.1333262249767253, 0.07612543261744721, 0.057200792359278094, 0.1065756056644261, 0.05535101549193825, 0.05037084700294638, 0.11489617110866807, 0.4136045782941977, 0.12625596203749118, 0.10570014988057316, 0.029860021870049328, 0.05312054615287761, 0.06978157284848484, 0.04879300675142118, 0.019906681246699552, 0.01795928851604416, 0.004866162007912764, 0.6591952022346941, 0.09381507685022514, 0.09087274633381277, 0.07966925705978106, 0.064504938244425, 0.007016326616060263, 0.9990624065207339, 0.25709633658279896, 0.1439776331346882, 0.07912782268886574, 0.07608798782421781, 0.10390708264614734, 0.030858929686577444, 0.08769463003469173, 0.07995686856104245, 0.1273045994831344, 0.014001663618984393, 0.02898602727891216, 0.3242477553358753, 0.11401883793107144, 0.19910512833835786, 0.12396607238472025, 0.01668568359966899, 0.05123360541180415, 0.034440962301880866, 0.09465916657504524, 0.012621222210006031, 0.02813143012270315, 0.19133667358266035, 0.05540388527982758, 0.0861122402992669, 0.03500322984733293, 0.21538797261886458, 0.08783019023042433, 0.0562628602454063, 0.24459312144854112, 0.9995045455490652, 0.9992436230038504, 0.15160346742850003, 0.8414951957898388, 0.006716609316452533, 0.07792501718212634, 0.7982468178009858, 0.12328435554187153, 0.9993816019001736, 0.9948425031301451, 0.10395435679891991, 0.8954849923236908, 0.9995135039664359, 0.04725598979448754, 0.08132205472665828, 0.14091394547151406, 0.07638769434651099, 0.10789168754283601, 0.15846888143934576, 0.1291473937957782, 0.06044591465680434, 0.16814781910809623, 0.03008062000974408, 0.9985484515229492, 0.9996772648516159, 0.19255333863594706, 0.061795038073153744, 0.4997982679356675, 0.034358041168673484, 0.2113390302101858, 0.9987641666128441, 0.999461062611407, 0.12627004799271696, 0.8735741555574568, 0.5218525522885034, 0.2089331433460644, 0.15802069922035675, 0.10110442913642885, 0.009846274571481194, 0.999533881182499, 0.9992843860855145, 0.9982157678694142, 0.999356132417681, 0.10583359215274855, 0.7522895135547685, 0.06884552725156248, 0.0720670683881174, 0.0008352143687364599, 0.9980118223139928, 0.9987768752743202, 0.999321629187476, 0.8095890078483376, 0.08599195959651197, 0.10432848039282702, 0.11886011157135282, 0.8810955997921874, 0.7386250084994709, 0.167829929580834, 0.09330304174631564, 0.9991285155965891, 0.9990850758169446, 0.9985588921163591, 0.9992368051253047, 0.998990350868066, 0.2018717005274439, 0.10500379385117675, 0.07469761412463857, 0.030051933252322256, 0.1259537033265689, 0.14695446209680427, 0.18097264034689495, 0.09447798981863748, 0.012203830762364368, 0.02791626286890849, 0.12851792014849184, 0.8711562815128782, 0.3674684612263126, 0.1258929785874361, 0.06940950243086424, 0.052681703722956434, 0.03193488844236947, 0.11611699232956789, 0.18324543130026288, 0.05311619200108391, 0.36466572019500626, 0.10593342786800454, 0.12091969034177191, 0.06658018900559248, 0.10143373582753494, 0.1299190744227111, 0.04419612775342594, 0.04183188278300971, 0.024519508322219913, 0.2521100304332035, 0.7478067984557834, 0.9983201560392231, 0.26451608884429406, 0.0492419972258423, 0.0527896915504707, 0.09096288248347237, 0.05534403146420316, 0.30935894510759715, 0.1778104395503758, 0.46277459005058147, 0.00266985340413797, 0.18671174806271537, 0.07564584645057582, 0.23316719729471605, 0.038979859700414364, 0.7414855462738851, 0.165455452474338, 0.09268569328423563, 0.9993901436948333, 0.9989291929446354, 0.9964326873473369, 0.9956369030727241, 0.04422850868233593, 0.955335787538456, 0.3736747679603807, 0.6262767097774864, 0.9980150395222152, 0.9224441210484626, 0.07676192262603568, 0.8657891728738768, 0.11055461745927965, 0.02344290683473882, 0.9979774897565864, 0.05164099642011394, 0.9477641695926793, 0.9989822308244471, 0.9997011336937218, 0.9994624674362751, 0.9995364320128658, 0.9985760815159181, 0.5137436123671575, 0.09224071435464254, 0.055749882302256484, 0.1650534394221351, 0.031591599971278674, 0.09426798280199733, 0.047471869475557794, 0.2358611686873269, 0.08389589452982442, 0.1750648153253601, 0.10417841848208967, 0.1690210329355437, 0.17363069747014945, 0.021614204817818013, 0.036723660792359045, 0.23019733662498634, 0.027171990168815455, 0.17432419666746538, 0.03728796919270346, 0.30383225370584555, 0.18479305868055879, 0.04234595870464746, 0.9991777672925167, 0.05636813274502796, 0.9431055328092849, 0.21283691348121767, 0.35231380879046237, 0.4345884620820675, 0.05081404411779196, 0.04471137705462577, 0.12280060661799724, 0.27574091587448873, 0.1127125243299062, 0.17099922199443227, 0.08157646788518072, 0.12280060661799724, 0.017809824286382968, 0.12104583913558908, 0.2537307012649848, 0.6247827543075406, 0.9988689281701515, 0.5206337664384246, 0.07373397037642629, 0.4055368370703446, 0.10238745773112763, 0.8973391342662036, 0.9960557738994, 0.9988326680777584, 0.9997947174538593, 0.9997431806767378, 0.9993023296797896, 0.09834735537873678, 0.032993951481898785, 0.06757415063119655, 0.287745326866175, 0.51330974517031, 0.06505589859724753, 0.9345008767250453, 0.9977271647398621, 0.8478525909522042, 0.05546051289957182, 0.09636264116300604, 0.004724587501394053, 0.9139195969160057, 0.07624639179079021, 0.0004993466464888023, 0.00030729024399310913, 0.004302063415903528, 0.07288095421968763, 0.8023591290240839, 0.04947881295648517, 0.0013372652150401398, 0.036774793413603846, 0.010698121720321118, 0.0033431630376003496, 0.023402141263202447, 0.9730033304338725, 0.025479628947531852, 0.11204931215357965, 0.7724611671193748, 0.04807625445707997, 0.06729132245035913, 0.00011575342164625997, 0.23327389224266298, 0.5854119687737985, 0.011487860019990439, 0.018990135951412766, 0.033760241691400475, 0.06283156092566199, 0.054157054379954925, 0.999016724220756, 0.9950308609826994, 0.9988353928076406, 0.998802511236137, 0.9578589226871499, 0.04196292259869921, 0.1856953842329585, 0.5690665000687438, 0.039934491232894304, 0.05757222486075595, 0.03793776667124959, 0.04126564094065745, 0.032613167840197015, 0.033445136407548974, 0.002495905702055894, 0.005733011518570234, 0.840841689390301, 0.11278988618804135, 0.0004472562177607984, 0.04017174028615171, 0.9998616944793928, 0.9996745738570292, 0.9991535059950885, 0.7706930111750977, 0.18658042313051873, 0.042350160282301895, 0.26936847168539874, 0.2926287018309346, 0.43797834274036584, 0.9997197292559324, 0.9640303533133099, 0.035861703242762256, 0.9335975896556102, 0.06584254457983679, 0.42031025460503246, 0.49296347889867753, 0.08655950550610055, 0.9953664641801488, 0.9981715312517517, 0.9968961202320132, 0.015186218896972027, 0.4878420958463294, 0.04215694365799435, 0.08874826323390453, 0.07125373906459276, 0.08625772333480113, 0.06123083459259122, 0.046712809327085957, 0.08601474383244957, 0.014578770141093147, 0.6004321839201644, 0.3992648912161693, 0.998082442407046, 0.9981498606700252, 0.9849376804619381, 0.01409886189880654, 0.0006608841515065566, 0.8770580052932687, 0.0859064095191289, 0.036761751821248856, 0.9998724300894176, 0.011553776450978085, 0.15773416546117908, 0.8303648901507293, 0.958254605078717, 0.04158993593890033, 0.8072092633547173, 0.01261453995325178, 0.18012107529402782, 0.7885562070647675, 0.055835656897753716, 0.15526230909287658, 0.9983589122334016, 0.975659608041778, 0.024189907637399453, 0.9977459409099295, 0.9997644123336189, 0.9981625588943579, 0.05265899265516392, 0.031150390021364573, 0.17577720083484294, 0.6600915980717731, 0.02021066971624249, 0.014648100069570246, 0.04524223312626759, 0.17791691480312624, 0.821479879625117, 0.9979271684685568, 0.8746595619906642, 0.05954967529598191, 0.06561843201404376, 0.9984122551236994, 0.9993043731839852, 0.067000412420226, 0.134524265562485, 0.6351953161870645, 0.055484716535499655, 0.10756706837778471, 0.9981305304191407, 0.9999580495267363, 0.9986913264787322, 0.0481326373059918, 0.07621000906782036, 0.056154743523657104, 0.7844951372025192, 0.03509671470228569, 0.0800965157751636, 0.9198040099615253, 0.9998536858622693, 0.12184117436345823, 0.036525691220555316, 0.11117673897059537, 0.5892100554556733, 0.1410371580706114, 0.07142944874833666, 0.9274839191322484, 0.9988953366293477, 0.9981562207767593, 0.4037637708092659, 0.07800742835701406, 0.1684860013762546, 0.14078164645546956, 0.000920688532110681, 0.09842997397837826, 0.09600270421190464, 0.013559231109266393, 0.2468686288905478, 0.05756004300556814, 0.05947871110575375, 0.6357186971948303, 0.9985139070928511, 0.999895336177178, 0.9992248605736441, 0.9991974949102393, 0.9990169890303124, 0.9998386526028639, 0.06368504466026609, 0.9354816695366113, 0.999416012460117, 0.9953103247941432, 0.9984339768871363, 0.17467360874018154, 0.8248475968286351, 0.15333296352880094, 0.8463843893901734, 0.9995404382431057, 0.9990764420190489, 0.143956890203647, 0.8557614692593739, 0.9974176514229615, 0.21403639273605618, 0.7857727393309264, 0.9995094991705262, 0.23175946892531094, 0.7679021604591451, 0.17289738425331386, 0.8267964880210372, 0.999886092141512, 0.9989626070748504, 0.9998487384010184, 0.08863149892870911, 0.13092337951988844, 0.3793707308476085, 0.11773333755333251, 0.012143213239051485, 0.22136938157627192, 0.02351875207793305, 0.026380083933111847, 0.0986958523449475, 0.9004724672709128, 0.9981977081434174, 0.9961366214433484, 0.9996062830837698, 0.999500597819264, 0.18411507764466437, 0.10272199405208304, 0.21328910459501732, 0.051606156916380624, 0.27175973844089274, 0.053383566121339106, 0.06705123000774395, 0.05601903494248443, 0.9980852097697116, 0.9990625907535178, 0.9998286935834749, 0.6960438695061414, 0.12414817555518896, 0.17943821002375673, 0.05057438682542188, 0.2735053868452416, 0.2471528792976271, 0.02063345271813221, 0.24591935766773879, 0.04765879024568581, 0.08040318260272171, 0.023100495977908888, 0.011101694668995047, 0.9987239488240599, 0.9984085197022327, 0.9996775511079766, 0.9983230147055878, 0.9986598579606237, 0.16240352747259235, 0.06946557132128461, 0.02347238483002311, 0.10848048124145816, 0.012053386804606462, 0.5341553520778233, 0.08944881786576375, 0.7157524094223261, 0.13708623116024266, 0.08071432301958212, 0.06192368697269528, 0.004270599101565192, 0.8933816964103505, 0.06776928988087269, 0.03870669056657536, 0.9978151263312621, 0.9992611605333238, 0.9993505390858602, 0.8030047609964474, 0.07136408345353448, 0.12557537533515117, 0.9990800579510273, 0.25619138927874063, 0.7434778684783044, 0.9972250709738101, 0.9998367121614802, 0.16463974552186914, 0.7778829470300207, 0.05715709007744004, 0.9284718603745883, 0.07115015881018373, 0.06058406710103292, 0.34486315119049504, 0.011650782134814023, 0.024855001887603246, 0.31752264911413147, 0.01646643875053715, 0.21095682852103256, 0.013048875990991705, 0.9981747632146721, 0.9977921411096525, 0.290295039956849, 0.11469123506801786, 0.05992479841831364, 0.06014430317442468, 0.10437451153079903, 0.1408123010452315, 0.05443717951553766, 0.08747264531024904, 0.06749771250414448, 0.020194437562215586, 0.6101954463770961, 0.3897109892241615, 0.9996257670942206, 0.9982931934251454, 0.1627600542713087, 0.1780188093592439, 0.6595173032451989, 0.9970340796098467, 0.999349177160951, 0.9986148314326865, 0.09157954498714618, 0.07243109467165197, 0.8354552126781927, 0.20198845135819182, 0.7978971770282811, 0.999381891621657, 0.9984426884432467, 0.9987391737174346, 0.9980217813285557, 0.9997542626634655, 0.30553592191316076, 0.1471554490543004, 0.12124563383418585, 0.013070233197090421, 0.1344696344806538, 0.04013330428753647, 0.09741167918066802, 0.03367507141368003, 0.07811386428378746, 0.029292699106420298, 0.3387480953764417, 0.12567470902974515, 0.13078513288240698, 0.11003055437873953, 0.0757177085108672, 0.025760707991989255, 0.04943552869717776, 0.05757048911570068, 0.05725760602268057, 0.028993833286530418, 0.46925029786826983, 0.15376010455576303, 0.03360443630939835, 0.06986553401912361, 0.08771643430553078, 0.02950292397205153, 0.020787210255189547, 0.04413786572122085, 0.05560345702789491, 0.035795016762299486, 0.999603274901381, 0.999565066901006, 0.4176740504408394, 0.03426097940549342, 0.048378568909264584, 0.0027546516104919334, 0.13119028294967833, 0.1878328066904187, 0.11259638457885777, 0.06525081002352767, 0.04114730444426692, 0.3003659065840079, 0.583971583897811, 0.07438528721045964, 0.9992364789110959, 0.9976950721492552, 0.9989688473099143, 0.19038815529749448, 0.14748953661458264, 0.6618644025363543, 0.9996088848778842, 0.8600757290604845, 0.04742272190308436, 0.09233060249312636, 0.9976104971701153, 0.5059440892250533, 0.059073694293949826, 0.039985255661551075, 0.10568967074359731, 0.09202636730145926, 0.03335453487345466, 0.03898060099668798, 0.12497904030896868, 0.03233925404834949, 0.20576643017038054, 0.02441296629140108, 0.7374618129064795, 0.9991812237408213, 0.21398297866918375, 0.07525138149662847, 0.1589107385794724, 0.09585092168285637, 0.04330107426900968, 0.4128316012831797, 0.996737173583978, 0.43579949384178035, 0.06645169586949133, 0.1062454439773844, 0.3913695809057833, 0.8655968911671237, 0.0007596286890453037, 0.03988050617487845, 0.00037981434452265185, 0.02468793239397237, 0.05811159471196574, 0.010634801646634252, 0.9992885550697542, 0.9974985981111687, 0.18958407833368165, 0.08744794450873167, 0.09370639039129426, 0.04785369504762142, 0.17947264365947338, 0.11501490851525735, 0.10124207012744105, 0.06820428778139637, 0.06960924502033898, 0.04785369504762142, 0.11962512538175155, 0.8802848900374544, 0.02533793321409408, 0.7739586872668738, 0.13820690844051317, 0.03282414075462188, 0.019003449910570562, 0.010365518133038487, 0.42892621888443483, 0.0549512134920996, 0.0919732052577105, 0.1639545349619911, 0.08261193019697746, 0.015443459422226259, 0.011212374649013585, 0.10450779389835305, 0.03125713876210863, 0.015231905183565625, 0.0555842528785562, 0.9437412078023435, 0.999203955290779, 0.9987272460173602, 0.9994506275912837, 0.9988194266981462, 0.9987492523586439, 0.9987569884776121, 0.9982815321094238, 0.9954044332225003, 0.9939564799394645, 0.9990635958712987, 0.9994334305625304, 0.24999433634638266, 0.04981060670848854, 0.12354599301711724, 0.08832557976969779, 0.10275888943011022, 0.08691362556378789, 0.12817406513648863, 0.0654205448738259, 0.07083303599648055, 0.03420066854315119, 0.7289603137283945, 0.2706578626298784, 0.9983907816400254, 0.999881021884091, 0.9977360157014556, 0.9989402325032436, 0.9999252789472043, 0.2341690544941247, 0.03855586024632563, 0.08919305387737998, 0.0842710291650831, 0.09307101274161389, 0.13669804996424542, 0.11969469186721979, 0.08546424727715507, 0.08583712793717756, 0.03311180260999725, 0.9806843560384956, 0.019239657417136076, 0.9996340468151388, 0.9987644927592055, 0.9990430015499702, 0.7994588153706891, 0.06756751313139699, 0.07783777512736932, 0.03675672714347996, 0.01837836357173998, 0.24960837704832714, 0.08982753182700932, 0.14964696156503965, 0.08982753182700932, 0.2010050903861775, 0.05844200865853619, 0.07497106161246561, 0.07556138493224882, 0.011117755855916817, 0.991526754102877, 0.007796136022252786, 0.9993799288317677, 0.999508180935973, 0.07067498761157923, 0.9282887795905502, 0.6600497815886991, 0.15323401027873473, 0.06129360411149389, 0.12578911291537925, 0.21526637905477453, 0.21997824176760492, 0.06196647358385085, 0.11730346590895195, 0.06821243113341671, 0.10305829956783683, 0.046406368811248155, 0.08919665693590555, 0.07111625350295173, 0.007560895981053419, 0.8954632048430333, 0.1041522929239316, 0.8761380514735994, 0.12295317756778668, 0.05329888346188336, 0.47486229480247727, 0.005294848904905871, 0.09748751219032574, 0.21658267983817175, 0.0656016206232823, 0.06529015892299372, 0.0024527608897725725, 0.01911596185521164, 0.02670104787495212, 0.8208860615914767, 0.15130593795806202, 0.1997230305839521, 0.6036130244094776, 0.05243840535993148, 0.0006348475225173303, 0.05510476495450427, 0.01904542567551991, 0.007745139774711429, 0.03986842441408834, 0.021711785270092696, 0.9991137273262679, 0.9982377222034666, 0.9964278017900138, 0.9988003899843021, 0.5584217296099849, 0.06769087285394527, 0.08872539202178281, 0.09431967903450555, 0.11076688285191044, 0.07910321835989968, 0.001006971662290095, 0.9990647849844501, 0.06349532451875445, 0.06270163296227002, 0.051589951171487985, 0.007143224008359875, 0.8143275369530257, 0.9990394466366894, 0.9988443459694919, 0.998619192013429], \"Term\": [\"ab\", \"accuracy\", \"accuracy\", \"accuracy\", \"accurate\", \"accurate\", \"accurate\", \"advertised\", \"advertised\", \"advertised\", \"advertised\", \"advertised\", \"ago\", \"ago\", \"ago\", \"ago\", \"air\", \"air\", \"air\", \"airsoft\", \"airsoft\", \"ak\", \"ak\", \"amazon\", \"amazon\", \"amazon\", \"ammo\", \"ammo\", \"ammo\", \"ar\", \"ar\", \"arrived\", \"arrived\", \"arrived\", \"arrows\", \"assisted\", \"awesome\", \"awesome\", \"awesome\", \"awesome\", \"awesome\", \"awesome\", \"awesome\", \"awesome\", \"awesome\", \"awsome\", \"axe\", \"backpacking\", \"bag\", \"bag\", \"ball\", \"balls\", \"bands\", \"bar\", \"bar\", \"bar\", \"barrel\", \"barrel\", \"bars\", \"bars\", \"bars\", \"baseball\", \"based\", \"based\", \"based\", \"based\", \"based\", \"basket\", \"basketball\", \"bat\", \"batteries\", \"battery\", \"bb\", \"bbs\", \"beam\", \"beat\", \"beat\", \"beat\", \"beat\", \"belt\", \"belt\", \"belt\", \"best\", \"best\", \"best\", \"best\", \"best\", \"best\", \"best\", \"best\", \"best\", \"best\", \"better\", \"better\", \"better\", \"better\", \"better\", \"better\", \"better\", \"better\", \"better\", \"better\", \"bi\", \"bicycle\", \"bike\", \"bikes\", \"bipod\", \"bit\", \"bit\", \"bit\", \"bit\", \"bit\", \"bit\", \"bit\", \"bit\", \"bit\", \"bit\", \"bite\", \"bk\", \"blade\", \"blades\", \"boat\", \"boil\", \"bolt\", \"bolts\", \"boots\", \"bore\", \"bottle\", \"bottles\", \"bought\", \"bought\", \"bought\", \"bought\", \"bought\", \"bought\", \"bought\", \"bought\", \"bought\", \"bought\", \"bow\", \"box\", \"box\", \"box\", \"box\", \"box\", \"box\", \"box\", \"bracelets\", \"brake\", \"brakes\", \"bright\", \"brightness\", \"buck\", \"buck\", \"buck\", \"buck\", \"buckle\", \"buffer\", \"burner\", \"button\", \"button\", \"button\", \"button\", \"button\", \"buy\", \"buy\", \"buy\", \"buy\", \"buy\", \"buy\", \"buy\", \"buy\", \"buy\", \"buy\", \"cable\", \"cable\", \"cage\", \"camelbak\", \"camera\", \"camp\", \"camp\", \"camping\", \"camping\", \"canteen\", \"carabiner\", \"cardio\", \"cards\", \"cards\", \"carry\", \"carry\", \"carry\", \"carrying\", \"carrying\", \"carrying\", \"case\", \"case\", \"case\", \"case\", \"case\", \"case\", \"case\", \"chain\", \"chair\", \"chamber\", \"charge\", \"charge\", \"charger\", \"cheap\", \"cheap\", \"cheap\", \"cheap\", \"cheap\", \"cheap\", \"cheap\", \"cheap\", \"clean\", \"clean\", \"clean\", \"cleaning\", \"cleaning\", \"cleats\", \"clip\", \"clip\", \"clip\", \"clip\", \"clip\", \"clips\", \"clothes\", \"club\", \"coffee\", \"cold\", \"cold\", \"cold\", \"coleman\", \"com\", \"comfortable\", \"comfortable\", \"comfortable\", \"comfortable\", \"comfortable\", \"compartment\", \"compartments\", \"compass\", \"compliments\", \"compression\", \"cook\", \"cooking\", \"cotton\", \"crosman\", \"crossbow\", \"cup\", \"customer\", \"cut\", \"cut\", \"cut\", \"cut\", \"cut\", \"cut\", \"cut\", \"cutting\", \"dark\", \"date\", \"day\", \"day\", \"day\", \"day\", \"day\", \"day\", \"day\", \"day\", \"deal\", \"deal\", \"deal\", \"deal\", \"deal\", \"deal\", \"decided\", \"decided\", \"decided\", \"decided\", \"decided\", \"decided\", \"described\", \"die\", \"door\", \"door\", \"door\", \"door\", \"dot\", \"drink\", \"drinking\", \"dumbbell\", \"dumbbells\", \"dvd\", \"ear\", \"ear\", \"easy\", \"easy\", \"easy\", \"easy\", \"easy\", \"easy\", \"easy\", \"easy\", \"easy\", \"eat\", \"edc\", \"edge\", \"emergency\", \"emergency\", \"emergency\", \"emergency\", \"exactly\", \"exactly\", \"exactly\", \"exactly\", \"exactly\", \"exactly\", \"exactly\", \"excellent\", \"excellent\", \"excellent\", \"excellent\", \"excellent\", \"excellent\", \"excellent\", \"excellent\", \"excellent\", \"excellent\", \"exercise\", \"exercise\", \"exercises\", \"expected\", \"expected\", \"expected\", \"expected\", \"expected\", \"expected\", \"expected\", \"expected\", \"expected\", \"extra\", \"extra\", \"extra\", \"extra\", \"extra\", \"extra\", \"extra\", \"extra\", \"extra\", \"extra\", \"eyes\", \"fast\", \"fast\", \"fast\", \"fast\", \"fast\", \"fast\", \"fast\", \"fast\", \"fast\", \"feel\", \"feel\", \"feel\", \"feel\", \"feel\", \"feel\", \"feet\", \"feet\", \"feet\", \"fenders\", \"filter\", \"fit\", \"fit\", \"fit\", \"fit\", \"fit\", \"fitness\", \"fits\", \"fits\", \"fits\", \"fits\", \"fits\", \"fits\", \"flap\", \"flash\", \"flash\", \"flashing\", \"flashlight\", \"flashlight\", \"flashlight\", \"flats\", \"fog\", \"folder\", \"food\", \"food\", \"fps\", \"frame\", \"frame\", \"frame\", \"frame\", \"fuel\", \"fun\", \"fun\", \"fun\", \"ga\", \"game\", \"game\", \"games\", \"gamo\", \"gear\", \"gear\", \"gear\", \"gear\", \"gear\", \"gerber\", \"gi\", \"glasses\", \"glasses\", \"glove\", \"glove\", \"glove\", \"gloves\", \"goggles\", \"going\", \"going\", \"going\", \"going\", \"going\", \"going\", \"going\", \"going\", \"going\", \"going\", \"golf\", \"good\", \"good\", \"good\", \"good\", \"good\", \"good\", \"good\", \"good\", \"good\", \"good\", \"got\", \"got\", \"got\", \"got\", \"got\", \"got\", \"got\", \"got\", \"got\", \"got\", \"grease\", \"great\", \"great\", \"great\", \"great\", \"great\", \"great\", \"great\", \"great\", \"great\", \"green\", \"green\", \"green\", \"green\", \"green\", \"green\", \"grip\", \"grip\", \"grips\", \"grips\", \"gun\", \"gun\", \"gun\", \"hammock\", \"hand\", \"hand\", \"hand\", \"hand\", \"hand\", \"hand\", \"hand\", \"hand\", \"handle\", \"handle\", \"handle\", \"handle\", \"handle\", \"handle\", \"handle\", \"hands\", \"hands\", \"hands\", \"hands\", \"hands\", \"happy\", \"happy\", \"happy\", \"happy\", \"happy\", \"happy\", \"happy\", \"happy\", \"happy\", \"hat\", \"havent\", \"head\", \"head\", \"head\", \"head\", \"head\", \"head\", \"headlamp\", \"headlight\", \"hearing\", \"heart\", \"heat\", \"heat\", \"heat\", \"helmet\", \"high\", \"high\", \"high\", \"high\", \"high\", \"high\", \"high\", \"high\", \"high\", \"high\", \"highly\", \"highly\", \"highly\", \"highly\", \"highly\", \"highly\", \"highly\", \"highly\", \"highly\", \"highly\", \"hiking\", \"hiking\", \"hiking\", \"hip\", \"hit\", \"hit\", \"hit\", \"hit\", \"hit\", \"hitch\", \"hits\", \"hitting\", \"hogue\", \"hold\", \"hold\", \"hold\", \"hold\", \"hold\", \"hold\", \"hold\", \"hold\", \"hold\", \"hold\", \"holder\", \"holder\", \"holder\", \"holds\", \"holds\", \"holds\", \"holds\", \"holds\", \"holds\", \"holster\", \"holsters\", \"hot\", \"hot\", \"hydration\", \"ice\", \"information\", \"inside\", \"inside\", \"inside\", \"inside\", \"inside\", \"inside\", \"inside\", \"install\", \"install\", \"install\", \"installed\", \"installed\", \"installed\", \"instructions\", \"instructions\", \"instructions\", \"iphone\", \"item\", \"item\", \"item\", \"item\", \"item\", \"item\", \"iwb\", \"ka\", \"kershaw\", \"keys\", \"keys\", \"kids\", \"kids\", \"kids\", \"kids\", \"kit\", \"kit\", \"kit\", \"kit\", \"kit\", \"knife\", \"knives\", \"know\", \"know\", \"know\", \"know\", \"know\", \"know\", \"know\", \"know\", \"know\", \"know\", \"lamp\", \"lantern\", \"laptop\", \"large\", \"large\", \"large\", \"large\", \"large\", \"large\", \"large\", \"laser\", \"lasts\", \"layer\", \"led\", \"lee\", \"leg\", \"leg\", \"leg\", \"leg\", \"leg\", \"lens\", \"lens\", \"lenses\", \"levers\", \"lid\", \"lid\", \"life\", \"life\", \"life\", \"life\", \"life\", \"life\", \"light\", \"light\", \"light\", \"lights\", \"like\", \"like\", \"like\", \"like\", \"like\", \"like\", \"like\", \"like\", \"like\", \"like\", \"little\", \"little\", \"little\", \"little\", \"little\", \"little\", \"little\", \"little\", \"little\", \"little\", \"ll\", \"ll\", \"ll\", \"ll\", \"ll\", \"ll\", \"ll\", \"ll\", \"ll\", \"ll\", \"load\", \"load\", \"loader\", \"loading\", \"long\", \"long\", \"long\", \"long\", \"long\", \"long\", \"long\", \"long\", \"long\", \"long\", \"looking\", \"looking\", \"looking\", \"looking\", \"looking\", \"looking\", \"looking\", \"looking\", \"looking\", \"looking\", \"looks\", \"looks\", \"looks\", \"looks\", \"looks\", \"looks\", \"looks\", \"loops\", \"lot\", \"lot\", \"lot\", \"lot\", \"lot\", \"lot\", \"lot\", \"lot\", \"lot\", \"lot\", \"love\", \"love\", \"love\", \"love\", \"love\", \"love\", \"love\", \"love\", \"love\", \"love\", \"low\", \"low\", \"low\", \"low\", \"low\", \"low\", \"low\", \"low\", \"low\", \"lube\", \"machete\", \"mag\", \"mag\", \"mag\", \"magazine\", \"magazine\", \"magazine\", \"magazines\", \"magnetic\", \"magpul\", \"magpul\", \"mags\", \"makes\", \"makes\", \"makes\", \"makes\", \"makes\", \"makes\", \"makes\", \"makes\", \"makes\", \"makes\", \"mask\", \"mat\", \"material\", \"material\", \"material\", \"material\", \"material\", \"mattress\", \"maxpedition\", \"miles\", \"miles\", \"minutes\", \"minutes\", \"minutes\", \"minutes\", \"minutes\", \"mirror\", \"mode\", \"modes\", \"molle\", \"money\", \"money\", \"money\", \"money\", \"money\", \"mora\", \"mosin\", \"mossberg\", \"mount\", \"mount\", \"mount\", \"mountain\", \"mountain\", \"mounted\", \"mounted\", \"mounted\", \"mouth\", \"muffs\", \"muscles\", \"nagant\", \"nalgene\", \"need\", \"need\", \"need\", \"need\", \"need\", \"need\", \"need\", \"need\", \"need\", \"need\", \"net\", \"net\", \"new\", \"new\", \"new\", \"new\", \"new\", \"new\", \"new\", \"new\", \"nice\", \"nice\", \"nice\", \"nice\", \"nice\", \"nice\", \"nice\", \"nice\", \"nice\", \"night\", \"night\", \"nut\", \"old\", \"old\", \"old\", \"old\", \"old\", \"old\", \"old\", \"open\", \"open\", \"open\", \"open\", \"open\", \"open\", \"opening\", \"opening\", \"opening\", \"optic\", \"optics\", \"organized\", \"owning\", \"oz\", \"oz\", \"pack\", \"pack\", \"paddle\", \"pads\", \"pads\", \"pair\", \"pair\", \"pair\", \"pairs\", \"pants\", \"pants\", \"pedal\", \"pedals\", \"pellet\", \"pellets\", \"pen\", \"people\", \"people\", \"people\", \"people\", \"people\", \"people\", \"people\", \"perfect\", \"perfect\", \"perfect\", \"perfect\", \"perfect\", \"perfect\", \"perfect\", \"perfect\", \"perfectly\", \"perfectly\", \"perfectly\", \"perfectly\", \"perfectly\", \"perfectly\", \"perfectly\", \"picatinny\", \"pin\", \"pin\", \"pistol\", \"pistol\", \"pistol\", \"plastic\", \"plastic\", \"plastic\", \"plastic\", \"plastic\", \"plastic\", \"plastic\", \"plastic\", \"plastic\", \"play\", \"play\", \"play\", \"plug\", \"pocket\", \"pocket\", \"pocket\", \"pockets\", \"pockets\", \"poncho\", \"pool\", \"pot\", \"pouch\", \"pouches\", \"power\", \"power\", \"power\", \"power\", \"power\", \"practice\", \"practice\", \"practicing\", \"press\", \"press\", \"press\", \"price\", \"price\", \"price\", \"price\", \"price\", \"price\", \"priced\", \"priced\", \"priced\", \"priced\", \"priced\", \"priced\", \"priced\", \"priced\", \"prime\", \"prime\", \"product\", \"product\", \"product\", \"product\", \"product\", \"products\", \"products\", \"products\", \"products\", \"products\", \"products\", \"products\", \"program\", \"promptly\", \"propane\", \"psi\", \"pump\", \"pump\", \"purchase\", \"purchase\", \"purchase\", \"purchase\", \"purchase\", \"purchase\", \"purchase\", \"purchase\", \"purchase\", \"quality\", \"quality\", \"quality\", \"quality\", \"quality\", \"rack\", \"rail\", \"rails\", \"rain\", \"rain\", \"rain\", \"range\", \"range\", \"range\", \"razor\", \"read\", \"read\", \"reading\", \"reading\", \"rear\", \"rear\", \"rear\", \"reccomend\", \"receiver\", \"recomend\", \"recommend\", \"recommend\", \"recommend\", \"recommend\", \"recommend\", \"recommend\", \"recommend\", \"recommend\", \"recommend\", \"recommend\", \"red\", \"red\", \"reel\", \"reticle\", \"review\", \"review\", \"review\", \"reviews\", \"reviews\", \"reviews\", \"ride\", \"rides\", \"rides\", \"rides\", \"riding\", \"riding\", \"rifle\", \"rifle\", \"rifle\", \"rifles\", \"rifles\", \"rifles\", \"rig\", \"rings\", \"rings\", \"riser\", \"road\", \"roller\", \"room\", \"room\", \"room\", \"room\", \"room\", \"room\", \"room\", \"rope\", \"rope\", \"routine\", \"running\", \"running\", \"running\", \"rush\", \"saddle\", \"safe\", \"safe\", \"safe\", \"safe\", \"safe\", \"scales\", \"scope\", \"scopes\", \"screw\", \"screw\", \"screw\", \"screw\", \"screw\", \"screws\", \"screws\", \"seat\", \"secure\", \"secure\", \"secure\", \"secure\", \"secure\", \"seller\", \"seller\", \"sent\", \"serrated\", \"set\", \"set\", \"set\", \"set\", \"set\", \"set\", \"set\", \"set\", \"setting\", \"setting\", \"setting\", \"setting\", \"settings\", \"sharp\", \"sharpen\", \"sharpener\", \"sharpening\", \"sheath\", \"shell\", \"shell\", \"shells\", \"shifter\", \"shimano\", \"shipped\", \"shipped\", \"shipping\", \"shipping\", \"shirt\", \"shirts\", \"shoot\", \"shoot\", \"shooters\", \"shooting\", \"shooting\", \"shorts\", \"shot\", \"shot\", \"shots\", \"shots\", \"sight\", \"sighting\", \"sights\", \"size\", \"size\", \"size\", \"size\", \"size\", \"size\", \"size\", \"size\", \"skin\", \"skin\", \"sks\", \"sleek\", \"sleeping\", \"sling\", \"small\", \"small\", \"small\", \"small\", \"small\", \"small\", \"small\", \"small\", \"smart\", \"sock\", \"socks\", \"soft\", \"soft\", \"soft\", \"solid\", \"solid\", \"solid\", \"solid\", \"solid\", \"solid\", \"solid\", \"solid\", \"solid\", \"solo\", \"springfield\", \"spyderco\", \"stack\", \"stakes\", \"stand\", \"stand\", \"stand\", \"stand\", \"stand\", \"stand\", \"stand\", \"started\", \"started\", \"started\", \"started\", \"started\", \"steel\", \"steel\", \"steel\", \"stem\", \"step\", \"steps\", \"stock\", \"stock\", \"stock\", \"stone\", \"storage\", \"storage\", \"storing\", \"stove\", \"strap\", \"strap\", \"strap\", \"straps\", \"straps\", \"stuff\", \"stuff\", \"stuff\", \"stuff\", \"stuff\", \"stuff\", \"stuff\", \"stuff\", \"suit\", \"sunglasses\", \"sure\", \"sure\", \"sure\", \"sure\", \"sure\", \"sure\", \"sure\", \"sure\", \"sure\", \"sure\", \"survival\", \"survival\", \"sweat\", \"swiss\", \"switch\", \"switch\", \"switch\", \"swivels\", \"tail\", \"tang\", \"tape\", \"tape\", \"tape\", \"target\", \"target\", \"targets\", \"tasks\", \"taste\", \"taurus\", \"tent\", \"thing\", \"thing\", \"thing\", \"thing\", \"thing\", \"thing\", \"thing\", \"thing\", \"thing\", \"thing\", \"think\", \"think\", \"think\", \"think\", \"think\", \"think\", \"think\", \"think\", \"think\", \"think\", \"time\", \"time\", \"time\", \"time\", \"time\", \"time\", \"time\", \"time\", \"time\", \"time\", \"tire\", \"tires\", \"took\", \"took\", \"took\", \"took\", \"took\", \"took\", \"took\", \"took\", \"tool\", \"tool\", \"tool\", \"tool\", \"topeak\", \"traction\", \"trails\", \"training\", \"training\", \"training\", \"trigger\", \"trip\", \"trip\", \"trip\", \"troy\", \"try\", \"try\", \"try\", \"try\", \"try\", \"try\", \"try\", \"try\", \"tube\", \"tube\", \"tube\", \"tube\", \"tubes\", \"turn\", \"turn\", \"turn\", \"turn\", \"turn\", \"turn\", \"tweezers\", \"unit\", \"unit\", \"unit\", \"unit\", \"update\", \"update\", \"update\", \"update\", \"update\", \"update\", \"update\", \"ups\", \"usb\", \"use\", \"use\", \"use\", \"use\", \"use\", \"use\", \"use\", \"use\", \"use\", \"use\", \"utg\", \"utg\", \"value\", \"value\", \"value\", \"value\", \"value\", \"value\", \"ve\", \"ve\", \"ve\", \"ve\", \"ve\", \"ve\", \"ve\", \"ve\", \"ve\", \"ve\", \"velcro\", \"velcro\", \"vest\", \"victorinox\", \"video\", \"videos\", \"visibility\", \"visible\", \"vision\", \"visor\", \"voodoo\", \"walking\", \"wallet\", \"want\", \"want\", \"want\", \"want\", \"want\", \"want\", \"want\", \"want\", \"want\", \"want\", \"warm\", \"warm\", \"washing\", \"watch\", \"watches\", \"watching\", \"water\", \"way\", \"way\", \"way\", \"way\", \"way\", \"way\", \"way\", \"way\", \"way\", \"way\", \"wear\", \"wear\", \"wearing\", \"weaver\", \"website\", \"weeks\", \"weeks\", \"weeks\", \"weeks\", \"weeks\", \"weight\", \"weight\", \"weight\", \"weight\", \"weight\", \"weight\", \"weight\", \"weight\", \"weight\", \"weights\", \"weights\", \"wheel\", \"wheels\", \"whistle\", \"whistle\", \"wood\", \"wood\", \"wood\", \"wood\", \"work\", \"work\", \"work\", \"work\", \"work\", \"work\", \"work\", \"work\", \"work\", \"work\", \"workout\", \"workout\", \"workouts\", \"workouts\", \"works\", \"works\", \"works\", \"works\", \"works\", \"works\", \"works\", \"works\", \"works\", \"worn\", \"worn\", \"worn\", \"worth\", \"worth\", \"worth\", \"worth\", \"worth\", \"worth\", \"worth\", \"worth\", \"worth\", \"wrench\", \"xd\", \"xdm\", \"xl\", \"years\", \"years\", \"years\", \"years\", \"years\", \"years\", \"years\", \"yoga\", \"zero\", \"zero\", \"zero\", \"zero\", \"zero\", \"zipper\", \"zippered\", \"zippers\"]}, \"R\": 30, \"lambda.step\": 0.01, \"plot.opts\": {\"xlab\": \"PC1\", \"ylab\": \"PC2\"}, \"topic.order\": [5, 8, 4, 7, 9, 10, 1, 6, 2, 3]};\n",
              "\n",
              "function LDAvis_load_lib(url, callback){\n",
              "  var s = document.createElement('script');\n",
              "  s.src = url;\n",
              "  s.async = true;\n",
              "  s.onreadystatechange = s.onload = callback;\n",
              "  s.onerror = function(){console.warn(\"failed to load library \" + url);};\n",
              "  document.getElementsByTagName(\"head\")[0].appendChild(s);\n",
              "}\n",
              "\n",
              "if(typeof(LDAvis) !== \"undefined\"){\n",
              "   // already loaded: just create the visualization\n",
              "   !function(LDAvis){\n",
              "       new LDAvis(\"#\" + \"ldavis_el34491404573654022246424928385\", ldavis_el34491404573654022246424928385_data);\n",
              "   }(LDAvis);\n",
              "}else if(typeof define === \"function\" && define.amd){\n",
              "   // require.js is available: use it to load d3/LDAvis\n",
              "   require.config({paths: {d3: \"https://d3js.org/d3.v5\"}});\n",
              "   require([\"d3\"], function(d3){\n",
              "      window.d3 = d3;\n",
              "      LDAvis_load_lib(\"https://cdn.jsdelivr.net/gh/bmabey/pyLDAvis@3.4.0/pyLDAvis/js/ldavis.v3.0.0.js\", function(){\n",
              "        new LDAvis(\"#\" + \"ldavis_el34491404573654022246424928385\", ldavis_el34491404573654022246424928385_data);\n",
              "      });\n",
              "    });\n",
              "}else{\n",
              "    // require.js not available: dynamically load d3 & LDAvis\n",
              "    LDAvis_load_lib(\"https://d3js.org/d3.v5.js\", function(){\n",
              "         LDAvis_load_lib(\"https://cdn.jsdelivr.net/gh/bmabey/pyLDAvis@3.4.0/pyLDAvis/js/ldavis.v3.0.0.js\", function(){\n",
              "                 new LDAvis(\"#\" + \"ldavis_el34491404573654022246424928385\", ldavis_el34491404573654022246424928385_data);\n",
              "            })\n",
              "         });\n",
              "}\n",
              "</script>"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for topic in lda_model.print_topics():\n",
        "    print(topic)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QVjjmSHrmqvx",
        "outputId": "bc0199a1-26b5-4498-98a6-b491a4361b4c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(0, '0.032*\"bag\" + 0.018*\"case\" + 0.013*\"carry\" + 0.012*\"pack\" + 0.011*\"great\" + 0.011*\"belt\" + 0.010*\"use\" + 0.010*\"fit\" + 0.009*\"small\" + 0.008*\"fits\"')\n",
            "(1, '0.017*\"grip\" + 0.014*\"gun\" + 0.013*\"great\" + 0.011*\"shooting\" + 0.010*\"range\" + 0.009*\"ball\" + 0.009*\"target\" + 0.009*\"grips\" + 0.009*\"like\" + 0.008*\"use\"')\n",
            "(2, '0.079*\"light\" + 0.023*\"bright\" + 0.018*\"battery\" + 0.015*\"batteries\" + 0.014*\"night\" + 0.011*\"lights\" + 0.010*\"use\" + 0.008*\"red\" + 0.008*\"glasses\" + 0.007*\"dark\"')\n",
            "(3, '0.063*\"knife\" + 0.023*\"blade\" + 0.015*\"sharp\" + 0.012*\"handle\" + 0.012*\"steel\" + 0.012*\"knives\" + 0.010*\"like\" + 0.010*\"great\" + 0.009*\"sheath\" + 0.009*\"edge\"')\n",
            "(4, '0.013*\"time\" + 0.012*\"use\" + 0.011*\"ve\" + 0.007*\"like\" + 0.006*\"years\" + 0.006*\"set\" + 0.006*\"reviews\" + 0.006*\"review\" + 0.006*\"watch\" + 0.006*\"ll\"')\n",
            "(5, '0.043*\"bike\" + 0.011*\"ride\" + 0.010*\"pump\" + 0.010*\"easy\" + 0.009*\"rack\" + 0.009*\"seat\" + 0.009*\"road\" + 0.009*\"chain\" + 0.008*\"tire\" + 0.008*\"great\"')\n",
            "(6, '0.015*\"comfortable\" + 0.014*\"fit\" + 0.014*\"like\" + 0.013*\"great\" + 0.013*\"wear\" + 0.012*\"holster\" + 0.009*\"size\" + 0.007*\"good\" + 0.006*\"love\" + 0.006*\"gloves\"')\n",
            "(7, '0.073*\"great\" + 0.043*\"good\" + 0.037*\"price\" + 0.033*\"quality\" + 0.032*\"product\" + 0.019*\"works\" + 0.018*\"buy\" + 0.015*\"nice\" + 0.013*\"recommend\" + 0.012*\"bought\"')\n",
            "(8, '0.028*\"water\" + 0.017*\"bottle\" + 0.016*\"use\" + 0.014*\"great\" + 0.011*\"camping\" + 0.009*\"tent\" + 0.008*\"stove\" + 0.007*\"bag\" + 0.007*\"easy\" + 0.007*\"like\"')\n",
            "(9, '0.020*\"scope\" + 0.015*\"sight\" + 0.014*\"great\" + 0.013*\"rifle\" + 0.012*\"mount\" + 0.012*\"tool\" + 0.011*\"easy\" + 0.011*\"works\" + 0.010*\"ar\" + 0.010*\"use\"')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "topics_df = pd.DataFrame()\n",
        "\n",
        "for i, topic in lda_model.show_topics(formatted=False):\n",
        "  # print(i, topic)\n",
        "    keywords = [word for word, _ in topic]\n",
        "    topics_df = topics_df.append(pd.Series([i, keywords]), ignore_index=True)\n",
        "\n",
        "topics_df.columns = ['Topic', 'Keywords']\n",
        "print(topics_df)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KAG5DouuoKEH",
        "outputId": "9f5c031a-90ab-42a3-84d3-0259e2b583d5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   Topic                                           Keywords\n",
            "0      0  [bag, case, carry, pack, great, belt, use, fit...\n",
            "1      1  [grip, gun, great, shooting, range, ball, targ...\n",
            "2      2  [light, bright, battery, batteries, night, lig...\n",
            "3      3  [knife, blade, sharp, handle, steel, knives, l...\n",
            "4      4  [time, use, ve, like, years, set, reviews, rev...\n",
            "5      5  [bike, ride, pump, easy, rack, seat, road, cha...\n",
            "6      6  [comfortable, fit, like, great, wear, holster,...\n",
            "7      7  [great, good, price, quality, product, works, ...\n",
            "8      8  [water, bottle, use, great, camping, tent, sto...\n",
            "9      9  [scope, sight, great, rifle, mount, tool, easy...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n",
            "<ipython-input-14-2210dd62faf3>:8: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  topics_df = topics_df.append(pd.Series([i, keywords]), ignore_index=True)\n",
            "<ipython-input-14-2210dd62faf3>:8: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  topics_df = topics_df.append(pd.Series([i, keywords]), ignore_index=True)\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "tensorProject",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.13"
    },
    "orig_nbformat": 4,
    "vscode": {
      "interpreter": {
        "hash": "6245d6dd82a2ae19478731a84abf513fc2659f068fc09753150ce21a402543e0"
      }
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}